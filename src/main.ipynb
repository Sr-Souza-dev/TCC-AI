{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das variaveis globais utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas que devem ser instaladas para a execução do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/sr-souza/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/sr-souza/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting enum\n",
      "  Using cached enum-0.4.7.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m Error in sys.excepthook:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 62, in apport_excepthook\n",
      "  \u001b[31m   \u001b[0m     if not enabled():\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 24, in enabled\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Original exception was:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: enum34 in /home/sr-souza/.local/lib/python3.10/site-packages (1.1.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/sr-souza/.local/lib/python3.10/site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /home/sr-souza/.local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/lib/python3/dist-packages (from statsmodels) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arch in /home/sr-souza/.local/lib/python3.10/site-packages (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/lib/python3/dist-packages (from arch) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (2.0.3)\n",
      "Requirement already satisfied: statsmodels>=0.12 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1->arch) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (23.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels>=0.12->arch) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/sr-souza/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sr-souza/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versões de pacotes utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:   3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "Pandas:   2.0.3\n",
      "Numpy:    1.24.3\n",
      "Matplt:   3.5.1\n",
      "Sklearn:  1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a base de dados\n",
    "\n",
    "#### Métodos  disponíveis\n",
    "- SMA => Média móvel simples = $\\frac{1}{n} \\sum_{i=0}^{n-1} Price_{t-x}$ \n",
    "    - x => tamanho da janela de amostragem\n",
    "- EMA => Média móvel exponencial = $\\alpha (currentPrice - EMA_{t-1}) + EMA_{t-1}$\n",
    "    - $\\alpha = \\frac{2}{n+1}$ => Fator de suavização\n",
    "    - n => número de amostras na análise\n",
    "    - $EMA_{t-1}$ => média móvel exponencial anterior\n",
    "- MACD => Convergência/Divergência da média móvel = $EMA(n) - EMA(k)$\n",
    "    - n => média exponencial rápida\n",
    "    - k => média exponencial lenta\n",
    "- CCI => Índice de Canal de Commodities = $\\frac{TP - SMA(TP,N)}{0.015 * DP(TP)}$\n",
    "    - DP => Desvio padrão de TP\n",
    "    - SMA => Média móvel simples\n",
    "    - TP => Preço típico (uma média simples entre os valores de fechamento, alta e baixa)\n",
    "- ADX => Indicador de força da tendência = $\\frac{(n-1)*EMA(TR) + TR}{n}$\n",
    "    - TR => True Range = $max(H-L, abs(H-C_{t-1}), abs(L-C_{t-1}))$\n",
    "- MTM => Indicador de momento = $Price_{t}-Price_{t-n}$\n",
    "- ROC => Taxa de variação = $\\frac{Price_{t}-Price_{t-n}}{Price_{t-n}}100$\n",
    "- TSI => Indicador de Força Real = $\\frac{EMA(EMA(PC,n), k)}{EMA(EMA(|PC|,n), k)}100$\n",
    "    - PC => Variação do preço de fechamento = $price_{t-1} - price_t$\n",
    "- K (%K) => Oscilador estocástico = $\\frac{C_t-L_{t-n}}{H_{t-n}-L_{t-n}}$\n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "- D (%D) => Média móvel simples do Oscilador estocástico = $\\frac{\\sum_{i=0}^{n-1} \\%K_{t-i}}{n}$\n",
    "    - %K => Oscilador estocástico\n",
    "- R (%R) => Williams %R = $\\frac{H_{t-n}-C_t}{H_{t-n}-L_{t-n}}$ \n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "\n",
    "\n",
    "#### Gerando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5732/1511573493.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_generate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutShape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/TCC-AI/src/data_generate.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(inputDataName, outputName)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDataName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportExternalData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDataName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0mdatas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mbounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/TCC-AI/src/data_generate.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(inputDataName, outputName)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# Convert a base de dados de string para float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconverter_para_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_para_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Define qual é a saída desejada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mrowq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "from data_generate import Generate\n",
    "\n",
    "dataShape, outShape = Generate(dataName, outputName)\n",
    "print(\"Data shape: \", dataShape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as variáveis mais relevantes\n",
    "\n",
    "* Randon Forest => Gera vários inputs de dados a partir de um método randomico e cria uma árvore binaria para cada um deles, realizando assim a predição com os melhores resultados (É possível treinar esse modelo e verificar quais foram as variaveis mais importantes para ele). \n",
    "* Fisher => Calcula o escore de Fisher para selecionar as caracteristicas mais importantes de um conjunto de dados, basicamente ele realiza a divizão do \"erro médio quadratico ponderado\" pela \"variância ponderada\" (Essa implementação foca em algoritmos de classificação com classes definidas por inteiros).\n",
    "* Gini => calcula o índice de impureza de Gini para cada feature (variável independente) em relação à variável dependente Y. O índice de impureza de Gini é uma medida de quão impura é a divisão das amostras em duas classes, e é usado em árvores de decisão para selecionar o melhor atributo para dividir os dados em subconjuntos mais homogêneos (Utilizado em bases de dados definidas para classificação com classes referênciadas em int).\n",
    "* KruskalWallis => É um teste não-paramétrico que compara as medianas de duas ou mais amostras independentes para determinar se há diferenças estatisticamente significativas entre elas (Pega os valores em que a maior próximidade estatistica -> não implica diretamente que possa ser uma boa escolha para o modelo).\n",
    "* Lasso => (Least Absolute Shrinkage and Selection Operator) é um método de regressão linear que utiliza a regularização L1 para selecionar as variáveis mais importantes em um conjunto de dados. O objetivo do Lasso é minimizar a soma dos erros quadrados (Caráter linear).\n",
    "* ElasticNet => é uma extensão do algoritmo Lasso (Least Absolute Shrinkage and Selection Operator) e Ridge Regression, que combina a penalização L1 e L2 para selecionar variáveis importantes em um modelo de regressão linear. É utilizado para lidar com problemas de regressão em que há um grande número de variáveis preditoras (high-dimensional data) e muitas dessas variáveis podem não ser relevantes para a predição da variável resposta (Caráter linear).\n",
    "* Chi2 ($X^2$) =>  é um teste estatístico que é usado para determinar se existe uma relação significativa entre duas variáveis categóricas. Ele é usado para avaliar se as diferenças entre as frequências observadas e as frequências esperadas são significativas o suficiente para rejeitar a hipótese nula de que não há relação entre as duas variáveis.\n",
    "* F_Regression => Ele utiliza a estatística F de Fisher para avaliar a relação linear entre as variáveis e calcular o p-valor associado a cada feature.\n",
    "* Mutual_Info_Regression => É uma técnica de seleção de recursos que mede a dependência mútua entre cada recurso e a variável de destino, usando a entropia da informação. Ele estima a informação mútua entre cada recurso e o destino, para ajudar na seleção de recursos que são relevantes para a predição do alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_selection import Selection\n",
    "\n",
    "d1Shape, d2Shape, outShape = Selection(dataName)\n",
    "print(\"Dataset 1 shape: \", d1Shape)\n",
    "print(\"Dataset 2 shape: \", d2Shape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base de dados\n",
    "* Otimização: base de dados destinada ao processo de otimização dos hiperparâmetros das redes.\n",
    "* Treinamento: base de dados destinada ao processo de treinamento dos modelos de IA.\n",
    "* Teste: base de dados destinada a realizar a avalição de mensurar o desempenho da proposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cut import Cut\n",
    "Cut(dataName, setDivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de IA utilizados\n",
    "* Conjunto de classificação:\n",
    "    - Support Vector Machine (SVM)\n",
    "    - K Neighbors Classifier (KNN)\n",
    "    - Logistic Refression (LR)\n",
    "* Conjunto Estatístico:\n",
    "    - Generalized Autoregressive Conditional Heteroskedasticity (GARCH)\n",
    "    - Autoregressive Integrated Moving Average (ARIMA)\n",
    "    - Seasonal Autoregressive Integreted Moving Average (SARIMA)\n",
    "* Conjunto de Regressão:\n",
    "    - Long Short-Term Memory (LSTM)\n",
    "    - Convolutional Neural Network (CNN)\n",
    "    - Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados\n",
    "##### Modelos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassificationOptimized\n",
    "SVM, KNN, LR = GetModelsClassificationOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos Estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from models_statistic import GetModelsStatisticsOptimized\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatisticsOptimized(dataName, setDivision[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_regression import GetModelsRegressionOptimized\n",
    "LSTM, CNN, RNN = GetModelsRegressionOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperando Modelos já Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassification\n",
    "from models_statistic import GetModelsStatistics\n",
    "from models_regression import GetModelsRegression\n",
    "\n",
    "SVM, KNN, LR = GetModelsClassification(dataName)\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatistics(dataName)\n",
    "LSTM, CNN, RNN = GetModelsRegression(dataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_statistic import GetStatisticPredictions\n",
    "from models_classification import GetClassificationPredictions\n",
    "from models_regression import GetRegressionPredictions\n",
    "import pandas as pd\n",
    "\n",
    "Y_Train_statistic = pd.read_csv(f'../Data/Cut/statistic/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "Y_Test_statistic  = pd.read_csv(f'../Data/Cut/statistic/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "X_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "X_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "\n",
    "X_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "X_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "LSTM_epoch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "LSTM_batch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "CNN_epoch  = pd.read_csv(f'../Results/optimization/regression/CNN/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "CNN_batch  = pd.read_csv(f'../Results/optimization/regression/CNN/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "RNN_epoch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "RNN_batch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "\n",
    "ClassificationModels = [SVM, KNN, LR]\n",
    "RegressionModels = [LSTM, CNN, RNN]\n",
    "RegressionNames  = ['LSTM', 'CNN', 'RNN']\n",
    "RegressionEpochs = [LSTM_epoch, CNN_epoch, RNN_epoch]\n",
    "RegressionBatch  = [LSTM_batch, CNN_batch, RNN_batch]\n",
    "\n",
    "GetStatisticPredictions(dataName, Y_Train_statistic.ravel(), Y_Test_statistic.ravel(), window=400)\n",
    "GetClassificationPredictions(dataName, ClassificationModels, X_Test_dataset1, Y_Test_dataset1, X_Train_dataset1, Y_Train_dataset1)\n",
    "GetRegressionPredictions(dataName, RegressionNames, RegressionModels, RegressionEpochs, RegressionBatch, X_Test_dataset2, Y_Test_dataset2, X_Train_dataset2, Y_Train_dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import GetEnsambles\n",
    "GetEnsambles(dataName, setDivision[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import MakeClassificationsLogs\n",
    "MakeClassificationsLogs(dataName, setDivision[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
