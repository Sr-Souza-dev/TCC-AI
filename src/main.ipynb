{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das variaveis globais utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas que devem ser instaladas para a execução do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versões de pacotes utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a base de dados\n",
    "\n",
    "#### Métodos  disponíveis\n",
    "- SMA => Média móvel simples = $\\frac{1}{n} \\sum_{i=0}^{n-1} Price_{t-x}$ \n",
    "    - x => tamanho da janela de amostragem\n",
    "- EMA => Média móvel exponencial = $\\alpha (currentPrice - EMA_{t-1}) + EMA_{t-1}$\n",
    "    - $\\alpha = \\frac{2}{n+1}$ => Fator de suavização\n",
    "    - n => número de amostras na análise\n",
    "    - $EMA_{t-1}$ => média móvel exponencial anterior\n",
    "- MACD => Convergência/Divergência da média móvel = $EMA(n) - EMA(k)$\n",
    "    - n => média exponencial rápida\n",
    "    - k => média exponencial lenta\n",
    "- CCI => Índice de Canal de Commodities = $\\frac{TP - SMA(TP,N)}{0.015 * DP(TP)}$\n",
    "    - DP => Desvio padrão de TP\n",
    "    - SMA => Média móvel simples\n",
    "    - TP => Preço típico (uma média simples entre os valores de fechamento, alta e baixa)\n",
    "- ADX => Indicador de força da tendência = $\\frac{(n-1)*EMA(TR) + TR}{n}$\n",
    "    - TR => True Range = $max(H-L, abs(H-C_{t-1}), abs(L-C_{t-1}))$\n",
    "- MTM => Indicador de momento = $Price_{t}-Price_{t-n}$\n",
    "- ROC => Taxa de variação = $\\frac{Price_{t}-Price_{t-n}}{Price_{t-n}}100$\n",
    "- TSI => Indicador de Força Real = $\\frac{EMA(EMA(PC,n), k)}{EMA(EMA(|PC|,n), k)}100$\n",
    "    - PC => Variação do preço de fechamento = $price_{t-1} - price_t$\n",
    "- K (%K) => Oscilador estocástico = $\\frac{C_t-L_{t-n}}{H_{t-n}-L_{t-n}}$\n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "- D (%D) => Média móvel simples do Oscilador estocástico = $\\frac{\\sum_{i=0}^{n-1} \\%K_{t-i}}{n}$\n",
    "    - %K => Oscilador estocástico\n",
    "- R (%R) => Williams %R = $\\frac{H_{t-n}-C_t}{H_{t-n}-L_{t-n}}$ \n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "\n",
    "\n",
    "#### Gerando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generate import Generate\n",
    "\n",
    "dataShape, outShape = Generate(dataName, outputName)\n",
    "print(\"Data shape: \", dataShape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as variáveis mais relevantes\n",
    "\n",
    "* Randon Forest => Gera vários inputs de dados a partir de um método randomico e cria uma árvore binaria para cada um deles, realizando assim a predição com os melhores resultados (É possível treinar esse modelo e verificar quais foram as variaveis mais importantes para ele). \n",
    "* Fisher => Calcula o escore de Fisher para selecionar as caracteristicas mais importantes de um conjunto de dados, basicamente ele realiza a divizão do \"erro médio quadratico ponderado\" pela \"variância ponderada\" (Essa implementação foca em algoritmos de classificação com classes definidas por inteiros).\n",
    "* Gini => calcula o índice de impureza de Gini para cada feature (variável independente) em relação à variável dependente Y. O índice de impureza de Gini é uma medida de quão impura é a divisão das amostras em duas classes, e é usado em árvores de decisão para selecionar o melhor atributo para dividir os dados em subconjuntos mais homogêneos (Utilizado em bases de dados definidas para classificação com classes referênciadas em int).\n",
    "* KruskalWallis => É um teste não-paramétrico que compara as medianas de duas ou mais amostras independentes para determinar se há diferenças estatisticamente significativas entre elas (Pega os valores em que a maior próximidade estatistica -> não implica diretamente que possa ser uma boa escolha para o modelo).\n",
    "* Lasso => (Least Absolute Shrinkage and Selection Operator) é um método de regressão linear que utiliza a regularização L1 para selecionar as variáveis mais importantes em um conjunto de dados. O objetivo do Lasso é minimizar a soma dos erros quadrados (Caráter linear).\n",
    "* ElasticNet => é uma extensão do algoritmo Lasso (Least Absolute Shrinkage and Selection Operator) e Ridge Regression, que combina a penalização L1 e L2 para selecionar variáveis importantes em um modelo de regressão linear. É utilizado para lidar com problemas de regressão em que há um grande número de variáveis preditoras (high-dimensional data) e muitas dessas variáveis podem não ser relevantes para a predição da variável resposta (Caráter linear).\n",
    "* Chi2 ($X^2$) =>  é um teste estatístico que é usado para determinar se existe uma relação significativa entre duas variáveis categóricas. Ele é usado para avaliar se as diferenças entre as frequências observadas e as frequências esperadas são significativas o suficiente para rejeitar a hipótese nula de que não há relação entre as duas variáveis.\n",
    "* F_Regression => Ele utiliza a estatística F de Fisher para avaliar a relação linear entre as variáveis e calcular o p-valor associado a cada feature.\n",
    "* Mutual_Info_Regression => É uma técnica de seleção de recursos que mede a dependência mútua entre cada recurso e a variável de destino, usando a entropia da informação. Ele estima a informação mútua entre cada recurso e o destino, para ajudar na seleção de recursos que são relevantes para a predição do alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_selection import Selection\n",
    "\n",
    "d1Shape, d2Shape, outShape = Selection(dataName)\n",
    "print(\"Dataset 1 shape: \", d1Shape)\n",
    "print(\"Dataset 2 shape: \", d2Shape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base de dados\n",
    "* Otimização: base de dados destinada ao processo de otimização dos hiperparâmetros das redes.\n",
    "* Treinamento: base de dados destinada ao processo de treinamento dos modelos de IA.\n",
    "* Teste: base de dados destinada a realizar a avalição de mensurar o desempenho da proposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cut import Cut\n",
    "Cut(dataName, setDivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de IA utilizados\n",
    "* Conjunto de classificação:\n",
    "    - Support Vector Machine (SVM)\n",
    "    - K Neighbors Classifier (KNN)\n",
    "    - Logistic Refression (LR)\n",
    "* Conjunto Estatístico:\n",
    "    - Generalized Autoregressive Conditional Heteroskedasticity (GARCH)\n",
    "    - Autoregressive Integrated Moving Average (ARIMA)\n",
    "    - Seasonal Autoregressive Integreted Moving Average (SARIMA)\n",
    "* Conjunto de Regressão:\n",
    "    - Long Short-Term Memory (LSTM)\n",
    "    - Convolutional Neural Network (CNN)\n",
    "    - Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassificationOptimized\n",
    "SVM, KNN, LR = GetModelsClassificationOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Inicio da otimização dos modelos Estatisticos ********************\n",
      "X_train: (440, 1) | X_test: (294, 1) | Y_train: (440, 2) | Y_test: (294, 2)\n",
      "-------------------- GARCH --------------------\n",
      "p: 1  |  q: 1\n",
      "q: 2\n",
      "q: 3\n",
      "q: 4\n",
      "p: 2  |  q: 1\n",
      "q: 2\n",
      "q: 3\n",
      "q: 4\n",
      "p: 3  |  q: 1\n",
      "q: 2\n",
      "q: 3\n",
      "q: 4\n"
     ]
    }
   ],
   "source": [
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Maximum Likelihood optimization failed to converge.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Maximum Likelihood optimization failed to converge. Check mle_retvals.\")\n",
    "\n",
    "from models_statistic import GetModelsStatisticsOptimized\n",
    "\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatisticsOptimized(dataName, setDivision[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
