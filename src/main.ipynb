{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das variaveis globais utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas que devem ser instaladas para a execução do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versões de pacotes utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a base de dados\n",
    "\n",
    "#### Métodos  disponíveis\n",
    "- SMA => Média móvel simples = $\\frac{1}{n} \\sum_{i=0}^{n-1} Price_{t-x}$ \n",
    "    - x => tamanho da janela de amostragem\n",
    "- EMA => Média móvel exponencial = $\\alpha (currentPrice - EMA_{t-1}) + EMA_{t-1}$\n",
    "    - $\\alpha = \\frac{2}{n+1}$ => Fator de suavização\n",
    "    - n => número de amostras na análise\n",
    "    - $EMA_{t-1}$ => média móvel exponencial anterior\n",
    "- MACD => Convergência/Divergência da média móvel = $EMA(n) - EMA(k)$\n",
    "    - n => média exponencial rápida\n",
    "    - k => média exponencial lenta\n",
    "- CCI => Índice de Canal de Commodities = $\\frac{TP - SMA(TP,N)}{0.015 * DP(TP)}$\n",
    "    - DP => Desvio padrão de TP\n",
    "    - SMA => Média móvel simples\n",
    "    - TP => Preço típico (uma média simples entre os valores de fechamento, alta e baixa)\n",
    "- ADX => Indicador de força da tendência = $\\frac{(n-1)*EMA(TR) + TR}{n}$\n",
    "    - TR => True Range = $max(H-L, abs(H-C_{t-1}), abs(L-C_{t-1}))$\n",
    "- MTM => Indicador de momento = $Price_{t}-Price_{t-n}$\n",
    "- ROC => Taxa de variação = $\\frac{Price_{t}-Price_{t-n}}{Price_{t-n}}100$\n",
    "- TSI => Indicador de Força Real = $\\frac{EMA(EMA(PC,n), k)}{EMA(EMA(|PC|,n), k)}100$\n",
    "    - PC => Variação do preço de fechamento = $price_{t-1} - price_t$\n",
    "- K (%K) => Oscilador estocástico = $\\frac{C_t-L_{t-n}}{H_{t-n}-L_{t-n}}$\n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "- D (%D) => Média móvel simples do Oscilador estocástico = $\\frac{\\sum_{i=0}^{n-1} \\%K_{t-i}}{n}$\n",
    "    - %K => Oscilador estocástico\n",
    "- R (%R) => Williams %R = $\\frac{H_{t-n}-C_t}{H_{t-n}-L_{t-n}}$ \n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "\n",
    "\n",
    "#### Gerando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generate import Generate\n",
    "\n",
    "dataShape, outShape = Generate(dataName, outputName)\n",
    "print(\"Data shape: \", dataShape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as variáveis mais relevantes\n",
    "\n",
    "* Randon Forest => Gera vários inputs de dados a partir de um método randomico e cria uma árvore binaria para cada um deles, realizando assim a predição com os melhores resultados (É possível treinar esse modelo e verificar quais foram as variaveis mais importantes para ele). \n",
    "* Fisher => Calcula o escore de Fisher para selecionar as caracteristicas mais importantes de um conjunto de dados, basicamente ele realiza a divizão do \"erro médio quadratico ponderado\" pela \"variância ponderada\" (Essa implementação foca em algoritmos de classificação com classes definidas por inteiros).\n",
    "* Gini => calcula o índice de impureza de Gini para cada feature (variável independente) em relação à variável dependente Y. O índice de impureza de Gini é uma medida de quão impura é a divisão das amostras em duas classes, e é usado em árvores de decisão para selecionar o melhor atributo para dividir os dados em subconjuntos mais homogêneos (Utilizado em bases de dados definidas para classificação com classes referênciadas em int).\n",
    "* KruskalWallis => É um teste não-paramétrico que compara as medianas de duas ou mais amostras independentes para determinar se há diferenças estatisticamente significativas entre elas (Pega os valores em que a maior próximidade estatistica -> não implica diretamente que possa ser uma boa escolha para o modelo).\n",
    "* Lasso => (Least Absolute Shrinkage and Selection Operator) é um método de regressão linear que utiliza a regularização L1 para selecionar as variáveis mais importantes em um conjunto de dados. O objetivo do Lasso é minimizar a soma dos erros quadrados (Caráter linear).\n",
    "* ElasticNet => é uma extensão do algoritmo Lasso (Least Absolute Shrinkage and Selection Operator) e Ridge Regression, que combina a penalização L1 e L2 para selecionar variáveis importantes em um modelo de regressão linear. É utilizado para lidar com problemas de regressão em que há um grande número de variáveis preditoras (high-dimensional data) e muitas dessas variáveis podem não ser relevantes para a predição da variável resposta (Caráter linear).\n",
    "* Chi2 ($X^2$) =>  é um teste estatístico que é usado para determinar se existe uma relação significativa entre duas variáveis categóricas. Ele é usado para avaliar se as diferenças entre as frequências observadas e as frequências esperadas são significativas o suficiente para rejeitar a hipótese nula de que não há relação entre as duas variáveis.\n",
    "* F_Regression => Ele utiliza a estatística F de Fisher para avaliar a relação linear entre as variáveis e calcular o p-valor associado a cada feature.\n",
    "* Mutual_Info_Regression => É uma técnica de seleção de recursos que mede a dependência mútua entre cada recurso e a variável de destino, usando a entropia da informação. Ele estima a informação mútua entre cada recurso e o destino, para ajudar na seleção de recursos que são relevantes para a predição do alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_selection import Selection\n",
    "\n",
    "d1Shape, d2Shape, outShape = Selection(dataName)\n",
    "print(\"Dataset 1 shape: \", d1Shape)\n",
    "print(\"Dataset 2 shape: \", d2Shape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base de dados\n",
    "* Otimização: base de dados destinada ao processo de otimização dos hiperparâmetros das redes.\n",
    "* Treinamento: base de dados destinada ao processo de treinamento dos modelos de IA.\n",
    "* Teste: base de dados destinada a realizar a avalição de mensurar o desempenho da proposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cut import Cut\n",
    "Cut(dataName, setDivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de IA utilizados\n",
    "* Conjunto de classificação:\n",
    "    - Support Vector Machine (SVM)\n",
    "    - K Neighbors Classifier (KNN)\n",
    "    - Logistic Refression (LR)\n",
    "* Conjunto Estatístico:\n",
    "    - Generalized Autoregressive Conditional Heteroskedasticity (GARCH)\n",
    "    - Autoregressive Integrated Moving Average (ARIMA)\n",
    "    - Seasonal Autoregressive Integreted Moving Average (SARIMA)\n",
    "* Conjunto de Regressão:\n",
    "    - Long Short-Term Memory (LSTM)\n",
    "    - Convolutional Neural Network (CNN)\n",
    "    - Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados\n",
    "##### Modelos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassificationOptimized\n",
    "SVM, KNN, LR = GetModelsClassificationOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos Estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from models_statistic import GetModelsStatisticsOptimized\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatisticsOptimized(dataName, setDivision[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_regression import GetModelsRegressionOptimized\n",
    "LSTM, CNN, RNN = GetModelsRegressionOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperando Modelos já Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassification\n",
    "from models_statistic import GetModelsStatistics\n",
    "from models_regression import GetModelsRegression\n",
    "\n",
    "SVM, KNN, LR = GetModelsClassification(dataName)\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatistics(dataName)\n",
    "LSTM, CNN, RNN = GetModelsRegression(dataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_statistic import GetStatisticPredictions\n",
    "from models_classification import GetClassificationPredictions\n",
    "from models_regression import GetRegressionPredictions\n",
    "import pandas as pd\n",
    "\n",
    "Y_Train_statistic = pd.read_csv(f'../Data/Cut/statistic/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "Y_Test_statistic  = pd.read_csv(f'../Data/Cut/statistic/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "X_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "X_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "\n",
    "X_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "X_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "LSTM_epoch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "LSTM_batch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "CNN_epoch  = pd.read_csv(f'../Results/optimization/regression/CNN/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "CNN_batch  = pd.read_csv(f'../Results/optimization/regression/CNN/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "RNN_epoch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "RNN_batch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "\n",
    "ClassificationModels = [SVM, KNN, LR]\n",
    "RegressionModels = [LSTM, CNN, RNN]\n",
    "RegressionNames  = ['LSTM', 'CNN', 'RNN']\n",
    "RegressionEpochs = [LSTM_epoch, CNN_epoch, RNN_epoch]\n",
    "RegressionBatch  = [LSTM_batch, CNN_batch, RNN_batch]\n",
    "\n",
    "GetStatisticPredictions(dataName, Y_Train_statistic.ravel(), Y_Test_statistic.ravel(), window=100)\n",
    "GetClassificationPredictions(dataName, ClassificationModels, X_Test_dataset1, Y_Test_dataset1, X_Train_dataset1, Y_Train_dataset1)\n",
    "GetRegressionPredictions(dataName, RegressionNames, RegressionModels, RegressionEpochs, RegressionBatch, X_Test_dataset2, Y_Test_dataset2, X_Train_dataset2, Y_Train_dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Obtendo os melhores Ensambles ******************************\n",
      "Regressions Shape:      (5283, 3)\n",
      "Classifications Shape:  (5283, 3)\n",
      "Statistics Shape:       (5283, 3)\n",
      "Outputs Shape:          (5283,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m setDivision \u001b[39m=\u001b[39m [\u001b[39m0.1\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.2\u001b[39m]              \u001b[39m# Size of the [optimization, train, test] set\u001b[39;00m\n\u001b[1;32m      5\u001b[0m outputName  \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFechamento\u001b[39m\u001b[39m\"\u001b[39m                 \u001b[39m# Name of the output variable0\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m GetEnsambles(dataName, setDivision[\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[0;32m~/Desktop/TCC-AI/src/strategy.py:107\u001b[0m, in \u001b[0;36mGetEnsambles\u001b[0;34m(dataName, testSize, trainSize)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[39mfor\u001b[39;00m m2 \u001b[39min\u001b[39;00m weights:\n\u001b[1;32m    106\u001b[0m             \u001b[39mfor\u001b[39;00m m3 \u001b[39min\u001b[39;00m weights:\n\u001b[0;32m--> 107\u001b[0m                 getBestWeights(data, [m1, m2, m3], name, outputs\u001b[39m.\u001b[39;49mravel())\n\u001b[1;32m    109\u001b[0m bestEnsambleRegression\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../Results/train/regression/\u001b[39m\u001b[39m{\u001b[39;00mdataName\u001b[39m}\u001b[39;00m\u001b[39m_ensamble.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m bestEnsambleClassification\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../Results/train/classification/\u001b[39m\u001b[39m{\u001b[39;00mdataName\u001b[39m}\u001b[39;00m\u001b[39m_ensamble.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/TCC-AI/src/strategy.py:55\u001b[0m, in \u001b[0;36mgetBestWeights\u001b[0;34m(data, weights, name, output)\u001b[0m\n\u001b[1;32m     53\u001b[0m line \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mloc[line]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     54\u001b[0m hits \u001b[39m=\u001b[39m calculateHits(line, weights)\n\u001b[0;32m---> 55\u001b[0m ensamble \u001b[39m=\u001b[39m ensamble\u001b[39m.\u001b[39;49mdropna(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     56\u001b[0m ensamble \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ensamble, pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mup\u001b[39m\u001b[39m'\u001b[39m: [hits], \u001b[39m'\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mhits], \u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m hits\u001b[39m>\u001b[39m\u001b[39m0.6\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m]})], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m hits \u001b[39m>\u001b[39m \u001b[39m0.6\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:6432\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6429\u001b[0m     mask \u001b[39m=\u001b[39m notna(agg_obj)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39magg_axis, bool_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   6430\u001b[0m \u001b[39melif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   6431\u001b[0m     \u001b[39m# faster equivalent to 'agg_obj.count(agg_axis) > 0'\u001b[39;00m\n\u001b[0;32m-> 6432\u001b[0m     mask \u001b[39m=\u001b[39m notna(agg_obj)\u001b[39m.\u001b[39;49many(axis\u001b[39m=\u001b[39;49magg_axis, bool_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   6433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6434\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid how option: \u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:11258\u001b[0m, in \u001b[0;36mDataFrame.any\u001b[0;34m(self, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[1;32m  11248\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m  11249\u001b[0m \u001b[39m# error: Signature of \"any\" incompatible with supertype \"NDFrame\"\u001b[39;00m\n\u001b[1;32m  11250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39many\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11256\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11257\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m> 11258\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logical_func(\n\u001b[1;32m  11259\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39many\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanany, axis, bool_only, skipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11260\u001b[0m     )\n\u001b[1;32m  11261\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11262\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11757\u001b[0m, in \u001b[0;36mNDFrame._logical_func\u001b[0;34m(self, name, func, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[1;32m  11754\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bool_data()\n\u001b[1;32m  11755\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_reduce_axis1(name, func, skipna\u001b[39m=\u001b[39mskipna)\n\u001b[0;32m> 11757\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11758\u001b[0m     func,\n\u001b[1;32m  11759\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m  11760\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m  11761\u001b[0m     skipna\u001b[39m=\u001b[39;49mskipna,\n\u001b[1;32m  11762\u001b[0m     numeric_only\u001b[39m=\u001b[39;49mbool_only,\n\u001b[1;32m  11763\u001b[0m     filter_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m  11764\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:11210\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11208\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor_from_mgr(res, axes\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m  11209\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m out\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m> 11210\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mastype(out_dtype)\n\u001b[1;32m  11211\u001b[0m \u001b[39melif\u001b[39;00m (df\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mget_dtypes() \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39many() \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m  11212\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6519\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6516\u001b[0m                 \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   6517\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[0;32m-> 6519\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   6520\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m   6521\u001b[0m     dtype \u001b[39m=\u001b[39m pandas_dtype(dtype)\n\u001b[1;32m   6522\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   6523\u001b[0m         arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtype \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39marrays\n\u001b[1;32m   6524\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1319\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1319\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mfind(dtype) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/base.py:537\u001b[0m, in \u001b[0;36mRegistry.find\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mfor\u001b[39;00m dtype_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtypes:\n\u001b[1;32m    536\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m         \u001b[39mreturn\u001b[39;00m dtype_type\u001b[39m.\u001b[39;49mconstruct_from_string(dtype)\n\u001b[1;32m    538\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/base.py:287\u001b[0m, in \u001b[0;36mExtensionDtype.construct_from_string\u001b[0;34m(cls, string)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstruct_from_string\u001b[39m\u001b[39m'\u001b[39m\u001b[39m expects a string, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(string)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39m# error: Non-overlapping equality check (left operand type: \"str\", right\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m#  operand type: \"Callable[[ExtensionDtype], str]\")  [comparison-overlap]\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39;49m(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mstr\u001b[39;49m), (\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m string \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mname:\n\u001b[1;32m    289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot construct a \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstring\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from strategy import GetEnsambles\n",
    "\n",
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable\n",
    "\n",
    "GetEnsambles(dataName, setDivision[2], setDivision[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import MakeClassificationsLogs\n",
    "MakeClassificationsLogs(dataName, setDivision[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
