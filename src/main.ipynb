{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das variaveis globais utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas que devem ser instaladas para a execução do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versões de pacotes utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a base de dados\n",
    "\n",
    "#### Métodos  disponíveis\n",
    "- SMA => Média móvel simples = $\\frac{1}{n} \\sum_{i=0}^{n-1} Price_{t-x}$ \n",
    "    - x => tamanho da janela de amostragem\n",
    "- EMA => Média móvel exponencial = $\\alpha (currentPrice - EMA_{t-1}) + EMA_{t-1}$\n",
    "    - $\\alpha = \\frac{2}{n+1}$ => Fator de suavização\n",
    "    - n => número de amostras na análise\n",
    "    - $EMA_{t-1}$ => média móvel exponencial anterior\n",
    "- MACD => Convergência/Divergência da média móvel = $EMA(n) - EMA(k)$\n",
    "    - n => média exponencial rápida\n",
    "    - k => média exponencial lenta\n",
    "- CCI => Índice de Canal de Commodities = $\\frac{TP - SMA(TP,N)}{0.015 * DP(TP)}$\n",
    "    - DP => Desvio padrão de TP\n",
    "    - SMA => Média móvel simples\n",
    "    - TP => Preço típico (uma média simples entre os valores de fechamento, alta e baixa)\n",
    "- ADX => Indicador de força da tendência = $\\frac{(n-1)*EMA(TR) + TR}{n}$\n",
    "    - TR => True Range = $max(H-L, abs(H-C_{t-1}), abs(L-C_{t-1}))$\n",
    "- MTM => Indicador de momento = $Price_{t}-Price_{t-n}$\n",
    "- ROC => Taxa de variação = $\\frac{Price_{t}-Price_{t-n}}{Price_{t-n}}100$\n",
    "- TSI => Indicador de Força Real = $\\frac{EMA(EMA(PC,n), k)}{EMA(EMA(|PC|,n), k)}100$\n",
    "    - PC => Variação do preço de fechamento = $price_{t-1} - price_t$\n",
    "- K (%K) => Oscilador estocástico = $\\frac{C_t-L_{t-n}}{H_{t-n}-L_{t-n}}$\n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "- D (%D) => Média móvel simples do Oscilador estocástico = $\\frac{\\sum_{i=0}^{n-1} \\%K_{t-i}}{n}$\n",
    "    - %K => Oscilador estocástico\n",
    "- R (%R) => Williams %R = $\\frac{H_{t-n}-C_t}{H_{t-n}-L_{t-n}}$ \n",
    "    - C => Preço de fechamento\n",
    "    - L => Menor valor\n",
    "    - H => Maior valor\n",
    "\n",
    "\n",
    "#### Gerando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generate import Generate\n",
    "\n",
    "dataShape, outShape = Generate(dataName, outputName)\n",
    "print(\"Data shape: \", dataShape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as variáveis mais relevantes\n",
    "\n",
    "* Randon Forest => Gera vários inputs de dados a partir de um método randomico e cria uma árvore binaria para cada um deles, realizando assim a predição com os melhores resultados (É possível treinar esse modelo e verificar quais foram as variaveis mais importantes para ele). \n",
    "* Fisher => Calcula o escore de Fisher para selecionar as caracteristicas mais importantes de um conjunto de dados, basicamente ele realiza a divizão do \"erro médio quadratico ponderado\" pela \"variância ponderada\" (Essa implementação foca em algoritmos de classificação com classes definidas por inteiros).\n",
    "* Gini => calcula o índice de impureza de Gini para cada feature (variável independente) em relação à variável dependente Y. O índice de impureza de Gini é uma medida de quão impura é a divisão das amostras em duas classes, e é usado em árvores de decisão para selecionar o melhor atributo para dividir os dados em subconjuntos mais homogêneos (Utilizado em bases de dados definidas para classificação com classes referênciadas em int).\n",
    "* KruskalWallis => É um teste não-paramétrico que compara as medianas de duas ou mais amostras independentes para determinar se há diferenças estatisticamente significativas entre elas (Pega os valores em que a maior próximidade estatistica -> não implica diretamente que possa ser uma boa escolha para o modelo).\n",
    "* Lasso => (Least Absolute Shrinkage and Selection Operator) é um método de regressão linear que utiliza a regularização L1 para selecionar as variáveis mais importantes em um conjunto de dados. O objetivo do Lasso é minimizar a soma dos erros quadrados (Caráter linear).\n",
    "* ElasticNet => é uma extensão do algoritmo Lasso (Least Absolute Shrinkage and Selection Operator) e Ridge Regression, que combina a penalização L1 e L2 para selecionar variáveis importantes em um modelo de regressão linear. É utilizado para lidar com problemas de regressão em que há um grande número de variáveis preditoras (high-dimensional data) e muitas dessas variáveis podem não ser relevantes para a predição da variável resposta (Caráter linear).\n",
    "* Chi2 ($X^2$) =>  é um teste estatístico que é usado para determinar se existe uma relação significativa entre duas variáveis categóricas. Ele é usado para avaliar se as diferenças entre as frequências observadas e as frequências esperadas são significativas o suficiente para rejeitar a hipótese nula de que não há relação entre as duas variáveis.\n",
    "* F_Regression => Ele utiliza a estatística F de Fisher para avaliar a relação linear entre as variáveis e calcular o p-valor associado a cada feature.\n",
    "* Mutual_Info_Regression => É uma técnica de seleção de recursos que mede a dependência mútua entre cada recurso e a variável de destino, usando a entropia da informação. Ele estima a informação mútua entre cada recurso e o destino, para ajudar na seleção de recursos que são relevantes para a predição do alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_selection import Selection\n",
    "\n",
    "d1Shape, d2Shape, outShape = Selection(dataName)\n",
    "print(\"Dataset 1 shape: \", d1Shape)\n",
    "print(\"Dataset 2 shape: \", d2Shape)\n",
    "print(\"Output shape: \", outShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base de dados\n",
    "* Otimização: base de dados destinada ao processo de otimização dos hiperparâmetros das redes.\n",
    "* Treinamento: base de dados destinada ao processo de treinamento dos modelos de IA.\n",
    "* Teste: base de dados destinada a realizar a avalição de mensurar o desempenho da proposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cut import Cut\n",
    "Cut(dataName, setDivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de IA utilizados\n",
    "* Conjunto de classificação:\n",
    "    - Support Vector Machine (SVM)\n",
    "    - K Neighbors Classifier (KNN)\n",
    "    - Logistic Refression (LR)\n",
    "* Conjunto Estatístico:\n",
    "    - Generalized Autoregressive Conditional Heteroskedasticity (GARCH)\n",
    "    - Autoregressive Integrated Moving Average (ARIMA)\n",
    "    - Seasonal Autoregressive Integreted Moving Average (SARIMA)\n",
    "* Conjunto de Regressão:\n",
    "    - Long Short-Term Memory (LSTM)\n",
    "    - Convolutional Neural Network (CNN)\n",
    "    - Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados\n",
    "##### Modelos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_classification import GetModelsClassificationOptimized\n",
    "SVM, KNN, LR = GetModelsClassificationOptimized(dataName, setDivision[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos Estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from models_statistic import GetModelsStatisticsOptimized\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatisticsOptimized(dataName, setDivision[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelos de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 59s]\n",
      "val_loss: 1.1861188411712646\n",
      "\n",
      "Best val_loss So Far: 1.1861188411712646\n",
      "Total elapsed time: 00h 00m 59s\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 130)            70200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1)              131       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70331 (274.73 KB)\n",
      "Trainable params: 70331 (274.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "LSTM:  None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 16)             80        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 16)             272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 64)             1088      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3553 (13.88 KB)\n",
      "Trainable params: 3553 (13.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "mlp:   None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1, 64)             4416      \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                8256      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12737 (49.75 KB)\n",
      "Trainable params: 12737 (49.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "RNN:   None\n"
     ]
    }
   ],
   "source": [
    "from models_regression import GetModelsRegressionOptimized\n",
    "\n",
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "LSTM, MLP, RNN = GetModelsRegressionOptimized(dataName, setDivision[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperando Modelos já Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 18:41:24.495229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-28 18:41:24.496588: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from models_classification import GetModelsClassification\n",
    "from models_statistic import GetModelsStatistics\n",
    "from models_regression import GetModelsRegression\n",
    "\n",
    "SVM, KNN, LR = GetModelsClassification(dataName)\n",
    "ARIMA, SARIMA, GARCH = GetModelsStatistics(dataName)\n",
    "LSTM, MLP, RNN = GetModelsRegression(dataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 4ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 3ms/step\n",
      "166/166 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from models_statistic import GetStatisticPredictions\n",
    "from models_classification import GetClassificationPredictions\n",
    "from models_regression import GetRegressionPredictions\n",
    "import pandas as pd\n",
    "\n",
    "Y_Train_statistic = pd.read_csv(f'../Data/Cut/statistic/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "Y_Test_statistic  = pd.read_csv(f'../Data/Cut/statistic/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "X_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset1 = pd.read_csv(f'../Data/Cut/dataset1/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "X_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset1  = pd.read_csv(f'../Data/Cut/dataset1/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut_class |T+1|']\n",
    "\n",
    "X_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/X/Train_{setDivision[1]}{dataName}.csv', sep=\";\")\n",
    "Y_Train_dataset2 = pd.read_csv(f'../Data/Cut/dataset2/Y/Train_{setDivision[1]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "X_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/X/Test_{setDivision[2]}{dataName}.csv', sep=\";\")\n",
    "Y_Test_dataset2  = pd.read_csv(f'../Data/Cut/dataset2/Y/Test_{setDivision[2]}{dataName}.csv', sep=\";\")['OutPut |T+1|']\n",
    "\n",
    "LSTM_epoch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "LSTM_batch = pd.read_csv(f'../Results/optimization/regression/LSTM/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "MLP_epoch  = pd.read_csv(f'../Results/optimization/regression/MLP/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "MLP_batch  = pd.read_csv(f'../Results/optimization/regression/MLP/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "RNN_epoch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Epochs'][0]\n",
    "RNN_batch  = pd.read_csv(f'../Results/optimization/regression/RNN/{dataName}_Logs.csv', sep=\";\")['Batch Size'][0]\n",
    "\n",
    "ClassificationModels = [SVM, KNN, LR]\n",
    "RegressionModels = [LSTM, MLP, RNN]\n",
    "RegressionNames  = ['LSTM', 'MLP', 'RNN']\n",
    "RegressionEpochs = [LSTM_epoch, MLP_epoch, RNN_epoch]\n",
    "RegressionBatch  = [LSTM_batch, MLP_batch, RNN_batch]\n",
    "\n",
    "# GetStatisticPredictions(dataName, Y_Train_statistic.ravel(), Y_Test_statistic.ravel(), window=100)\n",
    "# GetClassificationPredictions(dataName, ClassificationModels, X_Test_dataset1, Y_Test_dataset1, X_Train_dataset1, Y_Train_dataset1)\n",
    "GetRegressionPredictions(dataName, RegressionNames, RegressionModels, RegressionEpochs, RegressionBatch, X_Test_dataset2, Y_Test_dataset2, X_Train_dataset2, Y_Train_dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 19:10:05.678268: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 19:10:05.748406: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 19:10:05.750671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 19:10:07.157804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from strategy import GetEnsambles\n",
    "from models_buying import GetModelPrediction\n",
    "\n",
    "dataName    = \"PETR4_B_0_30min\"            # Name of the data file\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable\n",
    "\n",
    "# GetEnsambles(dataName, setDivision[2], setDivision[1])\n",
    "# GetModelPrediction(dataName, setDivision[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressions.shape:     (1321, 3)\n",
      "classifications.shape: (1321, 3)\n",
      "statistics.shape:      (1321, 3)\n",
      "ensambleReg.shape:     (1321,)\n",
      "ensambleClass.shape:   (1321,)\n",
      "ensambleStat.shape:    (1321,)\n",
      "buying.shape:          (1321,)\n",
      "buying2.shape:         (1321,)\n",
      "outputs.shape:         (1321,)\n",
      "               model  accuracy       f1 truePositives trueNegatives falsePositives falseNegatives\n",
      "                LSTM  0.519304 0.635267           133           553            478            157\n",
      "                 MLP  0.513248 0.581107           232           446            379            264\n",
      "                 RNN  0.517033 0.622038           158           525            453            185\n",
      "                 SVC  0.523846 0.667372            61           631            550             79\n",
      "KNeighborsClassifier  0.526117 0.624250           175           520            436            190\n",
      "  LogisticRegression  0.537472 0.699163             0           710            611              0\n",
      "               ARIMA  0.514762 0.560658           271           409            340            301\n",
      "              SARIMA  0.496593 0.518465           298           358            313            352\n",
      "               GARCH  0.519304 0.593730           222           464            389            246\n",
      "         ensambleReg  0.520061 0.650496            97           590            514            120\n",
      "       ensambleClass  0.529145 0.609787           213           486            398            224\n",
      "        ensambleStat  0.519304 0.593730           222           464            389            246\n",
      "              buying  0.529145 0.609787           213           486            398            224\n",
      "             buying2  0.545799 0.653580           155           566            456            144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/Desktop/TCC-AI/src/analyze.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  logs = pd.concat([logs, pd.DataFrame({'model': [column], 'accuracy': [accuracy], 'f1': [f1], 'truePositives': [matrix[0][0]], 'trueNegatives': [matrix[1][1]], 'falsePositives': [matrix[0][1]], 'falseNegatives': [matrix[1][0]]})], axis=0)\n"
     ]
    }
   ],
   "source": [
    "from analyze import MakeClassificationsLogs\n",
    "MakeClassificationsLogs(dataName, setDivision[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
