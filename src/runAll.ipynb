{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "\n",
    "dataNames = [\n",
    "    \"PETR3_B_0_60min\",\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "\n",
    "    \"PETR3_B_0_30min\",\n",
    "    \"WINFUT_F_0_30min\",\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:48:49.463277: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:48:49.528526: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:48:51.022536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:49:06.071178: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:06.629692: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:08.531175: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:09.122044: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:09.853481: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:10.396803: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:10.883420: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:11.463401: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 19:49:16.156186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "    | Etapa 2 PETR3_B_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 PETR3_B_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_30min -X_train: (447, 1) | X_test: (299, 1) | Y_train: (447, 2) | Y_test: (299, 2)\n",
      "                     * PETR3_B_0_30min - ARIMA \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:49:18.294974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-25 19:49:19.021076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-25 19:49:20.411951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "    | Etapa 2 PETR3_B_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 PETR3_B_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_60min -X_train: (227, 1) | X_test: (152, 1) | Y_train: (227, 2) | Y_test: (152, 2)\n",
      "                     * PETR3_B_0_60min - ARIMA \n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 2 WDOFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 WDOFUT_F_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WDOFUT_F_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WDOFUT_F_0_60min -X_train: (267, 1) | X_test: (179, 1) | Y_train: (267, 2) | Y_test: (179, 2)\n",
      "                     * WDOFUT_F_0_60min - ARIMA \n",
      "    | Etapa 2 WINFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 WINFUT_F_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_60min -X_train: (267, 1) | X_test: (179, 1) | Y_train: (267, 2) | Y_test: (179, 2)\n",
      "                     * WINFUT_F_0_60min - ARIMA \n",
      "                     * WINFUT_F_0_60min - SARIMA \n",
      "                     * PETR3_B_0_60min - SARIMA \n",
      "                     * WDOFUT_F_0_60min - SARIMA \n",
      "                     * PETR3_B_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WINFUT_F_0_60min - GARCH \n",
      "                     * PETR3_B_0_60min - GARCH \n",
      "                     * WDOFUT_F_0_60min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "             -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_60min - X_train: (3205, 4) | X_test: (3205, 4) | Y_train: (3205,) | Y_test: (3205,)\n",
      "                 * WINFUT_F_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "        - Etapa 2.3 PETR3_B_0_60min - Obtendo modelos de regressão otimizados\n",
      "             -- PETR3_B_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_60min - X_train: (2728, 4) | X_test: (2728, 4) | Y_train: (2728,) | Y_test: (2728,)\n",
      "                 * PETR3_B_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * PETR3_B_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WINFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "        - Etapa 2.3 WDOFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "             -- WDOFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_60min - X_train: (3206, 4) | X_test: (3206, 4) | Y_train: (3206,) | Y_test: (3206,)\n",
      "                 * WDOFUT_F_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * WDOFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * PETR3_B_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "                     * PETR3_B_0_30min - GARCH \n",
      "    | Etapa 2 PETR3_B_0_60min - Time: 19314.716354370117\n",
      "    | Etapa 2 WINFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 WINFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WINFUT_F_0_30min - ARIMA \n",
      "                     * WINFUT_F_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "        - Etapa 2.3 PETR3_B_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- PETR3_B_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_30min - X_train: (5364, 4) | X_test: (5364, 4) | Y_train: (5364,) | Y_test: (5364,)\n",
      "                 * PETR3_B_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "LU decomposition error.\n",
      "                 * PETR3_B_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WINFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_30min - X_train: (6440, 4) | X_test: (6440, 4) | Y_train: (6440,) | Y_test: (6440,)\n",
      "                 * WINFUT_F_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * WINFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WINFUT_F_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WINFUT_F_0_60min - Time: 52286.23096203804\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.2 WDOFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WDOFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WDOFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WDOFUT_F_0_30min - ARIMA \n",
      "                     * WDOFUT_F_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "                 * PETR3_B_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "LU decomposition error.\n",
      "    | Etapa 2 PETR3_B_0_30min - Time: 59787.21706557274\n",
      "                     * WDOFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WDOFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_30min - X_train: (6439, 4) | X_test: (6439, 4) | Y_train: (6439,) | Y_test: (6439,)\n",
      "                 * WDOFUT_F_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * WDOFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WDOFUT_F_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Time: 24582.75181865692\n",
      "                 * WDOFUT_F_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WDOFUT_F_0_60min - Time: 82855.46032476425\n",
      "                 * WINFUT_F_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WINFUT_F_0_30min - Time: 66319.38026046753\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models optimized {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 3 PETR3_B_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_60min - Treinando modelos!\n",
      "        - Etapa 4.2 PETR3_B_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.3 PETR3_B_0_60min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:37:06.275856: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:06.333684: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:06.336500: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:06.337469: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:06.393788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:06.395502: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:37:07.407396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-26 19:37:07.478934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-26 19:37:07.537122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 3 WDOFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WDOFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.2 WDOFUT_F_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 3 PETR3_B_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_30min - Treinando modelos!\n",
      "        - Etapa 4.2 PETR3_B_0_30min - Treinando modelos de regressão\n",
      "    | Etapa 3 WINFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.2 WINFUT_F_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.3 WDOFUT_F_0_60min - Treinando modelos de estatística\n",
      "        - Etapa 4.3 WINFUT_F_0_60min - Treinando modelos de estatística\n",
      "        - Etapa 4.3 PETR3_B_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WINFUT_F_0_60min - Time: 1910.1330981254578\n",
      "    | Etapa 3 WINFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.2 WINFUT_F_0_30min - Treinando modelos de regressão\n",
      "        - Etapa 4.3 WINFUT_F_0_30min - Treinando modelos de estatística\n",
      "    | Etapa 4 PETR3_B_0_60min - Time: 2318.026127576828\n",
      "    | Etapa 3 WDOFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.2 WDOFUT_F_0_30min - Treinando modelos de regressão\n",
      "        - Etapa 4.3 WDOFUT_F_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WDOFUT_F_0_60min - Time: 3169.470323562622\n",
      "    | Etapa 4 PETR3_B_0_30min - Time: 3928.9413928985596\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Time: 4683.5060975551605\n",
      "    | Etapa 4 WINFUT_F_0_30min - Time: 8605.578033685684\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models trained {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 PETR3_B_0_60min - Obtendo ensambles!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 22:32:30.248688: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:30.293610: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:30.306373: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:30.352760: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:30.417002: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:30.480774: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 22:32:31.370781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-26 22:32:31.514777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-26 22:32:31.568692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 5 WINFUT_F_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 WDOFUT_F_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 PETR3_B_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.7201 - accuracy: 0.4858 - val_loss: 0.7256 - val_accuracy: 0.4756\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.4853 - val_loss: 0.6919 - val_accuracy: 0.5244\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.4827 - val_loss: 0.7074 - val_accuracy: 0.4756\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5203 - val_loss: 0.7136 - val_accuracy: 0.4756\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.5035 - val_loss: 0.6956 - val_accuracy: 0.4756\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.4948 - val_loss: 0.6919 - val_accuracy: 0.5244\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.4901 - val_loss: 0.6921 - val_accuracy: 0.5244\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4957 - val_loss: 0.6969 - val_accuracy: 0.4756\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4909 - val_loss: 0.6958 - val_accuracy: 0.4756\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.5009 - val_loss: 0.6928 - val_accuracy: 0.5244\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.4810 - val_loss: 0.6941 - val_accuracy: 0.4756\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5052 - val_loss: 0.7042 - val_accuracy: 0.4756\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4922 - val_loss: 0.6928 - val_accuracy: 0.5195\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4879 - val_loss: 0.6937 - val_accuracy: 0.4756\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4888 - val_loss: 0.6947 - val_accuracy: 0.4756\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5121 - val_loss: 0.6930 - val_accuracy: 0.5098\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4909 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 18/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5125 - val_loss: 0.6930 - val_accuracy: 0.4951\n",
      "Epoch 19/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 20/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4965 - val_loss: 0.6924 - val_accuracy: 0.5244\n",
      "Epoch 21/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5244\n",
      "Epoch 22/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4991 - val_loss: 0.6927 - val_accuracy: 0.5220\n",
      "Epoch 23/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5030 - val_loss: 0.6948 - val_accuracy: 0.4756\n",
      "Epoch 24/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5082 - val_loss: 0.6919 - val_accuracy: 0.5244\n",
      "Epoch 25/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5009 - val_loss: 0.6943 - val_accuracy: 0.4805\n",
      "Epoch 26/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5060 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 27/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5095 - val_loss: 0.6934 - val_accuracy: 0.4732\n",
      "Epoch 28/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5134 - val_loss: 0.6927 - val_accuracy: 0.5244\n",
      "Epoch 29/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4871 - val_loss: 0.6926 - val_accuracy: 0.5244\n",
      "Epoch 30/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.4974 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 31/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6920 - val_accuracy: 0.5244\n",
      "Epoch 32/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5026 - val_loss: 0.7008 - val_accuracy: 0.4756\n",
      "Epoch 33/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6975 - val_accuracy: 0.4756\n",
      "Epoch 34/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5244\n",
      "Epoch 35/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4914 - val_loss: 0.6925 - val_accuracy: 0.5220\n",
      "Epoch 36/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5009 - val_loss: 0.6944 - val_accuracy: 0.4756\n",
      "Epoch 37/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5116 - val_loss: 0.6971 - val_accuracy: 0.4756\n",
      "Epoch 38/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5086 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 39/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6938 - val_accuracy: 0.4756\n",
      "Epoch 40/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 41/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6940 - val_accuracy: 0.4756\n",
      "Epoch 42/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5086 - val_loss: 0.6921 - val_accuracy: 0.5244\n",
      "Epoch 43/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.4965 - val_loss: 0.6935 - val_accuracy: 0.4756\n",
      "Epoch 44/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4983 - val_loss: 0.6952 - val_accuracy: 0.4756\n",
      "Epoch 45/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4983 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 46/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5047 - val_loss: 0.6966 - val_accuracy: 0.4756\n",
      "Epoch 47/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6953 - val_accuracy: 0.4756\n",
      "Epoch 48/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6962 - val_accuracy: 0.4756\n",
      "Epoch 49/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5086 - val_loss: 0.6945 - val_accuracy: 0.4756\n",
      "Epoch 50/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5091 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 51/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5082 - val_loss: 0.6933 - val_accuracy: 0.4829\n",
      "Epoch 52/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5049\n",
      "Epoch 53/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4953 - val_loss: 0.6944 - val_accuracy: 0.4756\n",
      "Epoch 54/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5013 - val_loss: 0.6946 - val_accuracy: 0.4756\n",
      "Epoch 55/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5244\n",
      "Epoch 56/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5039 - val_loss: 0.6921 - val_accuracy: 0.5244\n",
      "Epoch 57/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4965 - val_loss: 0.6945 - val_accuracy: 0.4756\n",
      "Epoch 58/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5043 - val_loss: 0.6941 - val_accuracy: 0.4756\n",
      "Epoch 59/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5073 - val_loss: 0.6947 - val_accuracy: 0.4756\n",
      "Epoch 60/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 61/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6942 - val_accuracy: 0.4756\n",
      "Epoch 62/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5069 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 63/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6956 - val_accuracy: 0.4756\n",
      "Epoch 64/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5121 - val_loss: 0.6933 - val_accuracy: 0.5146\n",
      "Epoch 65/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6937 - val_accuracy: 0.4805\n",
      "Epoch 66/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6942 - val_accuracy: 0.4756\n",
      "Epoch 67/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4780\n",
      "Epoch 68/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 69/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4918 - val_loss: 0.6944 - val_accuracy: 0.4756\n",
      "Epoch 70/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5043 - val_loss: 0.6946 - val_accuracy: 0.4756\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 6ms/step - loss: 0.8207 - accuracy: 0.5073 - val_loss: 0.7000 - val_accuracy: 0.4756\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5116 - val_loss: 0.7054 - val_accuracy: 0.4756\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.4849 - val_loss: 0.7010 - val_accuracy: 0.4756\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5112 - val_loss: 0.6963 - val_accuracy: 0.4756\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4853 - val_loss: 0.6975 - val_accuracy: 0.4756\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4948 - val_loss: 0.6934 - val_accuracy: 0.4756\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5009 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.4756\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6964 - val_accuracy: 0.4756\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6924 - val_accuracy: 0.5244\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5026 - val_loss: 0.6943 - val_accuracy: 0.4756\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4957 - val_loss: 0.6962 - val_accuracy: 0.4756\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4931 - val_loss: 0.6950 - val_accuracy: 0.4756\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5026 - val_loss: 0.6926 - val_accuracy: 0.5244\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5009 - val_loss: 0.6938 - val_accuracy: 0.4756\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5244\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4948 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5104 - val_loss: 0.6924 - val_accuracy: 0.5244\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5026 - val_loss: 0.6968 - val_accuracy: 0.4756\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5017 - val_loss: 0.6969 - val_accuracy: 0.4756\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6959 - val_accuracy: 0.4756\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4940 - val_loss: 0.6964 - val_accuracy: 0.4756\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.4756\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.4756\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5017 - val_loss: 0.6930 - val_accuracy: 0.5244\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6935 - val_accuracy: 0.4756\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6934 - val_accuracy: 0.4756\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5086 - val_loss: 0.6941 - val_accuracy: 0.4756\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5244\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4836 - val_loss: 0.6953 - val_accuracy: 0.4756\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5086 - val_loss: 0.6962 - val_accuracy: 0.4756\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5017 - val_loss: 0.6949 - val_accuracy: 0.4756\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4983 - val_loss: 0.6959 - val_accuracy: 0.4756\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5086 - val_loss: 0.6944 - val_accuracy: 0.4756\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4991 - val_loss: 0.6948 - val_accuracy: 0.4756\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4974 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6985 - val_accuracy: 0.4756\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4991 - val_loss: 0.6934 - val_accuracy: 0.4756\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4940 - val_loss: 0.6956 - val_accuracy: 0.4756\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4905 - val_loss: 0.6958 - val_accuracy: 0.4756\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5009 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.4756\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4983 - val_loss: 0.6937 - val_accuracy: 0.4756\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5112 - val_loss: 0.6969 - val_accuracy: 0.4756\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.4914 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.4756\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6967 - val_accuracy: 0.4756\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5078 - val_loss: 0.6926 - val_accuracy: 0.5244\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5017 - val_loss: 0.6926 - val_accuracy: 0.5244\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5017 - val_loss: 0.6942 - val_accuracy: 0.4756\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4957 - val_loss: 0.6933 - val_accuracy: 0.4756\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6941 - val_accuracy: 0.4756\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6947 - val_accuracy: 0.4756\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4983 - val_loss: 0.6968 - val_accuracy: 0.4756\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5069 - val_loss: 0.6920 - val_accuracy: 0.5244\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4974 - val_loss: 0.6957 - val_accuracy: 0.4756\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6929 - val_accuracy: 0.5244\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4871 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4922 - val_loss: 0.6948 - val_accuracy: 0.4756\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5035 - val_loss: 0.6925 - val_accuracy: 0.5244\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5009 - val_loss: 0.6926 - val_accuracy: 0.5244\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4784 - val_loss: 0.6949 - val_accuracy: 0.4756\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4931 - val_loss: 0.6956 - val_accuracy: 0.4756\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5121 - val_loss: 0.6923 - val_accuracy: 0.5244\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4896 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5086 - val_loss: 0.6937 - val_accuracy: 0.4756\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4974 - val_loss: 0.6968 - val_accuracy: 0.4756\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.4922 - val_loss: 0.6971 - val_accuracy: 0.4756\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4914 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5078 - val_loss: 0.6928 - val_accuracy: 0.5244\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4853 - val_loss: 0.6939 - val_accuracy: 0.4756\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4983 - val_loss: 0.6953 - val_accuracy: 0.4756\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6929 - val_accuracy: 0.5244\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5009 - val_loss: 0.6934 - val_accuracy: 0.4756\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5086 - val_loss: 0.6942 - val_accuracy: 0.4756\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6929 - val_accuracy: 0.5244\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5138 - val_loss: 0.6974 - val_accuracy: 0.4756\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5086 - val_loss: 0.6943 - val_accuracy: 0.4756\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.4756\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5043 - val_loss: 0.6950 - val_accuracy: 0.4756\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.4983 - val_loss: 0.6955 - val_accuracy: 0.4756\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5009 - val_loss: 0.6951 - val_accuracy: 0.4756\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6928 - val_accuracy: 0.5244\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4983 - val_loss: 0.6921 - val_accuracy: 0.5244\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5017 - val_loss: 0.6961 - val_accuracy: 0.4756\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5035 - val_loss: 0.6956 - val_accuracy: 0.4756\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5086 - val_loss: 0.6940 - val_accuracy: 0.4756\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6949 - val_accuracy: 0.4756\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5086 - val_loss: 0.6945 - val_accuracy: 0.4756\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6952 - val_accuracy: 0.4756\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.4756\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5086 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5026 - val_loss: 0.6932 - val_accuracy: 0.4756\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5244\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4991 - val_loss: 0.6940 - val_accuracy: 0.4756\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4991 - val_loss: 0.6960 - val_accuracy: 0.4756\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4793 - val_loss: 0.6936 - val_accuracy: 0.4756\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6953 - val_accuracy: 0.4756\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 PETR3_B_0_60min - Time: 2620.146806716919\n",
      "    | Etapa 5 WINFUT_F_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 1.2026 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.5073\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.4842 - val_loss: 0.6960 - val_accuracy: 0.4927\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.4945 - val_loss: 0.6983 - val_accuracy: 0.4927\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4835 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4798 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4941 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4842 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4879 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4872 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4974 - val_loss: 0.6950 - val_accuracy: 0.4927\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4857 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5077 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5033 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4849 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4835 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4901 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6941 - val_accuracy: 0.4927\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4989 - val_loss: 0.6939 - val_accuracy: 0.5073\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4754 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4901 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4923 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4938 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4842 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5018 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4864 - val_loss: 0.6943 - val_accuracy: 0.4927\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4791 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5055 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4952 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4857 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4872 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5026 - val_loss: 0.6945 - val_accuracy: 0.4927\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4886 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4908 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4857 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4916 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4827 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4886 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4894 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4769 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5011 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6946 - val_accuracy: 0.4927\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4886 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4982 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4894 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5099 - val_loss: 0.6949 - val_accuracy: 0.4927\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4930 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6956 - val_accuracy: 0.4927\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.4930 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4901 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5004 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.4982 - val_loss: 0.6944 - val_accuracy: 0.4927\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4923 - val_loss: 0.6941 - val_accuracy: 0.4927\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 0.9307 - accuracy: 0.4938 - val_loss: 0.7951 - val_accuracy: 0.5073\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7752 - accuracy: 0.4875 - val_loss: 0.8092 - val_accuracy: 0.4927\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.5044 - val_loss: 0.7458 - val_accuracy: 0.4927\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7218 - accuracy: 0.5004 - val_loss: 0.7013 - val_accuracy: 0.5073\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.5018 - val_loss: 0.7302 - val_accuracy: 0.4927\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.5029 - val_loss: 0.8867 - val_accuracy: 0.4927\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.5026 - val_loss: 0.7328 - val_accuracy: 0.4927\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.4872 - val_loss: 0.7169 - val_accuracy: 0.5073\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.4930 - val_loss: 0.6971 - val_accuracy: 0.4927\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.5132 - val_loss: 0.8593 - val_accuracy: 0.4927\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7317 - accuracy: 0.5022 - val_loss: 0.6929 - val_accuracy: 0.5156\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.5007 - val_loss: 0.6926 - val_accuracy: 0.5281\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.4905 - val_loss: 0.6936 - val_accuracy: 0.5073\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.4699\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.5103 - val_loss: 0.6956 - val_accuracy: 0.4927\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.4941 - val_loss: 0.6945 - val_accuracy: 0.4927\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.5073 - val_loss: 0.7194 - val_accuracy: 0.4927\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.5037 - val_loss: 0.7087 - val_accuracy: 0.5073\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5081 - val_loss: 0.7480 - val_accuracy: 0.4927\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.4938 - val_loss: 0.7132 - val_accuracy: 0.4927\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.5162 - val_loss: 0.7058 - val_accuracy: 0.5073\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.4901 - val_loss: 0.7302 - val_accuracy: 0.5073\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.5018 - val_loss: 0.6960 - val_accuracy: 0.4927\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7074 - accuracy: 0.4989 - val_loss: 0.6943 - val_accuracy: 0.5010\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5132 - val_loss: 0.7212 - val_accuracy: 0.4927\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.5073 - val_loss: 0.6949 - val_accuracy: 0.5073\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.4996 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.4996 - val_loss: 0.6934 - val_accuracy: 0.5010\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.5066 - val_loss: 0.6949 - val_accuracy: 0.4990\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.5029 - val_loss: 0.7001 - val_accuracy: 0.5073\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5103 - val_loss: 0.7106 - val_accuracy: 0.4927\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.5066 - val_loss: 0.6974 - val_accuracy: 0.4927\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4916 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.4912 - val_loss: 0.6948 - val_accuracy: 0.4615\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.4930 - val_loss: 0.6943 - val_accuracy: 0.5073\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5040 - val_loss: 0.6945 - val_accuracy: 0.4927\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.5018 - val_loss: 0.6966 - val_accuracy: 0.5073\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.4948\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4974 - val_loss: 0.6965 - val_accuracy: 0.4927\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.4844\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6973 - val_accuracy: 0.4927\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5011 - val_loss: 0.6945 - val_accuracy: 0.5073\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.4945 - val_loss: 0.6947 - val_accuracy: 0.4927\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.5125 - val_loss: 0.7106 - val_accuracy: 0.4927\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.4912 - val_loss: 0.6994 - val_accuracy: 0.4927\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5070 - val_loss: 0.7003 - val_accuracy: 0.4927\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5070 - val_loss: 0.6933 - val_accuracy: 0.5073\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.4886\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5095 - val_loss: 0.6935 - val_accuracy: 0.4969\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5117 - val_loss: 0.6944 - val_accuracy: 0.4927\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5114 - val_loss: 0.6934 - val_accuracy: 0.5073\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5117 - val_loss: 0.6933 - val_accuracy: 0.5031\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5081 - val_loss: 0.7001 - val_accuracy: 0.5073\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4883 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5143 - val_loss: 0.6936 - val_accuracy: 0.5073\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.5010\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6989 - accuracy: 0.5117 - val_loss: 0.6939 - val_accuracy: 0.5073\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5117 - val_loss: 0.6950 - val_accuracy: 0.5073\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5011 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5037 - val_loss: 0.6933 - val_accuracy: 0.5031\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.5031\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.4938 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5018 - val_loss: 0.6947 - val_accuracy: 0.4927\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6993 - val_accuracy: 0.4927\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.5022 - val_loss: 0.7110 - val_accuracy: 0.4927\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.4927\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4934 - val_loss: 0.6939 - val_accuracy: 0.4948\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5055 - val_loss: 0.6978 - val_accuracy: 0.4927\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.4941 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4989 - val_loss: 0.6946 - val_accuracy: 0.4927\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5026 - val_loss: 0.6971 - val_accuracy: 0.5073\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5011 - val_loss: 0.6934 - val_accuracy: 0.5073\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4930 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5121 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4927 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.4761\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5073 - val_loss: 0.7027 - val_accuracy: 0.5073\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5007 - val_loss: 0.6935 - val_accuracy: 0.4969\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5029 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6943 - val_accuracy: 0.4927\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4809 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6933 - val_accuracy: 0.4886\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5073 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4897 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5018 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5033 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5099 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.4823\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WINFUT_F_0_60min - Time: 3049.0841331481934\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 7.5579 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.5002 - val_loss: 0.6984 - val_accuracy: 0.5052\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5086 - val_loss: 0.7114 - val_accuracy: 0.4948\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.4914 - val_loss: 0.6963 - val_accuracy: 0.4948\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.4866 - val_loss: 0.6943 - val_accuracy: 0.4948\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.4987 - val_loss: 0.7091 - val_accuracy: 0.4948\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.4983 - val_loss: 0.7215 - val_accuracy: 0.5052\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.4939 - val_loss: 0.6958 - val_accuracy: 0.5052\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.4822 - val_loss: 0.6945 - val_accuracy: 0.5052\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.5028 - val_loss: 0.6943 - val_accuracy: 0.5052\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5057 - val_loss: 0.6996 - val_accuracy: 0.4948\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6975 - accuracy: 0.5072 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5028 - val_loss: 0.6947 - val_accuracy: 0.4948\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.4899 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.4906 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.5052\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.4948\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5127 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.4884 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5086 - val_loss: 0.6937 - val_accuracy: 0.4948\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5013 - val_loss: 0.6938 - val_accuracy: 0.5052\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4972 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5042 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4892 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.4948\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5053 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4991 - val_loss: 0.6938 - val_accuracy: 0.4948\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4958 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4917 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.4829 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4976 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6934 - val_accuracy: 0.4948\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4972 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5075 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4928 - val_loss: 0.6934 - val_accuracy: 0.5052\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4796 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5017 - val_loss: 0.6934 - val_accuracy: 0.5052\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5057 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6944 - val_accuracy: 0.5052\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5141 - val_loss: 0.6962 - val_accuracy: 0.5052\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4932 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.4936 - val_loss: 0.6939 - val_accuracy: 0.5052\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 2.5939 - accuracy: 0.4877 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5185 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6941 - val_accuracy: 0.4948\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5141 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.4943 - val_loss: 0.6939 - val_accuracy: 0.5052\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4998 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4921 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4921 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4892 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4950 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5046 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5057 - val_loss: 0.6934 - val_accuracy: 0.4948\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5053 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4917 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4947 - val_loss: 0.6934 - val_accuracy: 0.4948\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.5160 - val_loss: 0.6937 - val_accuracy: 0.4948\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4829 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4958 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4906 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4943 - val_loss: 0.6938 - val_accuracy: 0.5052\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5086 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.4943 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5145 - val_loss: 0.6939 - val_accuracy: 0.4948\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5046 - val_loss: 0.6934 - val_accuracy: 0.5052\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5046 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6938 - val_accuracy: 0.4948\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5079 - val_loss: 0.6937 - val_accuracy: 0.4948\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4914 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5086 - val_loss: 0.6933 - val_accuracy: 0.4948\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5105 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4928 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6934 - val_accuracy: 0.5052\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4958 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.4948\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6939 - val_accuracy: 0.5052\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WDOFUT_F_0_60min - Time: 3123.0748105049133\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "143/143 [==============================] - 2s 5ms/step - loss: 0.7038 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 2/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4997 - val_loss: 0.6940 - val_accuracy: 0.5130\n",
      "Epoch 3/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4929 - val_loss: 0.6940 - val_accuracy: 0.4870\n",
      "Epoch 4/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4869 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 5/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5005 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 6/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 7/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5025 - val_loss: 0.6940 - val_accuracy: 0.4870\n",
      "Epoch 8/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4990 - val_loss: 0.6942 - val_accuracy: 0.4870\n",
      "Epoch 9/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5106 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 10/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 11/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5019 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 12/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5001 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 13/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5049 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 14/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6934 - val_accuracy: 0.5130\n",
      "Epoch 15/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5045 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 16/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6935 - val_accuracy: 0.4870\n",
      "Epoch 17/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5010 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 18/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.5130\n",
      "Epoch 19/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4962 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 20/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5008 - val_loss: 0.6938 - val_accuracy: 0.4870\n",
      "Epoch 21/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4953 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 22/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5069 - val_loss: 0.6942 - val_accuracy: 0.4870\n",
      "Epoch 23/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4933 - val_loss: 0.6933 - val_accuracy: 0.4870\n",
      "Epoch 24/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5023 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 25/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4905 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 26/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6934 - val_accuracy: 0.4870\n",
      "Epoch 27/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4911 - val_loss: 0.6938 - val_accuracy: 0.4870\n",
      "Epoch 28/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4992 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 29/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4970 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 30/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4953 - val_loss: 0.6932 - val_accuracy: 0.4870\n",
      "Epoch 31/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4957 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 32/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4984 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 33/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4975 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 34/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4970 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 35/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5045 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 36/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4977 - val_loss: 0.6943 - val_accuracy: 0.4870\n",
      "Epoch 37/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4988 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 38/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4962 - val_loss: 0.6934 - val_accuracy: 0.5130\n",
      "Epoch 39/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5130\n",
      "Epoch 40/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4968 - val_loss: 0.6941 - val_accuracy: 0.4870\n",
      "Epoch 41/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 42/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5021 - val_loss: 0.6940 - val_accuracy: 0.4870\n",
      "Epoch 43/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4878 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 44/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4986 - val_loss: 0.6937 - val_accuracy: 0.4870\n",
      "Epoch 45/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4957 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 46/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5019 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 47/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4852 - val_loss: 0.6935 - val_accuracy: 0.5130\n",
      "Epoch 48/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5058 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 49/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5067 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 50/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5025 - val_loss: 0.6937 - val_accuracy: 0.4870\n",
      "Epoch 51/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 52/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5065 - val_loss: 0.6939 - val_accuracy: 0.4870\n",
      "Epoch 53/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5076 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 54/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5023 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 55/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5144 - val_loss: 0.6945 - val_accuracy: 0.4870\n",
      "Epoch 56/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4821 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 57/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5087 - val_loss: 0.6935 - val_accuracy: 0.4870\n",
      "Epoch 58/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4944 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 59/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4970 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 60/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.4870\n",
      "Epoch 61/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4896 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 62/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5126 - val_loss: 0.6935 - val_accuracy: 0.4870\n",
      "Epoch 63/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4992 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 64/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4975 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 65/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 66/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6937 - val_accuracy: 0.5130\n",
      "Epoch 67/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4970 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 68/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.4870\n",
      "Epoch 69/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 70/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 4ms/step - loss: 0.6962 - accuracy: 0.5038 - val_loss: 0.6983 - val_accuracy: 0.4870\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4927 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4992 - val_loss: 0.6930 - val_accuracy: 0.5404\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5038 - val_loss: 0.6925 - val_accuracy: 0.5130\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4900 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5078 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5043 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5065 - val_loss: 0.6926 - val_accuracy: 0.5230\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5161 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5093 - val_loss: 0.6940 - val_accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5143\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5068\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4977 - val_loss: 0.6930 - val_accuracy: 0.5019\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6966 - val_accuracy: 0.4882\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4920 - val_loss: 0.6933 - val_accuracy: 0.5130\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6930 - val_accuracy: 0.5193\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.4783\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4984 - val_loss: 0.6936 - val_accuracy: 0.5168\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5049 - val_loss: 0.6934 - val_accuracy: 0.4758\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6947 - val_accuracy: 0.4894\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5082 - val_loss: 0.6933 - val_accuracy: 0.5068\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5049 - val_loss: 0.6933 - val_accuracy: 0.5168\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6950 - val_accuracy: 0.5056\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5168\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5131 - val_loss: 0.6933 - val_accuracy: 0.5168\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5067 - val_loss: 0.6941 - val_accuracy: 0.4919\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6937 - val_accuracy: 0.4795\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5141 - val_loss: 0.6932 - val_accuracy: 0.4795\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5117 - val_loss: 0.6935 - val_accuracy: 0.4845\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5126 - val_loss: 0.6944 - val_accuracy: 0.4932\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6943 - val_accuracy: 0.4857\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5172 - val_loss: 0.6930 - val_accuracy: 0.5155\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5095 - val_loss: 0.6932 - val_accuracy: 0.4907\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5137 - val_loss: 0.6937 - val_accuracy: 0.4919\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5073 - val_loss: 0.6942 - val_accuracy: 0.4969\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5201 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6941 - val_accuracy: 0.4981\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5065 - val_loss: 0.6938 - val_accuracy: 0.4907\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5118\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5095 - val_loss: 0.6940 - val_accuracy: 0.4969\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6930 - val_accuracy: 0.4957\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6938 - val_accuracy: 0.4907\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5078 - val_loss: 0.6930 - val_accuracy: 0.5168\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6938 - val_accuracy: 0.5106\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5218 - val_loss: 0.6932 - val_accuracy: 0.5193\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6930 - val_accuracy: 0.5118\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5157 - val_loss: 0.6933 - val_accuracy: 0.4957\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5117 - val_loss: 0.6943 - val_accuracy: 0.4919\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5159 - val_loss: 0.6934 - val_accuracy: 0.5056\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5181 - val_loss: 0.6930 - val_accuracy: 0.5155\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5159 - val_loss: 0.6938 - val_accuracy: 0.5043\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5087 - val_loss: 0.6932 - val_accuracy: 0.4944\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.4981\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6936 - val_accuracy: 0.5043\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5155 - val_loss: 0.6930 - val_accuracy: 0.4919\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.4882\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5137 - val_loss: 0.6930 - val_accuracy: 0.4882\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5078 - val_loss: 0.6929 - val_accuracy: 0.4919\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5225 - val_loss: 0.6929 - val_accuracy: 0.5106\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5146 - val_loss: 0.6927 - val_accuracy: 0.5006\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5047 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5172 - val_loss: 0.6939 - val_accuracy: 0.5081\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5058 - val_loss: 0.6944 - val_accuracy: 0.5068\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5102 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6927 - val_accuracy: 0.5056\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5126 - val_loss: 0.6933 - val_accuracy: 0.5093\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5218 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5113 - val_loss: 0.6934 - val_accuracy: 0.5056\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5155\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6929 - val_accuracy: 0.5143\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5091 - val_loss: 0.6926 - val_accuracy: 0.5031\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5104 - val_loss: 0.6930 - val_accuracy: 0.5193\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5126 - val_loss: 0.6933 - val_accuracy: 0.5081\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5168 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5297 - val_loss: 0.6940 - val_accuracy: 0.5056\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5141 - val_loss: 0.6926 - val_accuracy: 0.5155\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5146 - val_loss: 0.6924 - val_accuracy: 0.5242\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5043 - val_loss: 0.6927 - val_accuracy: 0.5168\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5106 - val_loss: 0.6929 - val_accuracy: 0.5006\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.4994\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5124 - val_loss: 0.6927 - val_accuracy: 0.5019\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5025 - val_loss: 0.6938 - val_accuracy: 0.4994\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5185 - val_loss: 0.6934 - val_accuracy: 0.4957\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5056\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5227 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6928 - val_accuracy: 0.5143\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5043\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5179 - val_loss: 0.6929 - val_accuracy: 0.5217\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5172 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5133 - val_loss: 0.6926 - val_accuracy: 0.4957\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5010 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5093\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5087 - val_loss: 0.6925 - val_accuracy: 0.5068\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5161 - val_loss: 0.6927 - val_accuracy: 0.5217\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5093\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5058 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5122 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 PETR3_B_0_30min - Time: 5020.178251028061\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "51/51 [==============================] - 0s 972us/step\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WINFUT_F_0_30min - Time: 5740.77686047554\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5127 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "51/51 [==============================] - 0s 906us/step\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.7064 - accuracy: 0.5045 - val_loss: 0.6951 - val_accuracy: 0.5104\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5127 - val_loss: 0.6938 - val_accuracy: 0.5311\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5131 - val_loss: 0.6935 - val_accuracy: 0.5300\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5127 - val_loss: 0.6926 - val_accuracy: 0.5280\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6927 - val_accuracy: 0.5269\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6929 - val_accuracy: 0.5321\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5131 - val_loss: 0.6932 - val_accuracy: 0.5311\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5127 - val_loss: 0.6928 - val_accuracy: 0.5280\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6931 - val_accuracy: 0.5290\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5127 - val_loss: 0.6924 - val_accuracy: 0.5280\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5125 - val_loss: 0.6927 - val_accuracy: 0.5269\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5300\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5290\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5300\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5290\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5311\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5311\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5311\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5280\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5300\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5300\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5300\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5321\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5280\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5311\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5280\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5300\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5311\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5321\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5290\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5321\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5321\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6917 - val_accuracy: 0.5311\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5321\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5300\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5311\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5311\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5300\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5311\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5311\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5321\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5300\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5311\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5280\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5290\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5290\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5300\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5311\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5280\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5290\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5311\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5321\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5321\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5290\n",
      "51/51 [==============================] - 0s 949us/step\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Time: 5629.77897977829\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 PETR3_B_0_60min - Obtendo resultados!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 00:57:17.286090: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 00:57:17.319189: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 00:57:17.344085: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 00:57:17.370649: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 00:57:17.376329: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 00:57:17.431858: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WINFUT_F_0_30min - Obtendo resultados!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 00:57:18.423050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-27 00:57:18.460385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-27 00:57:18.589378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 6 WDOFUT_F_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 WINFUT_F_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 PETR3_B_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 WDOFUT_F_0_30min - Obtendo resultados!\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerando estrategias...\n",
      "Files: ['PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'WDOFUT_F_0_60min_predictions.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/classification \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/regression \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_30min_Predictions.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/statistic \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'WDOFUT_F_0_60min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble1 \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'WDOFUT_F_0_60min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble2 \n",
      "\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
