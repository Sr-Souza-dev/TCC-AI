{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "\n",
    "dataNames = [\n",
    "    \"PETR3_B_0_60min\",\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "\n",
    "    \"PETR3_B_0_30min\",\n",
    "    \"WINFUT_F_0_30min\",\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:54:36.608638: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:37.264902: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:39.499865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:54:44.167686: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.226040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.240884: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.298937: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.535069: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.596850: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.908645: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:44.971594: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 10:54:45.356255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-28 10:54:45.625623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-28 10:54:45.932941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-28 10:54:46.298434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "    | Etapa 2 PETR3_B_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 PETR3_B_0_60min - Obtendo modelos de regressão otimizados\n",
      "             -- PETR3_B_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_60min - X_train: (2728, 4) | X_test: (2728, 4) | Y_train: (2728,) | Y_test: (2728,)\n",
      "                 * PETR3_B_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 2 WDOFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 WDOFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "             -- WDOFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_60min - X_train: (3206, 4) | X_test: (3206, 4) | Y_train: (3206,) | Y_test: (3206,)\n",
      "                 * WDOFUT_F_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "    | Etapa 2 WINFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 WINFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "Using TensorFlow backend\n",
      "             -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_60min - X_train: (3205, 4) | X_test: (3205, 4) | Y_train: (3205,) | Y_test: (3205,)\n",
      "                 * WINFUT_F_0_60min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "    | Etapa 2 PETR3_B_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 PETR3_B_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- PETR3_B_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_30min - X_train: (5364, 4) | X_test: (5364, 4) | Y_train: (5364,) | Y_test: (5364,)\n",
      "                 * PETR3_B_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * PETR3_B_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WINFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WDOFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * PETR3_B_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * PETR3_B_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 PETR3_B_0_60min - Time: 8454.045109987259\n",
      "    | Etapa 2 WINFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 WINFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_30min - X_train: (6440, 4) | X_test: (6440, 4) | Y_train: (6440,) | Y_test: (6440,)\n",
      "                 * WINFUT_F_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * WINFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * PETR3_B_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 PETR3_B_0_30min - Time: 35934.02074766159\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.3 WDOFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "             -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_30min - X_train: (6439, 4) | X_test: (6439, 4) | Y_train: (6439,) | Y_test: (6439,)\n",
      "                 * WDOFUT_F_0_30min - MLP\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "                 * WINFUT_F_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "                 * WDOFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "                 * WDOFUT_F_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WINFUT_F_0_60min - Time: 39062.058117866516\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Time: 7213.368268251419\n",
      "                 * WINFUT_F_0_30min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "                 * WDOFUT_F_0_60min - RF\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "    | Etapa 2 WDOFUT_F_0_60min - Time: 57389.24161171913\n",
      "    | Etapa 2 WINFUT_F_0_30min - Time: 48995.657794713974\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models optimized {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 3 PETR3_B_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 WINFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_60min - Treinando modelos!\n",
      "    | Etapa 3 WDOFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 PETR3_B_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_30min - Treinando modelos!\n",
      "    | Etapa 4 WDOFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.2 PETR3_B_0_30min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 PETR3_B_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 4 WINFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.2 WDOFUT_F_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 WINFUT_F_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 4 PETR3_B_0_60min - Time: 0.4055478572845459\n",
      "    | Etapa 3 WINFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.2 WINFUT_F_0_30min - Treinando modelos de regressão\n",
      "    | Etapa 4 WDOFUT_F_0_60min - Time: 0.6132369041442871\n",
      "    | Etapa 3 WDOFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.2 WDOFUT_F_0_30min - Treinando modelos de regressão\n",
      "    | Etapa 4 WINFUT_F_0_60min - Time: 0.7511422634124756\n",
      "    | Etapa 4 PETR3_B_0_30min - Time: 1.0222339630126953\n",
      "    | Etapa 4 WINFUT_F_0_30min - Time: 1.389157772064209\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Time: 1.4310626983642578\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models trained {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 PETR3_B_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 WINFUT_F_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 WDOFUT_F_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 PETR3_B_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.2494 - accuracy: 0.9340 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.9498e-04 - accuracy: 1.0000 - val_loss: 3.3489e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5168e-04 - accuracy: 1.0000 - val_loss: 1.7209e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.4023e-04 - accuracy: 1.0000 - val_loss: 1.0419e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.9141e-05 - accuracy: 1.0000 - val_loss: 6.9913e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.1507e-05 - accuracy: 1.0000 - val_loss: 5.0030e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.4903e-05 - accuracy: 1.0000 - val_loss: 3.7305e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.4143e-05 - accuracy: 1.0000 - val_loss: 2.8850e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6826e-05 - accuracy: 1.0000 - val_loss: 2.2973e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1602e-05 - accuracy: 1.0000 - val_loss: 1.8742e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7733e-05 - accuracy: 1.0000 - val_loss: 1.5576e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4809e-05 - accuracy: 1.0000 - val_loss: 1.3055e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2523e-05 - accuracy: 1.0000 - val_loss: 1.1137e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0726e-05 - accuracy: 1.0000 - val_loss: 9.5692e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.2687e-06 - accuracy: 1.0000 - val_loss: 8.3297e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.0869e-06 - accuracy: 1.0000 - val_loss: 7.2874e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.1038e-06 - accuracy: 1.0000 - val_loss: 6.4329e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.2851e-06 - accuracy: 1.0000 - val_loss: 5.7008e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.5965e-06 - accuracy: 1.0000 - val_loss: 5.0850e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.0020e-06 - accuracy: 1.0000 - val_loss: 4.5689e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.5018e-06 - accuracy: 1.0000 - val_loss: 4.1284e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.0629e-06 - accuracy: 1.0000 - val_loss: 3.7362e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.6769e-06 - accuracy: 1.0000 - val_loss: 3.3780e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.3481e-06 - accuracy: 1.0000 - val_loss: 3.0805e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.0624e-06 - accuracy: 1.0000 - val_loss: 2.8226e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8049e-06 - accuracy: 1.0000 - val_loss: 2.5915e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5645e-06 - accuracy: 1.0000 - val_loss: 2.3699e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3539e-06 - accuracy: 1.0000 - val_loss: 2.1868e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.1701e-06 - accuracy: 1.0000 - val_loss: 2.0161e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0058e-06 - accuracy: 1.0000 - val_loss: 1.8757e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8681e-06 - accuracy: 1.0000 - val_loss: 1.7370e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7229e-06 - accuracy: 1.0000 - val_loss: 1.5948e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6001e-06 - accuracy: 1.0000 - val_loss: 1.4951e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5021e-06 - accuracy: 1.0000 - val_loss: 1.4006e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3993e-06 - accuracy: 1.0000 - val_loss: 1.3055e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3027e-06 - accuracy: 1.0000 - val_loss: 1.2226e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2135e-06 - accuracy: 1.0000 - val_loss: 1.1409e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1484e-06 - accuracy: 1.0000 - val_loss: 1.0825e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0709e-06 - accuracy: 1.0000 - val_loss: 9.9729e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0009e-06 - accuracy: 1.0000 - val_loss: 9.3797e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.2868e-07 - accuracy: 1.0000 - val_loss: 8.7168e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.7283e-07 - accuracy: 1.0000 - val_loss: 8.1353e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.2192e-07 - accuracy: 1.0000 - val_loss: 7.6701e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.7712e-07 - accuracy: 1.0000 - val_loss: 7.1991e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.3212e-07 - accuracy: 1.0000 - val_loss: 6.8996e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.9618e-07 - accuracy: 1.0000 - val_loss: 6.4722e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.5575e-07 - accuracy: 1.0000 - val_loss: 6.1175e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6.1132e-07 - accuracy: 1.0000 - val_loss: 5.7249e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.7578e-07 - accuracy: 1.0000 - val_loss: 5.4284e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.4220e-07 - accuracy: 1.0000 - val_loss: 5.0562e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.0862e-07 - accuracy: 1.0000 - val_loss: 4.8207e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.9211e-07 - accuracy: 1.0000 - val_loss: 4.5881e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.6244e-07 - accuracy: 1.0000 - val_loss: 4.4107e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.4850e-07 - accuracy: 1.0000 - val_loss: 4.2247e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.2526e-07 - accuracy: 1.0000 - val_loss: 3.9833e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0479e-07 - accuracy: 1.0000 - val_loss: 3.6402e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7393e-07 - accuracy: 1.0000 - val_loss: 3.5210e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.5377e-07 - accuracy: 1.0000 - val_loss: 3.3495e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2893e-07 - accuracy: 1.0000 - val_loss: 3.1431e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1587e-07 - accuracy: 1.0000 - val_loss: 2.9657e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3.0142e-07 - accuracy: 1.0000 - val_loss: 2.8436e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8959e-07 - accuracy: 1.0000 - val_loss: 2.7244e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7689e-07 - accuracy: 1.0000 - val_loss: 2.6110e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6454e-07 - accuracy: 1.0000 - val_loss: 2.4918e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5395e-07 - accuracy: 1.0000 - val_loss: 2.2970e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3173e-07 - accuracy: 1.0000 - val_loss: 2.1807e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1502e-07 - accuracy: 1.0000 - val_loss: 1.9451e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.0427e-07 - accuracy: 1.0000 - val_loss: 1.9451e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.9599e-07 - accuracy: 1.0000 - val_loss: 1.8259e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8411e-07 - accuracy: 1.0000 - val_loss: 1.7125e-07 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "                 * PETR3_B_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying2/tuner0.json\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "                 * PETR3_B_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "    | Etapa 5 PETR3_B_0_60min - Time: 1606.8068177700043\n",
      "    | Etapa 5 WINFUT_F_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 23/70\n",
      "70/86 [=======================>......] - ETA: 0s - loss: nan - accuracy: 0.5058Reloading Tuner from optmz/modelWDOFUT_F_0_60min/buying/tuner0.json\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 25/70\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 2s 7ms/step - loss: 0.3678 - accuracy: 0.9538 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 9.2008e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.0512e-04 - accuracy: 1.0000 - val_loss: 2.7426e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.7375e-05 - accuracy: 1.0000 - val_loss: 8.2615e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.3580e-05 - accuracy: 1.0000 - val_loss: 3.9333e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7005e-05 - accuracy: 1.0000 - val_loss: 2.2804e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0142e-05 - accuracy: 1.0000 - val_loss: 1.4808e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.6827e-06 - accuracy: 1.0000 - val_loss: 1.0404e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.7024e-06 - accuracy: 1.0000 - val_loss: 7.7341e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.4927e-06 - accuracy: 1.0000 - val_loss: 5.9527e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.6901e-06 - accuracy: 1.0000 - val_loss: 4.6707e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0756e-06 - accuracy: 1.0000 - val_loss: 3.8003e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6779e-06 - accuracy: 1.0000 - val_loss: 3.1656e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "23/86 [=======>......................] - ETA: 0s - loss: 1.4287e-06 - accuracy: 1.0000Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.3745e-06 - accuracy: 1.0000 - val_loss: 2.6392e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1456e-06 - accuracy: 1.0000 - val_loss: 2.2630e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.6474e-07 - accuracy: 1.0000 - val_loss: 1.9336e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.3184e-07 - accuracy: 1.0000 - val_loss: 1.6848e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 7.0244e-07 - accuracy: 1.0000 - val_loss: 1.4662e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.1639e-07 - accuracy: 1.0000 - val_loss: 1.3039e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.4456e-07 - accuracy: 1.0000 - val_loss: 1.1544e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.6393e-07 - accuracy: 1.0000 - val_loss: 1.0003e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.0820e-07 - accuracy: 1.0000 - val_loss: 9.0658e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6673e-07 - accuracy: 1.0000 - val_loss: 8.2505e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.3374e-07 - accuracy: 1.0000 - val_loss: 7.4425e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.0500e-07 - accuracy: 1.0000 - val_loss: 6.7560e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.6882e-07 - accuracy: 1.0000 - val_loss: 6.0472e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.5014e-07 - accuracy: 1.0000 - val_loss: 5.5466e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.2796e-07 - accuracy: 1.0000 - val_loss: 4.9245e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0268e-07 - accuracy: 1.0000 - val_loss: 4.3917e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6361e-07 - accuracy: 1.0000 - val_loss: 4.2628e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6007e-07 - accuracy: 1.0000 - val_loss: 3.8266e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.3351e-07 - accuracy: 1.0000 - val_loss: 3.5837e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2560e-07 - accuracy: 1.0000 - val_loss: 3.2690e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.2144e-07 - accuracy: 1.0000 - val_loss: 3.1401e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 2.8823e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.8123e-08 - accuracy: 1.0000 - val_loss: 2.5899e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.7143e-08 - accuracy: 1.0000 - val_loss: 2.4610e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 8.5568e-08 - accuracy: 1.0000 - val_loss: 2.3321e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.4431e-08 - accuracy: 1.0000 - val_loss: 2.2033e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5018 - val_loss: nan - val_accuracy: 0.4927\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.0494e-08 - accuracy: 1.0000 - val_loss: 2.0595e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 7.8744e-08 - accuracy: 1.0000 - val_loss: 1.9306e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "26/26 [==============================] - 0s 1ms/steposs: 7.8179e-08 - accuracy: 1.0000\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 7.7869e-08 - accuracy: 1.0000 - val_loss: 1.8018e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      " 1/86 [..............................] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.0000                 * WINFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "22/86 [======>.......................] - ETA: 0s - loss: 5.8081e-08 - accuracy: 1.0000    | ERRO - Etapa 5 WINFUT_F_0_60min (Obtendo ensambles)\n",
      "        - Input X contains NaN.\n",
      "SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Obtendo ensambles!\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.1971e-08 - accuracy: 1.0000 - val_loss: 1.6878e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.0483e-08 - accuracy: 1.0000 - val_loss: 1.6878e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.6328e-08 - accuracy: 1.0000 - val_loss: 1.3804e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.5540e-08 - accuracy: 1.0000 - val_loss: 1.3804e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.4884e-08 - accuracy: 1.0000 - val_loss: 1.2516e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.2740e-08 - accuracy: 1.0000 - val_loss: 1.0657e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.0903e-08 - accuracy: 1.0000 - val_loss: 1.0657e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.0159e-08 - accuracy: 1.0000 - val_loss: 9.3682e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.8803e-08 - accuracy: 1.0000 - val_loss: 9.3682e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.8803e-08 - accuracy: 1.0000 - val_loss: 9.3682e-08 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.8716e-08 - accuracy: 1.0000 - val_loss: 8.0795e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6703e-08 - accuracy: 1.0000 - val_loss: 8.0795e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6703e-08 - accuracy: 1.0000 - val_loss: 8.0795e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6703e-08 - accuracy: 1.0000 - val_loss: 8.0795e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5960e-08 - accuracy: 1.0000 - val_loss: 6.7907e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.4604e-08 - accuracy: 1.0000 - val_loss: 6.7907e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1768e-08 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.1430e-09 - accuracy: 1.0000 - val_loss: 5.6507e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.6932e-09 - accuracy: 1.0000 - val_loss: 3.8662e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.3309e-09 - accuracy: 1.0000 - val_loss: 2.5775e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.1997e-09 - accuracy: 1.0000 - val_loss: 2.5775e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.1997e-09 - accuracy: 1.0000 - val_loss: 2.5775e-08 - val_accuracy: 1.0000\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "                 * WDOFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_60min/buying2/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/keras_tuner/src/engine/oracle.py:101: DeprecationWarning: currentThread() is deprecated, use current_thread() instead\n",
      "  thread_name = threading.currentThread().getName()\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/keras_tuner/src/engine/oracle.py:101: DeprecationWarning: getName() is deprecated, get the name attribute instead\n",
      "  thread_name = threading.currentThread().getName()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step\n",
      "                 * WDOFUT_F_0_60min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "    | Etapa 5 WDOFUT_F_0_60min - Time: 1854.2084941864014\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "143/143 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "                 * PETR3_B_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying2/tuner0.json\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "                 * PETR3_B_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "    | Etapa 5 PETR3_B_0_30min - Time: 2947.103490114212\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.4936 - val_loss: nan - val_accuracy: 0.4907\n",
      "51/51 [==============================] - 0s 911us/step\n",
      "                 * WINFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "    | ERRO - Etapa 5 WINFUT_F_0_30min (Obtendo ensambles)\n",
      "        - Input X contains NaN.\n",
      "SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5131 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "51/51 [==============================] - 0s 891us/step\n",
      "                 * WDOFUT_F_0_30min - SVR \n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "    | ERRO - Etapa 5 WDOFUT_F_0_30min (Obtendo ensambles)\n",
      "        - Input X contains NaN.\n",
      "SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "dataNames = [\n",
    "    \"PETR3_B_0_60min\",\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "\n",
    "    \"PETR3_B_0_30min\",\n",
    "    \"WINFUT_F_0_30min\",\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 PETR3_B_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 WINFUT_F_0_60min - Obtendo resultados!\n",
      "    | ERRO - Etapa 6 WINFUT_F_0_60min (Obtendo resultados)\n",
      "        - [Errno 2] No such file or directory: '../Results/test/ensamble1/WINFUT_F_0_60min_SVR.csv'\n",
      "    | Etapa 6 WDOFUT_F_0_60min - Obtendo resultados!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 04:18:42.821459: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 04:18:42.878295: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 04:18:42.970410: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 04:18:43.029745: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WDOFUT_F_0_30min - Obtendo resultados!\n",
      "    | ERRO - Etapa 6 WDOFUT_F_0_30min (Obtendo resultados)\n",
      "        - [Errno 2] No such file or directory: '../Results/test/ensamble1/WDOFUT_F_0_30min_SVR.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 04:18:43.938433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-29 04:18:44.092903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 6 PETR3_B_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 WINFUT_F_0_30min - Obtendo resultados!\n",
      "    | ERRO - Etapa 6 WINFUT_F_0_30min (Obtendo resultados)\n",
      "        - [Errno 2] No such file or directory: '../Results/test/ensamble1/WINFUT_F_0_30min_SVR.csv'\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerando estrategias...\n",
      "Files: ['PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'WDOFUT_F_0_60min_predictions.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/classification \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/regression \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_30min_Predictions.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/statistic \n",
      "\n",
      "Files: ['PETR3_B_0_60min_SVR.csv', 'WDOFUT_F_0_60min_SVR.csv', 'WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_30min_SVR.csv', 'PETR3_B_0_5min.csv', 'WDOFUT_F_0_60min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble1 \n",
      "\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_PETR3_B_0_60min_SVR.csv'\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_WDOFUT_F_0_60min_SVR.csv'\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_PETR3_B_0_30min_SVR.csv'\n",
      "Files: ['PETR3_B_0_60min_SVR.csv', 'WDOFUT_F_0_60min_SVR.csv', 'WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_30min_SVR.csv', 'PETR3_B_0_5min.csv', 'WDOFUT_F_0_60min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble2 \n",
      "\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_PETR3_B_0_60min_SVR.csv'\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_WDOFUT_F_0_60min_SVR.csv'\n",
      "Error: [Errno 2] No such file or directory: '../Data/Cut/dataset1/Y/Test_PETR3_B_0_30min_SVR.csv'\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
