{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "dataNames = [\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "    \"WINFUT_F_0_30min\"\n",
    "]\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:34:46.795006: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:47.399790: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:49.222168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getOptmizedModels, trainModels, getEnsambles, getResults, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "dataNames = [\n",
    "    \"PETR3_B_0_60min\",\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "\n",
    "    \"PETR3_B_0_30min\",\n",
    "    \"WINFUT_F_0_30min\",\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "# Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "# commit_and_push(f\"models optimized {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:34:53.775201: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:53.834720: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:34:54.051294: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.127932: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.387254: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.391448: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.450159: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.451497: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:34:54.950742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 16:34:55.541490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 16:34:55.795737: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 16:34:55.823883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 3 PETR3_B_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 PETR3_B_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 WINFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 WDOFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_60min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 PETR3_B_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 4 WINFUT_F_0_60min - Treinando modelos!\n",
      "    | Etapa 4 WDOFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 WDOFUT_F_0_60min - Treinando modelos de classificação\n",
      "        - Etapa 4.1 WINFUT_F_0_60min - Treinando modelos de classificação\n",
      "    | Etapa 4 PETR3_B_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WINFUT_F_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 WDOFUT_F_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 PETR3_B_0_30min - Treinando modelos de regressão\n",
      "22/22 [==============================] - 1s 3ms/step\n",
      "26/26 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 1s 3ms/step\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "22/22 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 1s 2ms/step\n",
      "26/26 [==============================] - 1s 3ms/step\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "        - Etapa 4.3 WDOFUT_F_0_60min - Treinando modelos de estatística\n",
      "        - Etapa 4.3 WINFUT_F_0_60min - Treinando modelos de estatística\n",
      "        - Etapa 4.3 PETR3_B_0_60min - Treinando modelos de estatística\n",
      "168/168 [==============================] - 0s 3ms/step\n",
      "        - Etapa 4.3 PETR3_B_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WINFUT_F_0_60min - Time: 2336.1693210601807\n",
      "    | Etapa 3 WINFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WINFUT_F_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WINFUT_F_0_30min - Treinando modelos de regressão\n",
      "51/51 [==============================] - 1s 2ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 1s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "        - Etapa 4.3 WINFUT_F_0_30min - Treinando modelos de estatística\n",
      "    | Etapa 4 PETR3_B_0_60min - Time: 2817.1325895786285\n",
      "    | Etapa 3 WDOFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WDOFUT_F_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WDOFUT_F_0_30min - Treinando modelos de regressão\n",
      "51/51 [==============================] - 1s 3ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 1s 3ms/step\n",
      "202/202 [==============================] - 1s 5ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "        - Etapa 4.3 WDOFUT_F_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WDOFUT_F_0_60min - Time: 3674.2729756832123\n",
      "    | Etapa 4 PETR3_B_0_30min - Time: 4443.54642868042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WDOFUT_F_0_30min - Time: 3705.651410341263\n",
      "    | Etapa 4 WINFUT_F_0_30min - Time: 4758.611298561096\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models trained {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 PETR3_B_0_60min - Obtendo ensambles!\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 18:33:20.083670: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 18:33:20.148167: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 18:33:20.587973: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 18:33:20.659956: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 18:33:20.679280: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 18:33:20.751831: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 18:33:21.330423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 18:33:22.073680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 18:33:22.219488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 WDOFUT_F_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 PETR3_B_0_30min - Obtendo ensambles!\n",
      "    | Etapa 5 WINFUT_F_0_60min - Obtendo ensambles!\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.4216 - accuracy: 0.8231 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.9691e-04 - accuracy: 1.0000 - val_loss: 4.4400e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2909e-04 - accuracy: 1.0000 - val_loss: 2.0680e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.9422e-05 - accuracy: 1.0000 - val_loss: 4.0324e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.6360e-05 - accuracy: 1.0000 - val_loss: 1.8287e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3007e-05 - accuracy: 1.0000 - val_loss: 1.2434e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.7192e-05 - accuracy: 1.0000 - val_loss: 9.2574e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3534e-05 - accuracy: 1.0000 - val_loss: 7.3042e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1061e-05 - accuracy: 1.0000 - val_loss: 5.9586e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.2204e-06 - accuracy: 1.0000 - val_loss: 4.9817e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.8028e-06 - accuracy: 1.0000 - val_loss: 4.2418e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.6808e-06 - accuracy: 1.0000 - val_loss: 3.6199e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.7788e-06 - accuracy: 1.0000 - val_loss: 3.1512e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.0439e-06 - accuracy: 1.0000 - val_loss: 2.7456e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.4310e-06 - accuracy: 1.0000 - val_loss: 2.4228e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.9230e-06 - accuracy: 1.0000 - val_loss: 2.1591e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.4905e-06 - accuracy: 1.0000 - val_loss: 1.9079e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1176e-06 - accuracy: 1.0000 - val_loss: 1.7137e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8032e-06 - accuracy: 1.0000 - val_loss: 1.5509e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.5330e-06 - accuracy: 1.0000 - val_loss: 1.4200e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2838e-06 - accuracy: 1.0000 - val_loss: 1.2668e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0767e-06 - accuracy: 1.0000 - val_loss: 1.1517e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.8903e-06 - accuracy: 1.0000 - val_loss: 1.0409e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7291e-06 - accuracy: 1.0000 - val_loss: 9.5774e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5832e-06 - accuracy: 1.0000 - val_loss: 8.8825e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4597e-06 - accuracy: 1.0000 - val_loss: 8.1237e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3376e-06 - accuracy: 1.0000 - val_loss: 7.4607e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2325e-06 - accuracy: 1.0000 - val_loss: 6.9606e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.1389e-06 - accuracy: 1.0000 - val_loss: 6.4344e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0594e-06 - accuracy: 1.0000 - val_loss: 5.9692e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.8669e-07 - accuracy: 1.0000 - val_loss: 5.5738e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.1397e-07 - accuracy: 1.0000 - val_loss: 5.2539e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.5354e-07 - accuracy: 1.0000 - val_loss: 4.9632e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.9584e-07 - accuracy: 1.0000 - val_loss: 4.5329e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.4025e-07 - accuracy: 1.0000 - val_loss: 4.1781e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.9355e-07 - accuracy: 1.0000 - val_loss: 3.8903e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.4686e-07 - accuracy: 1.0000 - val_loss: 3.6722e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.0366e-07 - accuracy: 1.0000 - val_loss: 3.4105e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.6730e-07 - accuracy: 1.0000 - val_loss: 3.1605e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.3130e-07 - accuracy: 1.0000 - val_loss: 2.9279e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.9818e-07 - accuracy: 1.0000 - val_loss: 2.7883e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.7504e-07 - accuracy: 1.0000 - val_loss: 2.6371e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.4675e-07 - accuracy: 1.0000 - val_loss: 2.5208e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.1615e-07 - accuracy: 1.0000 - val_loss: 2.3173e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.9368e-07 - accuracy: 1.0000 - val_loss: 2.1341e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.6997e-07 - accuracy: 1.0000 - val_loss: 1.9975e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.4858e-07 - accuracy: 1.0000 - val_loss: 1.9859e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.3258e-07 - accuracy: 1.0000 - val_loss: 1.8608e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1093e-07 - accuracy: 1.0000 - val_loss: 1.7678e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9715e-07 - accuracy: 1.0000 - val_loss: 1.6777e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7869e-07 - accuracy: 1.0000 - val_loss: 1.5759e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6928e-07 - accuracy: 1.0000 - val_loss: 1.4392e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.5066e-07 - accuracy: 1.0000 - val_loss: 1.3142e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.3549e-07 - accuracy: 1.0000 - val_loss: 1.2880e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2.2926e-07 - accuracy: 1.0000 - val_loss: 1.1950e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1574e-07 - accuracy: 1.0000 - val_loss: 1.1834e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.0802e-07 - accuracy: 1.0000 - val_loss: 1.1485e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.9738e-07 - accuracy: 1.0000 - val_loss: 1.0525e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.8293e-07 - accuracy: 1.0000 - val_loss: 1.0525e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.7845e-07 - accuracy: 1.0000 - val_loss: 9.9438e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.7028e-07 - accuracy: 1.0000 - val_loss: 9.1297e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5675e-07 - accuracy: 1.0000 - val_loss: 8.6936e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4857e-07 - accuracy: 1.0000 - val_loss: 8.6936e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4729e-07 - accuracy: 1.0000 - val_loss: 8.5773e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.3813e-07 - accuracy: 1.0000 - val_loss: 7.7341e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2620e-07 - accuracy: 1.0000 - val_loss: 7.7341e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.2127e-07 - accuracy: 1.0000 - val_loss: 7.3270e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.1330e-07 - accuracy: 1.0000 - val_loss: 6.6873e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1.0815e-07 - accuracy: 1.0000 - val_loss: 6.6873e-08 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 0.3063 - accuracy: 0.9181 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.6585e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.8372e-04 - accuracy: 1.0000 - val_loss: 1.3750e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.7099e-04 - accuracy: 1.0000 - val_loss: 6.8179e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.5562e-05 - accuracy: 1.0000 - val_loss: 3.9464e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.0638e-05 - accuracy: 1.0000 - val_loss: 2.5741e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.1818e-05 - accuracy: 1.0000 - val_loss: 1.8142e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0419e-05 - accuracy: 1.0000 - val_loss: 1.3366e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3084e-05 - accuracy: 1.0000 - val_loss: 1.0217e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.8093e-05 - accuracy: 1.0000 - val_loss: 8.0717e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4528e-05 - accuracy: 1.0000 - val_loss: 6.5156e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1886e-05 - accuracy: 1.0000 - val_loss: 5.3515e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.8894e-06 - accuracy: 1.0000 - val_loss: 4.4667e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.3394e-06 - accuracy: 1.0000 - val_loss: 3.7713e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 7.1122e-06 - accuracy: 1.0000 - val_loss: 3.2142e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.1318e-06 - accuracy: 1.0000 - val_loss: 2.7676e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.3259e-06 - accuracy: 1.0000 - val_loss: 2.4147e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.6540e-06 - accuracy: 1.0000 - val_loss: 2.1066e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.1040e-06 - accuracy: 1.0000 - val_loss: 1.8508e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6321e-06 - accuracy: 1.0000 - val_loss: 1.6283e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.2333e-06 - accuracy: 1.0000 - val_loss: 1.4548e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.8985e-06 - accuracy: 1.0000 - val_loss: 1.3063e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.6077e-06 - accuracy: 1.0000 - val_loss: 1.1579e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3452e-06 - accuracy: 1.0000 - val_loss: 1.0397e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.1206e-06 - accuracy: 1.0000 - val_loss: 9.3657e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.9286e-06 - accuracy: 1.0000 - val_loss: 8.5850e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7589e-06 - accuracy: 1.0000 - val_loss: 7.8093e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6056e-06 - accuracy: 1.0000 - val_loss: 7.0732e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4659e-06 - accuracy: 1.0000 - val_loss: 6.4685e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.3455e-06 - accuracy: 1.0000 - val_loss: 5.9431e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2403e-06 - accuracy: 1.0000 - val_loss: 5.4251e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1387e-06 - accuracy: 1.0000 - val_loss: 5.0782e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0484e-06 - accuracy: 1.0000 - val_loss: 4.4586e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.6650e-07 - accuracy: 1.0000 - val_loss: 3.9530e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.8602e-07 - accuracy: 1.0000 - val_loss: 3.6804e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.1919e-07 - accuracy: 1.0000 - val_loss: 3.4325e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.6786e-07 - accuracy: 1.0000 - val_loss: 3.2392e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.0602e-07 - accuracy: 1.0000 - val_loss: 2.9790e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.6230e-07 - accuracy: 1.0000 - val_loss: 2.7014e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.1508e-07 - accuracy: 1.0000 - val_loss: 2.5378e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.7141e-07 - accuracy: 1.0000 - val_loss: 2.2999e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.2821e-07 - accuracy: 1.0000 - val_loss: 2.2404e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.9819e-07 - accuracy: 1.0000 - val_loss: 2.1686e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.6432e-07 - accuracy: 1.0000 - val_loss: 2.0025e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.3701e-07 - accuracy: 1.0000 - val_loss: 1.8166e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.1251e-07 - accuracy: 1.0000 - val_loss: 1.6258e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7693e-07 - accuracy: 1.0000 - val_loss: 1.4672e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.5465e-07 - accuracy: 1.0000 - val_loss: 1.3507e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.3268e-07 - accuracy: 1.0000 - val_loss: 1.3259e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.1190e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.8643e-07 - accuracy: 1.0000 - val_loss: 1.1277e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7531e-07 - accuracy: 1.0000 - val_loss: 1.0310e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 2.6279e-07 - accuracy: 1.0000 - val_loss: 9.6160e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 2.4560e-07 - accuracy: 1.0000 - val_loss: 9.1947e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3382e-07 - accuracy: 1.0000 - val_loss: 7.9803e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.1343e-07 - accuracy: 1.0000 - val_loss: 7.1625e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.9540e-07 - accuracy: 1.0000 - val_loss: 6.4685e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.8525e-07 - accuracy: 1.0000 - val_loss: 6.4685e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7488e-07 - accuracy: 1.0000 - val_loss: 6.2455e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6687e-07 - accuracy: 1.0000 - val_loss: 6.2455e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6118e-07 - accuracy: 1.0000 - val_loss: 6.2455e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.5348e-07 - accuracy: 1.0000 - val_loss: 6.1463e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.4809e-07 - accuracy: 1.0000 - val_loss: 5.3037e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2643e-07 - accuracy: 1.0000 - val_loss: 3.8662e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1339e-07 - accuracy: 1.0000 - val_loss: 3.7671e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0621e-07 - accuracy: 1.0000 - val_loss: 3.7671e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0411e-07 - accuracy: 1.0000 - val_loss: 3.3706e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0009e-07 - accuracy: 1.0000 - val_loss: 3.3706e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.5840e-08 - accuracy: 1.0000 - val_loss: 3.0980e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 9.0895e-08 - accuracy: 1.0000 - val_loss: 2.4288e-08 - val_accuracy: 1.0000\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 7ms/step - loss: 0.6422 - accuracy: 0.9684 - val_loss: 0.5994 - val_accuracy: 0.9896\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.9982 - val_loss: 0.4322 - val_accuracy: 0.9896\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.9989 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5840e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.8228e-04 - accuracy: 1.0000 - val_loss: 9.7103e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.4883e-04 - accuracy: 1.0000 - val_loss: 8.2144e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.4520e-04 - accuracy: 1.0000 - val_loss: 7.0239e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.6342e-04 - accuracy: 1.0000 - val_loss: 6.0451e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.9733e-04 - accuracy: 1.0000 - val_loss: 5.2741e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.4093e-04 - accuracy: 1.0000 - val_loss: 4.5356e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.7207e-04 - accuracy: 1.0000 - val_loss: 3.3630e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.0464e-04 - accuracy: 1.0000 - val_loss: 2.6349e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6184e-04 - accuracy: 1.0000 - val_loss: 2.1485e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3155e-04 - accuracy: 1.0000 - val_loss: 1.7837e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0919e-04 - accuracy: 1.0000 - val_loss: 1.5065e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.1967e-05 - accuracy: 1.0000 - val_loss: 1.2932e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 7.8455e-05 - accuracy: 1.0000 - val_loss: 1.1225e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.7562e-05 - accuracy: 1.0000 - val_loss: 9.8326e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.8727e-05 - accuracy: 1.0000 - val_loss: 8.6439e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.1369e-05 - accuracy: 1.0000 - val_loss: 7.7081e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.5256e-05 - accuracy: 1.0000 - val_loss: 6.8584e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.0099e-05 - accuracy: 1.0000 - val_loss: 6.1377e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5683e-05 - accuracy: 1.0000 - val_loss: 5.5239e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.1899e-05 - accuracy: 1.0000 - val_loss: 5.0169e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.8634e-05 - accuracy: 1.0000 - val_loss: 4.5156e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.5779e-05 - accuracy: 1.0000 - val_loss: 4.1166e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3298e-05 - accuracy: 1.0000 - val_loss: 3.7549e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.1119e-05 - accuracy: 1.0000 - val_loss: 3.4367e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.9202e-05 - accuracy: 1.0000 - val_loss: 3.1528e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7505e-05 - accuracy: 1.0000 - val_loss: 2.9025e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6002e-05 - accuracy: 1.0000 - val_loss: 2.6740e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.4642e-05 - accuracy: 1.0000 - val_loss: 2.4739e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3432e-05 - accuracy: 1.0000 - val_loss: 2.2928e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2354e-05 - accuracy: 1.0000 - val_loss: 2.1174e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1366e-05 - accuracy: 1.0000 - val_loss: 1.9663e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0484e-05 - accuracy: 1.0000 - val_loss: 1.8301e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.6821e-06 - accuracy: 1.0000 - val_loss: 1.7059e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.9577e-06 - accuracy: 1.0000 - val_loss: 1.5862e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.2971e-06 - accuracy: 1.0000 - val_loss: 1.4756e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.6879e-06 - accuracy: 1.0000 - val_loss: 1.3832e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.1440e-06 - accuracy: 1.0000 - val_loss: 1.2895e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.6403e-06 - accuracy: 1.0000 - val_loss: 1.2072e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.1780e-06 - accuracy: 1.0000 - val_loss: 1.1318e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.7517e-06 - accuracy: 1.0000 - val_loss: 1.0617e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.3661e-06 - accuracy: 1.0000 - val_loss: 9.9664e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.0031e-06 - accuracy: 1.0000 - val_loss: 9.3580e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.6722e-06 - accuracy: 1.0000 - val_loss: 8.8089e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.3679e-06 - accuracy: 1.0000 - val_loss: 8.2481e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.0810e-06 - accuracy: 1.0000 - val_loss: 7.7704e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.8194e-06 - accuracy: 1.0000 - val_loss: 7.3196e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.5827e-06 - accuracy: 1.0000 - val_loss: 6.8909e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.3558e-06 - accuracy: 1.0000 - val_loss: 6.5132e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.1463e-06 - accuracy: 1.0000 - val_loss: 6.1336e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.9540e-06 - accuracy: 1.0000 - val_loss: 5.7971e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7708e-06 - accuracy: 1.0000 - val_loss: 5.4908e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.6086e-06 - accuracy: 1.0000 - val_loss: 5.1788e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.4469e-06 - accuracy: 1.0000 - val_loss: 4.8745e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3059e-06 - accuracy: 1.0000 - val_loss: 4.6234e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.1693e-06 - accuracy: 1.0000 - val_loss: 4.3818e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0421e-06 - accuracy: 1.0000 - val_loss: 4.1221e-06 - val_accuracy: 1.0000\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 0.4791 - accuracy: 0.8723 - val_loss: 0.6845 - val_accuracy: 0.7390\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9715 - val_loss: 0.4384 - val_accuracy: 0.6732\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 0.2473 - val_accuracy: 0.8366\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.1623 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.1086 - val_accuracy: 0.9878\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0508 - val_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.0327 - val_accuracy: 0.9951\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0581 - val_accuracy: 0.9878\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9951\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.4402e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.9368e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.5178e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.9662e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.1924e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7574e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4512e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2151e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.0624e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.5084e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.9971e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.7305e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.9688e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.2680e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.8910e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.1214e-05 - accuracy: 1.0000 - val_loss: 9.5855e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.6273e-05 - accuracy: 1.0000 - val_loss: 8.6687e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.3086e-05 - accuracy: 1.0000 - val_loss: 8.2348e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.9909e-05 - accuracy: 1.0000 - val_loss: 7.7480e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7315e-05 - accuracy: 1.0000 - val_loss: 6.8465e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4630e-05 - accuracy: 1.0000 - val_loss: 7.0962e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2338e-05 - accuracy: 1.0000 - val_loss: 5.9374e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0887e-05 - accuracy: 1.0000 - val_loss: 6.0532e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1.9500e-05 - accuracy: 1.0000 - val_loss: 5.4004e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.7526e-05 - accuracy: 1.0000 - val_loss: 5.2275e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.6062e-05 - accuracy: 1.0000 - val_loss: 4.6890e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4724e-05 - accuracy: 1.0000 - val_loss: 4.4711e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3667e-05 - accuracy: 1.0000 - val_loss: 4.3561e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2531e-05 - accuracy: 1.0000 - val_loss: 4.0149e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2112e-05 - accuracy: 1.0000 - val_loss: 3.9329e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.0834e-05 - accuracy: 1.0000 - val_loss: 3.6121e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0164e-05 - accuracy: 1.0000 - val_loss: 3.3646e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.4620e-06 - accuracy: 1.0000 - val_loss: 3.3428e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.9274e-06 - accuracy: 1.0000 - val_loss: 2.9651e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.8445e-06 - accuracy: 1.0000 - val_loss: 2.9146e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.7116e-06 - accuracy: 1.0000 - val_loss: 2.6510e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.3273e-06 - accuracy: 1.0000 - val_loss: 2.5316e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.7855e-06 - accuracy: 1.0000 - val_loss: 2.3888e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.3643e-06 - accuracy: 1.0000 - val_loss: 2.4204e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.0619e-06 - accuracy: 1.0000 - val_loss: 2.3235e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.5962e-06 - accuracy: 1.0000 - val_loss: 2.1597e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.2530e-06 - accuracy: 1.0000 - val_loss: 2.0157e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.8839e-06 - accuracy: 1.0000 - val_loss: 1.9921e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.6271e-06 - accuracy: 1.0000 - val_loss: 1.8991e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4.4137e-06 - accuracy: 1.0000 - val_loss: 1.8683e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.1311e-06 - accuracy: 1.0000 - val_loss: 1.7548e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.9037e-06 - accuracy: 1.0000 - val_loss: 1.6794e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7172e-06 - accuracy: 1.0000 - val_loss: 1.5977e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.4627e-06 - accuracy: 1.0000 - val_loss: 1.5667e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2946e-06 - accuracy: 1.0000 - val_loss: 1.5548e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.1221e-06 - accuracy: 1.0000 - val_loss: 1.4556e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.9493e-06 - accuracy: 1.0000 - val_loss: 1.3882e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.8096e-06 - accuracy: 1.0000 - val_loss: 1.3548e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6267e-06 - accuracy: 1.0000 - val_loss: 1.3109e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2.5230e-06 - accuracy: 1.0000 - val_loss: 1.2525e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.4009e-06 - accuracy: 1.0000 - val_loss: 1.1723e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2.2673e-06 - accuracy: 1.0000 - val_loss: 1.2789e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2.1409e-06 - accuracy: 1.0000 - val_loss: 1.1500e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.0191e-06 - accuracy: 1.0000 - val_loss: 1.1158e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.9038e-06 - accuracy: 1.0000 - val_loss: 1.0282e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8319e-06 - accuracy: 1.0000 - val_loss: 1.0864e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7221e-06 - accuracy: 1.0000 - val_loss: 9.8467e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6319e-06 - accuracy: 1.0000 - val_loss: 9.4488e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.5632e-06 - accuracy: 1.0000 - val_loss: 9.1264e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4956e-06 - accuracy: 1.0000 - val_loss: 9.6573e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4193e-06 - accuracy: 1.0000 - val_loss: 8.7633e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.3449e-06 - accuracy: 1.0000 - val_loss: 8.6928e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.2888e-06 - accuracy: 1.0000 - val_loss: 8.2070e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1.2154e-06 - accuracy: 1.0000 - val_loss: 8.0799e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1579e-06 - accuracy: 1.0000 - val_loss: 7.5937e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0958e-06 - accuracy: 1.0000 - val_loss: 7.7101e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.0503e-06 - accuracy: 1.0000 - val_loss: 7.1714e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.9613e-07 - accuracy: 1.0000 - val_loss: 7.2234e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.4481e-07 - accuracy: 1.0000 - val_loss: 6.8768e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9.0892e-07 - accuracy: 1.0000 - val_loss: 7.0753e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8.6892e-07 - accuracy: 1.0000 - val_loss: 6.5753e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.3389e-07 - accuracy: 1.0000 - val_loss: 6.7079e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.8572e-07 - accuracy: 1.0000 - val_loss: 6.3055e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.4766e-07 - accuracy: 1.0000 - val_loss: 6.2790e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.1321e-07 - accuracy: 1.0000 - val_loss: 5.9510e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.8097e-07 - accuracy: 1.0000 - val_loss: 5.6316e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.4513e-07 - accuracy: 1.0000 - val_loss: 5.6286e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.1751e-07 - accuracy: 1.0000 - val_loss: 5.5083e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.8697e-07 - accuracy: 1.0000 - val_loss: 5.2551e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.6059e-07 - accuracy: 1.0000 - val_loss: 5.2979e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.3565e-07 - accuracy: 1.0000 - val_loss: 4.9880e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.1019e-07 - accuracy: 1.0000 - val_loss: 4.8448e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.8422e-07 - accuracy: 1.0000 - val_loss: 4.8848e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.6273e-07 - accuracy: 1.0000 - val_loss: 4.6858e-05 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 PETR3_B_0_60min - Time: 5255.478765487671\n",
      "    | Etapa 5 WINFUT_F_0_30min - Obtendo ensambles!\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 7ms/step - loss: 0.1699 - accuracy: 0.9174 - val_loss: 7.7310e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.8836e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1699e-05 - accuracy: 1.0000 - val_loss: 1.4382e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.6342e-06 - accuracy: 1.0000 - val_loss: 1.1108e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.4748e-06 - accuracy: 1.0000 - val_loss: 8.7596e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.8700e-06 - accuracy: 1.0000 - val_loss: 6.9344e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7674e-06 - accuracy: 1.0000 - val_loss: 5.5275e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.9447e-06 - accuracy: 1.0000 - val_loss: 4.4567e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3581e-06 - accuracy: 1.0000 - val_loss: 3.6463e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.9128e-06 - accuracy: 1.0000 - val_loss: 3.0347e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.5712e-06 - accuracy: 1.0000 - val_loss: 2.5400e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3052e-06 - accuracy: 1.0000 - val_loss: 2.1247e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0916e-06 - accuracy: 1.0000 - val_loss: 1.8127e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.1984e-07 - accuracy: 1.0000 - val_loss: 1.5361e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.6925e-07 - accuracy: 1.0000 - val_loss: 1.3242e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 6.6339e-07 - accuracy: 1.0000 - val_loss: 1.1472e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.6873e-07 - accuracy: 1.0000 - val_loss: 9.9902e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.9259e-07 - accuracy: 1.0000 - val_loss: 8.7114e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.3010e-07 - accuracy: 1.0000 - val_loss: 7.6408e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7277e-07 - accuracy: 1.0000 - val_loss: 6.7560e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.2857e-07 - accuracy: 1.0000 - val_loss: 6.0125e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.9036e-07 - accuracy: 1.0000 - val_loss: 5.3433e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.5885e-07 - accuracy: 1.0000 - val_loss: 4.8179e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3220e-07 - accuracy: 1.0000 - val_loss: 4.3322e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.0590e-07 - accuracy: 1.0000 - val_loss: 3.9183e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.8805e-07 - accuracy: 1.0000 - val_loss: 3.5639e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7054e-07 - accuracy: 1.0000 - val_loss: 3.2714e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.5606e-07 - accuracy: 1.0000 - val_loss: 2.9592e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4280e-07 - accuracy: 1.0000 - val_loss: 2.7039e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2726e-07 - accuracy: 1.0000 - val_loss: 2.4908e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1413e-07 - accuracy: 1.0000 - val_loss: 2.2528e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.0345e-07 - accuracy: 1.0000 - val_loss: 2.0694e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 9.5096e-08 - accuracy: 1.0000 - val_loss: 1.9480e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.6562e-08 - accuracy: 1.0000 - val_loss: 1.7919e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.9517e-08 - accuracy: 1.0000 - val_loss: 1.6432e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.4002e-08 - accuracy: 1.0000 - val_loss: 1.5638e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.9539e-08 - accuracy: 1.0000 - val_loss: 1.4424e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.3368e-08 - accuracy: 1.0000 - val_loss: 1.3334e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.8817e-08 - accuracy: 1.0000 - val_loss: 1.2119e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.4878e-08 - accuracy: 1.0000 - val_loss: 1.1574e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.1465e-08 - accuracy: 1.0000 - val_loss: 1.0855e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.8576e-08 - accuracy: 1.0000 - val_loss: 1.0112e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.5776e-08 - accuracy: 1.0000 - val_loss: 9.6160e-08 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.2625e-08 - accuracy: 1.0000 - val_loss: 8.7734e-08 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.9299e-08 - accuracy: 1.0000 - val_loss: 8.2777e-08 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.6367e-08 - accuracy: 1.0000 - val_loss: 8.0547e-08 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.4704e-08 - accuracy: 1.0000 - val_loss: 7.3360e-08 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.3172e-08 - accuracy: 1.0000 - val_loss: 6.8403e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.9977e-08 - accuracy: 1.0000 - val_loss: 6.8403e-08 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.8314e-08 - accuracy: 1.0000 - val_loss: 6.1216e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.6958e-08 - accuracy: 1.0000 - val_loss: 6.1216e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.5820e-08 - accuracy: 1.0000 - val_loss: 5.4028e-08 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 2.3938e-08 - accuracy: 1.0000 - val_loss: 5.4028e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3938e-08 - accuracy: 1.0000 - val_loss: 4.9072e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.0525e-08 - accuracy: 1.0000 - val_loss: 4.6593e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.8380e-08 - accuracy: 1.0000 - val_loss: 4.3124e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.7899e-08 - accuracy: 1.0000 - val_loss: 3.8167e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.5623e-08 - accuracy: 1.0000 - val_loss: 3.8167e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.5623e-08 - accuracy: 1.0000 - val_loss: 3.8167e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.5361e-08 - accuracy: 1.0000 - val_loss: 3.5936e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3741e-08 - accuracy: 1.0000 - val_loss: 3.0980e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.2560e-08 - accuracy: 1.0000 - val_loss: 3.0980e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.2560e-08 - accuracy: 1.0000 - val_loss: 3.0980e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.2560e-08 - accuracy: 1.0000 - val_loss: 2.8749e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1903e-08 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5402e-09 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5402e-09 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5402e-09 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5402e-09 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.5402e-09 - accuracy: 1.0000 - val_loss: 2.3792e-08 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.1026e-09 - accuracy: 1.0000 - val_loss: 2.1562e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.7394e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.5206e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 6.5206e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 6.5206e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.5206e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.5206e-09 - accuracy: 1.0000 - val_loss: 1.6605e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.3456e-09 - accuracy: 1.0000 - val_loss: 1.4375e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.0392e-09 - accuracy: 1.0000 - val_loss: 1.4375e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.4266e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5010e-09 - accuracy: 1.0000 - val_loss: 9.4178e-09 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0196e-09 - accuracy: 1.0000 - val_loss: 7.1873e-09 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.5382e-09 - accuracy: 1.0000 - val_loss: 2.2305e-09 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.8139e-10 - accuracy: 1.0000 - val_loss: 2.2305e-09 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.8139e-10 - accuracy: 1.0000 - val_loss: 2.2305e-09 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.8139e-10 - accuracy: 1.0000 - val_loss: 2.2305e-09 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.8139e-10 - accuracy: 1.0000 - val_loss: 2.2305e-09 - val_accuracy: 1.0000\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 WINFUT_F_0_60min - Time: 5986.916589975357\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Obtendo ensambles!\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 8ms/step - loss: 0.6630 - accuracy: 0.5428 - val_loss: 0.6499 - val_accuracy: 0.5447\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6741 - val_loss: 0.6059 - val_accuracy: 0.5759\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.8683 - val_loss: 0.5438 - val_accuracy: 0.7069\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.9585 - val_loss: 0.4470 - val_accuracy: 0.7588\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9717 - val_loss: 0.3426 - val_accuracy: 0.8378\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.1669 - accuracy: 0.9765 - val_loss: 0.2488 - val_accuracy: 0.9168\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9890 - val_loss: 0.2063 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9916 - val_loss: 0.1533 - val_accuracy: 0.9314\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9919 - val_loss: 0.1364 - val_accuracy: 0.9459\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9945 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9967 - val_loss: 0.0879 - val_accuracy: 0.9667\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.0871 - val_accuracy: 0.9667\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.0625 - val_accuracy: 0.9667\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0454 - val_accuracy: 0.9667\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0476 - val_accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0404 - val_accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9958\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0235 - val_accuracy: 0.9958\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0214 - val_accuracy: 0.9958\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0166 - val_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0128 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0107 - val_accuracy: 0.9979\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.9141e-04 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.8905e-04 - accuracy: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.1161e-04 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.4482e-04 - accuracy: 0.9996 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.7555e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.1889e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.5493e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.1124e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.6684e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.2992e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.9018e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.6076e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.2769e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.0550e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7644e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.5641e-04 - accuracy: 1.0000 - val_loss: 9.5439e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3447e-04 - accuracy: 1.0000 - val_loss: 9.0232e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.1967e-04 - accuracy: 1.0000 - val_loss: 8.0510e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: 7.3217e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.7863e-04 - accuracy: 1.0000 - val_loss: 6.5615e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6450e-04 - accuracy: 1.0000 - val_loss: 6.0123e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.5177e-04 - accuracy: 1.0000 - val_loss: 5.5812e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4068e-04 - accuracy: 1.0000 - val_loss: 5.3621e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.3075e-04 - accuracy: 1.0000 - val_loss: 5.1346e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.2002e-04 - accuracy: 1.0000 - val_loss: 4.3252e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1174e-04 - accuracy: 1.0000 - val_loss: 4.0710e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0406e-04 - accuracy: 1.0000 - val_loss: 3.7769e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 9.6859e-05 - accuracy: 1.0000 - val_loss: 3.5003e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.0070e-05 - accuracy: 1.0000 - val_loss: 3.3691e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 8.4307e-05 - accuracy: 1.0000 - val_loss: 3.1886e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.9913e-05 - accuracy: 1.0000 - val_loss: 3.0232e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.3863e-05 - accuracy: 1.0000 - val_loss: 2.7523e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.9320e-05 - accuracy: 1.0000 - val_loss: 2.6293e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 6.5366e-05 - accuracy: 1.0000 - val_loss: 2.4831e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 6.1659e-05 - accuracy: 1.0000 - val_loss: 2.3250e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.7585e-05 - accuracy: 1.0000 - val_loss: 2.1962e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 5.4033e-05 - accuracy: 1.0000 - val_loss: 2.1166e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 5.1127e-05 - accuracy: 1.0000 - val_loss: 1.9389e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.7892e-05 - accuracy: 1.0000 - val_loss: 1.8616e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 4.5215e-05 - accuracy: 1.0000 - val_loss: 1.7254e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 4.2816e-05 - accuracy: 1.0000 - val_loss: 1.6261e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.9970e-05 - accuracy: 1.0000 - val_loss: 1.5541e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.7726e-05 - accuracy: 1.0000 - val_loss: 1.4629e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.5656e-05 - accuracy: 1.0000 - val_loss: 1.3780e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.3722e-05 - accuracy: 1.0000 - val_loss: 1.2921e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 3.1687e-05 - accuracy: 1.0000 - val_loss: 1.2106e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.9964e-05 - accuracy: 1.0000 - val_loss: 1.2040e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.8211e-05 - accuracy: 1.0000 - val_loss: 1.0663e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.6597e-05 - accuracy: 1.0000 - val_loss: 1.0052e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.5155e-05 - accuracy: 1.0000 - val_loss: 9.6221e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3771e-05 - accuracy: 1.0000 - val_loss: 9.0756e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.2434e-05 - accuracy: 1.0000 - val_loss: 8.5302e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.1183e-05 - accuracy: 1.0000 - val_loss: 8.0725e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.0052e-05 - accuracy: 1.0000 - val_loss: 7.6197e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.8895e-05 - accuracy: 1.0000 - val_loss: 7.2892e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7897e-05 - accuracy: 1.0000 - val_loss: 6.8595e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.6920e-05 - accuracy: 1.0000 - val_loss: 6.5153e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.5990e-05 - accuracy: 1.0000 - val_loss: 6.1372e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.5106e-05 - accuracy: 1.0000 - val_loss: 5.7596e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.4254e-05 - accuracy: 1.0000 - val_loss: 5.3775e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3292e-05 - accuracy: 1.0000 - val_loss: 5.0645e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2464e-05 - accuracy: 1.0000 - val_loss: 4.7467e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1656e-05 - accuracy: 1.0000 - val_loss: 4.3965e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0974e-05 - accuracy: 1.0000 - val_loss: 4.1498e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0284e-05 - accuracy: 1.0000 - val_loss: 3.8827e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.6581e-06 - accuracy: 1.0000 - val_loss: 3.6906e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 9.0667e-06 - accuracy: 1.0000 - val_loss: 3.3880e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 8.5019e-06 - accuracy: 1.0000 - val_loss: 3.2005e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 7.9873e-06 - accuracy: 1.0000 - val_loss: 3.0271e-05 - val_accuracy: 1.0000\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 WDOFUT_F_0_60min - Time: 6105.650656223297\n",
      "Epoch 1/70\n",
      "143/143 [==============================] - 2s 5ms/step - loss: 0.6311 - accuracy: 0.6694 - val_loss: 0.6243 - val_accuracy: 0.6683\n",
      "Epoch 2/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6817 - val_loss: 0.6205 - val_accuracy: 0.6683\n",
      "Epoch 3/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6837 - val_loss: 0.6346 - val_accuracy: 0.6733\n",
      "Epoch 4/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6826 - val_loss: 0.6220 - val_accuracy: 0.6683\n",
      "Epoch 5/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6870 - val_loss: 0.6196 - val_accuracy: 0.6683\n",
      "Epoch 6/70\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6101 - accuracy: 0.6857 - val_loss: 0.6161 - val_accuracy: 0.6683\n",
      "Epoch 7/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6852 - val_loss: 0.6149 - val_accuracy: 0.6683\n",
      "Epoch 8/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6839 - val_loss: 0.6130 - val_accuracy: 0.6683\n",
      "Epoch 9/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6828 - val_loss: 0.6173 - val_accuracy: 0.6683\n",
      "Epoch 10/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6870 - val_loss: 0.6156 - val_accuracy: 0.6683\n",
      "Epoch 11/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6861 - val_loss: 0.6170 - val_accuracy: 0.6683\n",
      "Epoch 12/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6861 - val_loss: 0.6139 - val_accuracy: 0.6683\n",
      "Epoch 13/70\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.6857 - val_loss: 0.6117 - val_accuracy: 0.6683\n",
      "Epoch 14/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6857 - val_loss: 0.6143 - val_accuracy: 0.6683\n",
      "Epoch 15/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6870 - val_loss: 0.6136 - val_accuracy: 0.6683\n",
      "Epoch 16/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6863 - val_loss: 0.6130 - val_accuracy: 0.6683\n",
      "Epoch 17/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6870 - val_loss: 0.6224 - val_accuracy: 0.6683\n",
      "Epoch 18/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6870 - val_loss: 0.6128 - val_accuracy: 0.6683\n",
      "Epoch 19/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6877 - val_loss: 0.6121 - val_accuracy: 0.6683\n",
      "Epoch 20/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6850 - val_loss: 0.6163 - val_accuracy: 0.6683\n",
      "Epoch 21/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6824 - val_loss: 0.6235 - val_accuracy: 0.6683\n",
      "Epoch 22/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6822 - val_loss: 0.6149 - val_accuracy: 0.6683\n",
      "Epoch 23/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6852 - val_loss: 0.6138 - val_accuracy: 0.6683\n",
      "Epoch 24/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6835 - val_loss: 0.6118 - val_accuracy: 0.6683\n",
      "Epoch 25/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6870 - val_loss: 0.6099 - val_accuracy: 0.6683\n",
      "Epoch 26/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6870 - val_loss: 0.6114 - val_accuracy: 0.6683\n",
      "Epoch 27/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6870 - val_loss: 0.6120 - val_accuracy: 0.6683\n",
      "Epoch 28/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6861 - val_loss: 0.6108 - val_accuracy: 0.6683\n",
      "Epoch 29/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6861 - val_loss: 0.6198 - val_accuracy: 0.6733\n",
      "Epoch 30/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6798 - val_loss: 0.6208 - val_accuracy: 0.6683\n",
      "Epoch 31/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6870 - val_loss: 0.6122 - val_accuracy: 0.6683\n",
      "Epoch 32/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6870 - val_loss: 0.6130 - val_accuracy: 0.6683\n",
      "Epoch 33/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6837 - val_loss: 0.6218 - val_accuracy: 0.6683\n",
      "Epoch 34/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6870 - val_loss: 0.6250 - val_accuracy: 0.6683\n",
      "Epoch 35/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6870 - val_loss: 0.6219 - val_accuracy: 0.6683\n",
      "Epoch 36/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6870 - val_loss: 0.6204 - val_accuracy: 0.6683\n",
      "Epoch 37/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6870 - val_loss: 0.6218 - val_accuracy: 0.6683\n",
      "Epoch 38/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6870 - val_loss: 0.6218 - val_accuracy: 0.6683\n",
      "Epoch 39/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6870 - val_loss: 0.6242 - val_accuracy: 0.6683\n",
      "Epoch 40/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6863 - val_loss: 0.6212 - val_accuracy: 0.6683\n",
      "Epoch 41/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6870 - val_loss: 0.6205 - val_accuracy: 0.6683\n",
      "Epoch 42/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6870 - val_loss: 0.6269 - val_accuracy: 0.6683\n",
      "Epoch 43/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6870 - val_loss: 0.6221 - val_accuracy: 0.6683\n",
      "Epoch 44/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6870 - val_loss: 0.6234 - val_accuracy: 0.6683\n",
      "Epoch 45/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6870 - val_loss: 0.6311 - val_accuracy: 0.6683\n",
      "Epoch 46/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6870 - val_loss: 0.6246 - val_accuracy: 0.6683\n",
      "Epoch 47/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6870 - val_loss: 0.6202 - val_accuracy: 0.6683\n",
      "Epoch 48/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6870 - val_loss: 0.6226 - val_accuracy: 0.6683\n",
      "Epoch 49/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6870 - val_loss: 0.6234 - val_accuracy: 0.6683\n",
      "Epoch 50/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6870 - val_loss: 0.6225 - val_accuracy: 0.6683\n",
      "Epoch 51/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6863 - val_loss: 0.6317 - val_accuracy: 0.6683\n",
      "Epoch 52/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6870 - val_loss: 0.6214 - val_accuracy: 0.6683\n",
      "Epoch 53/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6870 - val_loss: 0.6216 - val_accuracy: 0.6683\n",
      "Epoch 54/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6870 - val_loss: 0.6257 - val_accuracy: 0.6683\n",
      "Epoch 55/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6870 - val_loss: 0.6300 - val_accuracy: 0.6683\n",
      "Epoch 56/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6870 - val_loss: 0.6209 - val_accuracy: 0.6683\n",
      "Epoch 57/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6870 - val_loss: 0.6250 - val_accuracy: 0.6683\n",
      "Epoch 58/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6767 - val_loss: 0.6294 - val_accuracy: 0.6571\n",
      "Epoch 59/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6646 - val_loss: 0.6269 - val_accuracy: 0.6571\n",
      "Epoch 60/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6646 - val_loss: 0.6320 - val_accuracy: 0.6571\n",
      "Epoch 61/70\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6646 - val_loss: 0.6268 - val_accuracy: 0.6571\n",
      "Epoch 62/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6646 - val_loss: 0.6289 - val_accuracy: 0.6571\n",
      "Epoch 63/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6646 - val_loss: 0.6270 - val_accuracy: 0.6571\n",
      "Epoch 64/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6646 - val_loss: 0.6269 - val_accuracy: 0.6571\n",
      "Epoch 65/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6646 - val_loss: 0.6289 - val_accuracy: 0.6571\n",
      "Epoch 66/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6646 - val_loss: 0.6267 - val_accuracy: 0.6571\n",
      "Epoch 67/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6646 - val_loss: 0.6266 - val_accuracy: 0.6571\n",
      "Epoch 68/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6646 - val_loss: 0.6267 - val_accuracy: 0.6571\n",
      "Epoch 69/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6646 - val_loss: 0.6310 - val_accuracy: 0.6571\n",
      "Epoch 70/70\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6646 - val_loss: 0.6284 - val_accuracy: 0.6571\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 5ms/step - loss: 0.6422 - accuracy: 0.6473 - val_loss: 0.6337 - val_accuracy: 0.6547\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6819 - val_loss: 0.6279 - val_accuracy: 0.6621\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6809 - val_loss: 0.6308 - val_accuracy: 0.6522\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6835 - val_loss: 0.6356 - val_accuracy: 0.6472\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6866 - val_loss: 0.6269 - val_accuracy: 0.6571\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6872 - val_loss: 0.6309 - val_accuracy: 0.6472\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6863 - val_loss: 0.6388 - val_accuracy: 0.6584\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6850 - val_loss: 0.6236 - val_accuracy: 0.6509\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6879 - val_loss: 0.6244 - val_accuracy: 0.6584\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6846 - val_loss: 0.6262 - val_accuracy: 0.6584\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6852 - val_loss: 0.6241 - val_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.6852 - val_loss: 0.6226 - val_accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6868 - val_loss: 0.6201 - val_accuracy: 0.6559\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.6866 - val_loss: 0.6203 - val_accuracy: 0.6634\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6868 - val_loss: 0.6182 - val_accuracy: 0.6609\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6848 - val_loss: 0.6184 - val_accuracy: 0.6534\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6852 - val_loss: 0.6188 - val_accuracy: 0.6534\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6855 - val_loss: 0.6192 - val_accuracy: 0.6609\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6855 - val_loss: 0.6271 - val_accuracy: 0.6571\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6872 - val_loss: 0.6213 - val_accuracy: 0.6596\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6855 - val_loss: 0.6197 - val_accuracy: 0.6596\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6839 - val_loss: 0.6207 - val_accuracy: 0.6584\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6866 - val_loss: 0.6297 - val_accuracy: 0.6584\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6870 - val_loss: 0.6179 - val_accuracy: 0.6621\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6868 - val_loss: 0.6189 - val_accuracy: 0.6621\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6866 - val_loss: 0.6208 - val_accuracy: 0.6671\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6901 - val_loss: 0.6212 - val_accuracy: 0.6621\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6872 - val_loss: 0.6218 - val_accuracy: 0.6658\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6863 - val_loss: 0.6207 - val_accuracy: 0.6621\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6877 - val_loss: 0.6242 - val_accuracy: 0.6584\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6855 - val_loss: 0.6189 - val_accuracy: 0.6646\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6857 - val_loss: 0.6178 - val_accuracy: 0.6671\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6861 - val_loss: 0.6202 - val_accuracy: 0.6658\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.6866 - val_loss: 0.6234 - val_accuracy: 0.6671\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6870 - val_loss: 0.6226 - val_accuracy: 0.6671\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6866 - val_loss: 0.6202 - val_accuracy: 0.6646\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6868 - val_loss: 0.6178 - val_accuracy: 0.6646\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6861 - val_loss: 0.6225 - val_accuracy: 0.6671\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6857 - val_loss: 0.6206 - val_accuracy: 0.6671\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6863 - val_loss: 0.6244 - val_accuracy: 0.6646\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6870 - val_loss: 0.6226 - val_accuracy: 0.6658\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6887 - val_loss: 0.6257 - val_accuracy: 0.6671\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6879 - val_loss: 0.6230 - val_accuracy: 0.6621\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6859 - val_loss: 0.6244 - val_accuracy: 0.6671\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6887 - val_loss: 0.6228 - val_accuracy: 0.6671\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6890 - val_loss: 0.6297 - val_accuracy: 0.6671\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6868 - val_loss: 0.6367 - val_accuracy: 0.6646\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6877 - val_loss: 0.6345 - val_accuracy: 0.6671\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6848 - val_loss: 0.6288 - val_accuracy: 0.6671\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6852 - val_loss: 0.6330 - val_accuracy: 0.6671\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6877 - val_loss: 0.6315 - val_accuracy: 0.6584\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6881 - val_loss: 0.6310 - val_accuracy: 0.6671\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6881 - val_loss: 0.6422 - val_accuracy: 0.6671\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6870 - val_loss: 0.6487 - val_accuracy: 0.6671\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6857 - val_loss: 0.6288 - val_accuracy: 0.6683\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6861 - val_loss: 0.6403 - val_accuracy: 0.6671\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6898 - val_loss: 0.6377 - val_accuracy: 0.6671\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6887 - val_loss: 0.6456 - val_accuracy: 0.6671\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6892 - val_loss: 0.6379 - val_accuracy: 0.6671\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6883 - val_loss: 0.6431 - val_accuracy: 0.6671\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.6890 - val_loss: 0.6434 - val_accuracy: 0.6671\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6890 - val_loss: 0.6383 - val_accuracy: 0.6671\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6881 - val_loss: 0.6421 - val_accuracy: 0.6671\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6885 - val_loss: 0.6498 - val_accuracy: 0.6671\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6885 - val_loss: 0.6429 - val_accuracy: 0.6671\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6885 - val_loss: 0.6444 - val_accuracy: 0.6671\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6887 - val_loss: 0.6559 - val_accuracy: 0.6671\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.6887 - val_loss: 0.6499 - val_accuracy: 0.6484\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6877 - val_loss: 0.6540 - val_accuracy: 0.6484\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6887 - val_loss: 0.6565 - val_accuracy: 0.6671\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6890 - val_loss: 0.6625 - val_accuracy: 0.6671\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6879 - val_loss: 0.6474 - val_accuracy: 0.6484\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6892 - val_loss: 0.6613 - val_accuracy: 0.6671\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6883 - val_loss: 0.6555 - val_accuracy: 0.6671\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6883 - val_loss: 0.6517 - val_accuracy: 0.6634\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6863 - val_loss: 0.6595 - val_accuracy: 0.6671\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6855 - val_loss: 0.6591 - val_accuracy: 0.6634\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6887 - val_loss: 0.6586 - val_accuracy: 0.6671\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6874 - val_loss: 0.6683 - val_accuracy: 0.6671\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6894 - val_loss: 0.6652 - val_accuracy: 0.6671\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6894 - val_loss: 0.6733 - val_accuracy: 0.6671\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6890 - val_loss: 0.6545 - val_accuracy: 0.6671\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.6894 - val_loss: 0.6625 - val_accuracy: 0.6671\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6885 - val_loss: 0.6698 - val_accuracy: 0.6671\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6894 - val_loss: 0.6509 - val_accuracy: 0.6634\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6896 - val_loss: 0.6650 - val_accuracy: 0.6671\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6883 - val_loss: 0.6733 - val_accuracy: 0.6671\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6881 - val_loss: 0.6737 - val_accuracy: 0.6671\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6894 - val_loss: 0.6781 - val_accuracy: 0.6671\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6896 - val_loss: 0.6775 - val_accuracy: 0.6671\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6890 - val_loss: 0.6843 - val_accuracy: 0.6671\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6887 - val_loss: 0.6800 - val_accuracy: 0.6671\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6012 - accuracy: 0.6894 - val_loss: 0.6838 - val_accuracy: 0.6671\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6892 - val_loss: 0.6987 - val_accuracy: 0.6770\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6890 - val_loss: 0.6694 - val_accuracy: 0.6671\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6890 - val_loss: 0.6822 - val_accuracy: 0.6671\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6892 - val_loss: 0.7000 - val_accuracy: 0.6671\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6903 - val_loss: 0.6947 - val_accuracy: 0.6671\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6890 - val_loss: 0.6958 - val_accuracy: 0.6671\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6898 - val_loss: 0.6841 - val_accuracy: 0.6671\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 PETR3_B_0_30min - Time: 9452.600982189178\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 3ms/step - loss: 0.6915 - accuracy: 0.5442 - val_loss: 0.6918 - val_accuracy: 0.5331\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5641 - val_loss: 0.6913 - val_accuracy: 0.5321\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5641 - val_loss: 0.6908 - val_accuracy: 0.5331\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5641 - val_loss: 0.6907 - val_accuracy: 0.5321\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5641 - val_loss: 0.6909 - val_accuracy: 0.5321\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5641 - val_loss: 0.6910 - val_accuracy: 0.5331\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5647 - val_loss: 0.6911 - val_accuracy: 0.5321\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5645 - val_loss: 0.6916 - val_accuracy: 0.5331\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5647 - val_loss: 0.6914 - val_accuracy: 0.5331\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5647 - val_loss: 0.6917 - val_accuracy: 0.5331\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5647 - val_loss: 0.6915 - val_accuracy: 0.5331\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6848 - accuracy: 0.5649 - val_loss: 0.6917 - val_accuracy: 0.5331\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6916 - val_accuracy: 0.5331\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5650 - val_loss: 0.6919 - val_accuracy: 0.5331\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5650 - val_loss: 0.6920 - val_accuracy: 0.5331\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5647 - val_loss: 0.6925 - val_accuracy: 0.5331\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5650 - val_loss: 0.6924 - val_accuracy: 0.5331\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6923 - val_accuracy: 0.5331\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6923 - val_accuracy: 0.5331\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6926 - val_accuracy: 0.5331\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6931 - val_accuracy: 0.5331\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6924 - val_accuracy: 0.5331\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6928 - val_accuracy: 0.5331\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6931 - val_accuracy: 0.5331\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6931 - val_accuracy: 0.5331\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6926 - val_accuracy: 0.5331\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6936 - val_accuracy: 0.5331\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6932 - val_accuracy: 0.5331\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6930 - val_accuracy: 0.5331\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6926 - val_accuracy: 0.5331\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6926 - val_accuracy: 0.5331\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5650 - val_loss: 0.6933 - val_accuracy: 0.5331\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6931 - val_accuracy: 0.5331\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6933 - val_accuracy: 0.5331\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6937 - val_accuracy: 0.5331\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6933 - val_accuracy: 0.5331\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6933 - val_accuracy: 0.5331\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6937 - val_accuracy: 0.5331\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6930 - val_accuracy: 0.5331\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5650 - val_loss: 0.6932 - val_accuracy: 0.5331\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6936 - val_accuracy: 0.5331\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6930 - val_accuracy: 0.5331\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6939 - val_accuracy: 0.5331\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6939 - val_accuracy: 0.5331\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6937 - val_accuracy: 0.5331\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6938 - val_accuracy: 0.5331\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5650 - val_loss: 0.6943 - val_accuracy: 0.5331\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6943 - val_accuracy: 0.5331\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5650 - val_loss: 0.6934 - val_accuracy: 0.5331\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5650 - val_loss: 0.6936 - val_accuracy: 0.5331\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6934 - val_accuracy: 0.5331\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6939 - val_accuracy: 0.5331\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5650 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6932 - val_accuracy: 0.5331\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5650 - val_loss: 0.6935 - val_accuracy: 0.5331\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5650 - val_loss: 0.6936 - val_accuracy: 0.5331\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.6933 - val_accuracy: 0.5331\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5650 - val_loss: 0.6932 - val_accuracy: 0.5331\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5129 - val_loss: nan - val_accuracy: 0.5362\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 2s 3ms/step - loss: 0.6929 - accuracy: 0.5130 - val_loss: 0.6922 - val_accuracy: 0.5383\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5176\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5274 - val_loss: 0.6915 - val_accuracy: 0.5176\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5278 - val_loss: 0.6915 - val_accuracy: 0.5124\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5314 - val_loss: 0.6915 - val_accuracy: 0.5124\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5303 - val_loss: 0.6916 - val_accuracy: 0.5124\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5374 - val_loss: 0.6918 - val_accuracy: 0.5280\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5522 - val_loss: 0.6910 - val_accuracy: 0.5321\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5407 - val_loss: 0.6916 - val_accuracy: 0.5290\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5404 - val_loss: 0.6919 - val_accuracy: 0.5290\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5460 - val_loss: 0.6916 - val_accuracy: 0.5342\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5468 - val_loss: 0.6919 - val_accuracy: 0.5311\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5543 - val_loss: 0.6922 - val_accuracy: 0.5352\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5543 - val_loss: 0.6915 - val_accuracy: 0.5321\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5557 - val_loss: 0.6921 - val_accuracy: 0.5321\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5579 - val_loss: 0.6921 - val_accuracy: 0.5311\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5561 - val_loss: 0.6923 - val_accuracy: 0.5321\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5561 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5597 - val_loss: 0.6929 - val_accuracy: 0.5331\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5614 - val_loss: 0.6924 - val_accuracy: 0.5321\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5579 - val_loss: 0.6931 - val_accuracy: 0.5352\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5574 - val_loss: 0.6928 - val_accuracy: 0.5362\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5561 - val_loss: 0.6930 - val_accuracy: 0.5352\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5592 - val_loss: 0.6933 - val_accuracy: 0.5362\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5632 - val_loss: 0.6940 - val_accuracy: 0.5331\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5577 - val_loss: 0.6932 - val_accuracy: 0.5321\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.5594 - val_loss: 0.6936 - val_accuracy: 0.5311\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5588 - val_loss: 0.6934 - val_accuracy: 0.5321\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5638 - val_loss: 0.6938 - val_accuracy: 0.5352\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5625 - val_loss: 0.6942 - val_accuracy: 0.5352\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5612 - val_loss: 0.6942 - val_accuracy: 0.5352\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5599 - val_loss: 0.6942 - val_accuracy: 0.5311\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5612 - val_loss: 0.6940 - val_accuracy: 0.5321\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5638 - val_loss: 0.6941 - val_accuracy: 0.5321\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5667 - val_loss: 0.6943 - val_accuracy: 0.5321\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5634 - val_loss: 0.6950 - val_accuracy: 0.5311\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5645 - val_loss: 0.6949 - val_accuracy: 0.5352\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5628 - val_loss: 0.6946 - val_accuracy: 0.5311\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5628 - val_loss: 0.6952 - val_accuracy: 0.5311\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5627 - val_loss: 0.6954 - val_accuracy: 0.5352\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5659 - val_loss: 0.6948 - val_accuracy: 0.5321\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5667 - val_loss: 0.6943 - val_accuracy: 0.5321\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5630 - val_loss: 0.6945 - val_accuracy: 0.5321\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5634 - val_loss: 0.6950 - val_accuracy: 0.5311\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5689 - val_loss: 0.6951 - val_accuracy: 0.5321\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5674 - val_loss: 0.6959 - val_accuracy: 0.5311\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5647 - val_loss: 0.6956 - val_accuracy: 0.5311\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6823 - accuracy: 0.5680 - val_loss: 0.6970 - val_accuracy: 0.5352\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5663 - val_loss: 0.6959 - val_accuracy: 0.5311\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5676 - val_loss: 0.6965 - val_accuracy: 0.5311\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5659 - val_loss: 0.6962 - val_accuracy: 0.5311\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5645 - val_loss: 0.6958 - val_accuracy: 0.5321\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5645 - val_loss: 0.6961 - val_accuracy: 0.5311\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5676 - val_loss: 0.6954 - val_accuracy: 0.5321\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5678 - val_loss: 0.6965 - val_accuracy: 0.5352\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5665 - val_loss: 0.6955 - val_accuracy: 0.5321\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5643 - val_loss: 0.6958 - val_accuracy: 0.5311\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5661 - val_loss: 0.6961 - val_accuracy: 0.5311\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5658 - val_loss: 0.6960 - val_accuracy: 0.5311\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5650 - val_loss: 0.6961 - val_accuracy: 0.5311\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6822 - accuracy: 0.5659 - val_loss: 0.6972 - val_accuracy: 0.5311\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5656 - val_loss: 0.6962 - val_accuracy: 0.5311\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5691 - val_loss: 0.6965 - val_accuracy: 0.5311\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5694 - val_loss: 0.6967 - val_accuracy: 0.5311\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5658 - val_loss: 0.6975 - val_accuracy: 0.5311\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5700 - val_loss: 0.6968 - val_accuracy: 0.5311\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5678 - val_loss: 0.6962 - val_accuracy: 0.5311\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5674 - val_loss: 0.6967 - val_accuracy: 0.5311\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5691 - val_loss: 0.6968 - val_accuracy: 0.5311\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5687 - val_loss: 0.6965 - val_accuracy: 0.5311\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5694 - val_loss: 0.6966 - val_accuracy: 0.5311\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5683 - val_loss: 0.6963 - val_accuracy: 0.5331\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5676 - val_loss: 0.6971 - val_accuracy: 0.5311\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5696 - val_loss: 0.6965 - val_accuracy: 0.5321\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5669 - val_loss: 0.6965 - val_accuracy: 0.5321\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5654 - val_loss: 0.6974 - val_accuracy: 0.5311\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5685 - val_loss: 0.6976 - val_accuracy: 0.5311\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5681 - val_loss: 0.6966 - val_accuracy: 0.5331\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6817 - accuracy: 0.5665 - val_loss: 0.6978 - val_accuracy: 0.5311\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5685 - val_loss: 0.6974 - val_accuracy: 0.5321\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5720 - val_loss: 0.6977 - val_accuracy: 0.5311\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5676 - val_loss: 0.6976 - val_accuracy: 0.5311\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5694 - val_loss: 0.6980 - val_accuracy: 0.5311\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5698 - val_loss: 0.6966 - val_accuracy: 0.5321\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5665 - val_loss: 0.6983 - val_accuracy: 0.5311\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5691 - val_loss: 0.6973 - val_accuracy: 0.5321\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.5645 - val_loss: 0.6972 - val_accuracy: 0.5321\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5698 - val_loss: 0.6982 - val_accuracy: 0.5311\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5707 - val_loss: 0.6973 - val_accuracy: 0.5321\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5698 - val_loss: 0.6974 - val_accuracy: 0.5321\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5672 - val_loss: 0.6983 - val_accuracy: 0.5311\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5658 - val_loss: 0.6968 - val_accuracy: 0.5321\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5687 - val_loss: 0.6987 - val_accuracy: 0.5311\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5681 - val_loss: 0.6972 - val_accuracy: 0.5321\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5696 - val_loss: 0.6973 - val_accuracy: 0.5321\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5681 - val_loss: 0.6978 - val_accuracy: 0.5321\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5680 - val_loss: 0.6969 - val_accuracy: 0.5321\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5705 - val_loss: 0.6978 - val_accuracy: 0.5321\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5691 - val_loss: 0.6978 - val_accuracy: 0.5321\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5667 - val_loss: 0.6978 - val_accuracy: 0.5321\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 WINFUT_F_0_30min - Time: 9646.019115686417\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5260 - val_loss: 0.6850 - val_accuracy: 0.5663\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5494 - val_loss: 0.6865 - val_accuracy: 0.5694\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5492 - val_loss: 0.6873 - val_accuracy: 0.5704\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5558 - val_loss: 0.6868 - val_accuracy: 0.5694\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5562 - val_loss: 0.6879 - val_accuracy: 0.5704\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5523 - val_loss: 0.6885 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5582 - val_loss: 0.6915 - val_accuracy: 0.5683\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5538 - val_loss: 0.6878 - val_accuracy: 0.5694\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5509 - val_loss: 0.6913 - val_accuracy: 0.5694\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5580 - val_loss: 0.6990 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5576 - val_loss: 0.7007 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5598 - val_loss: 0.6984 - val_accuracy: 0.5694\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5569 - val_loss: 0.7001 - val_accuracy: 0.5704\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5556 - val_loss: 0.7092 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5595 - val_loss: 0.7003 - val_accuracy: 0.5694\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5567 - val_loss: 0.7121 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5615 - val_loss: 0.7126 - val_accuracy: 0.5704\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5544 - val_loss: 0.7133 - val_accuracy: 0.5704\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5597 - val_loss: 0.7177 - val_accuracy: 0.5704\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5611 - val_loss: 0.7073 - val_accuracy: 0.5694\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5673 - val_loss: 0.7034 - val_accuracy: 0.5704\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5571 - val_loss: 0.7105 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5624 - val_loss: 0.7130 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5600 - val_loss: 0.7290 - val_accuracy: 0.5704\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5618 - val_loss: 0.7186 - val_accuracy: 0.5704\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5644 - val_loss: 0.7230 - val_accuracy: 0.5704\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5591 - val_loss: 0.7220 - val_accuracy: 0.5704\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5620 - val_loss: 0.7323 - val_accuracy: 0.5704\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5651 - val_loss: 0.7276 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5626 - val_loss: 0.7352 - val_accuracy: 0.5704\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5604 - val_loss: 0.7300 - val_accuracy: 0.5704\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5637 - val_loss: 0.7510 - val_accuracy: 0.5704\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5611 - val_loss: 0.7415 - val_accuracy: 0.5704\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5650 - val_loss: 0.7425 - val_accuracy: 0.5704\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5629 - val_loss: 0.7476 - val_accuracy: 0.5704\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5637 - val_loss: 0.7393 - val_accuracy: 0.5704\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5644 - val_loss: 0.7476 - val_accuracy: 0.5704\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5617 - val_loss: 0.7295 - val_accuracy: 0.5704\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5615 - val_loss: 0.7328 - val_accuracy: 0.5704\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5617 - val_loss: 0.7348 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5640 - val_loss: 0.7516 - val_accuracy: 0.5704\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5650 - val_loss: 0.7497 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5686 - val_loss: 0.7180 - val_accuracy: 0.5704\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5611 - val_loss: 0.7244 - val_accuracy: 0.5704\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5629 - val_loss: 0.7414 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5639 - val_loss: 0.7510 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5650 - val_loss: 0.7476 - val_accuracy: 0.5704\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5602 - val_loss: 0.7438 - val_accuracy: 0.5704\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5657 - val_loss: 0.7334 - val_accuracy: 0.5704\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5604 - val_loss: 0.7391 - val_accuracy: 0.5704\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5659 - val_loss: 0.7573 - val_accuracy: 0.5704\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5615 - val_loss: 0.7572 - val_accuracy: 0.5704\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5651 - val_loss: 0.7669 - val_accuracy: 0.5704\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5633 - val_loss: 0.7327 - val_accuracy: 0.5694\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5662 - val_loss: 0.7571 - val_accuracy: 0.5735\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5655 - val_loss: 0.7559 - val_accuracy: 0.5704\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5671 - val_loss: 0.7508 - val_accuracy: 0.5735\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5624 - val_loss: 0.7550 - val_accuracy: 0.5735\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5661 - val_loss: 0.7467 - val_accuracy: 0.5704\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5615 - val_loss: 0.7525 - val_accuracy: 0.5704\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5659 - val_loss: 0.7533 - val_accuracy: 0.5704\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5655 - val_loss: 0.7519 - val_accuracy: 0.5704\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5620 - val_loss: 0.7596 - val_accuracy: 0.5704\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5670 - val_loss: 0.7732 - val_accuracy: 0.5704\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5644 - val_loss: 0.7506 - val_accuracy: 0.5735\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5648 - val_loss: 0.7720 - val_accuracy: 0.5714\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.7659 - val_accuracy: 0.5704\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5671 - val_loss: 0.7549 - val_accuracy: 0.5704\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5640 - val_loss: 0.7460 - val_accuracy: 0.5735\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5653 - val_loss: 0.7598 - val_accuracy: 0.5735\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5642 - val_loss: 0.7679 - val_accuracy: 0.5735\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5639 - val_loss: 0.7756 - val_accuracy: 0.5580\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5650 - val_loss: 0.7686 - val_accuracy: 0.5725\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5646 - val_loss: 0.7801 - val_accuracy: 0.5704\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5639 - val_loss: 0.7449 - val_accuracy: 0.5725\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5682 - val_loss: 0.7481 - val_accuracy: 0.5735\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5677 - val_loss: 0.7581 - val_accuracy: 0.5735\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5679 - val_loss: 0.7533 - val_accuracy: 0.5725\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5681 - val_loss: 0.7500 - val_accuracy: 0.5704\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5666 - val_loss: 0.7606 - val_accuracy: 0.5735\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5629 - val_loss: 0.7719 - val_accuracy: 0.5735\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5693 - val_loss: 0.7652 - val_accuracy: 0.5725\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5651 - val_loss: 0.7759 - val_accuracy: 0.5487\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5657 - val_loss: 0.7624 - val_accuracy: 0.5725\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5635 - val_loss: 0.7570 - val_accuracy: 0.5704\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5655 - val_loss: 0.7465 - val_accuracy: 0.5735\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5646 - val_loss: 0.7536 - val_accuracy: 0.5735\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5659 - val_loss: 0.7696 - val_accuracy: 0.5735\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5681 - val_loss: 0.7839 - val_accuracy: 0.5725\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5677 - val_loss: 0.7693 - val_accuracy: 0.5735\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5655 - val_loss: 0.7878 - val_accuracy: 0.5497\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5681 - val_loss: 0.7649 - val_accuracy: 0.5735\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5670 - val_loss: 0.7653 - val_accuracy: 0.5735\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5695 - val_loss: 0.7700 - val_accuracy: 0.5735\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5661 - val_loss: 0.7948 - val_accuracy: 0.5435\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5642 - val_loss: 0.8037 - val_accuracy: 0.5735\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5673 - val_loss: 0.7668 - val_accuracy: 0.5735\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5655 - val_loss: 0.7787 - val_accuracy: 0.5735\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5692 - val_loss: 0.8102 - val_accuracy: 0.5176\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5622 - val_loss: 0.7971 - val_accuracy: 0.5735\n",
      "51/51 [==============================] - 0s 966us/step\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Time: 9287.969574213028\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 22:48:34.907217: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:34.974088: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.031844: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.052470: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.059606: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.094297: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.119522: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:35.127061: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 22:48:36.230865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 22:48:36.261307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 22:48:36.328646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 22:48:36.357486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WINFUT_F_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 PETR3_B_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 WDOFUT_F_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 PETR3_B_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 WINFUT_F_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 WDOFUT_F_0_30min - Obtendo resultados!\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerando estrategias...\n",
      "Files: ['PETR3_B_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_60min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_30min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_predictions.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv'] \n",
      " Path: ../Results/test/classification \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_60min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/regression \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_60min_ensamble.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_60min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'WDOFUT_F_0_60min_predictions.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'WDOFUT_F_0_60min_predictions_class.csv'] \n",
      " Path: ../Results/test/statistic \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'WDOFUT_F_0_60min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_60min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv'] \n",
      " Path: ../Results/test/ensamble1 \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'WDOFUT_F_0_60min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_60min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv'] \n",
      " Path: ../Results/test/ensamble2 \n",
      "\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\", \"main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
