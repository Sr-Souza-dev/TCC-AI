{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/sr-souza/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/sr-souza/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting enum\n",
      "  Using cached enum-0.4.7.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m Error in sys.excepthook:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 62, in apport_excepthook\n",
      "  \u001b[31m   \u001b[0m     if not enabled():\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 24, in enabled\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Original exception was:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: enum34 in /home/sr-souza/.local/lib/python3.10/site-packages (1.1.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/sr-souza/.local/lib/python3.10/site-packages (1.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /home/sr-souza/.local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/lib/python3/dist-packages (from statsmodels) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arch in /home/sr-souza/.local/lib/python3.10/site-packages (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/lib/python3/dist-packages (from arch) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (2.0.3)\n",
      "Requirement already satisfied: statsmodels>=0.12 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1->arch) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (23.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels>=0.12->arch) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/sr-souza/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sr-souza/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tuner in /home/sr-souza/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: keras-core in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
      "Requirement already satisfied: packaging in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
      "Requirement already satisfied: namex in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.9.0)\n",
      "Requirement already satisfied: dm-tree in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sr-souza/.local/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in /home/sr-souza/.local/lib/python3.10/site-packages (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gitpython in /home/sr-souza/.local/lib/python3.10/site-packages (3.1.40)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from gitpython) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:   3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "Pandas:   2.0.3\n",
      "Numpy:    1.24.3\n",
      "Matplt:   3.5.1\n",
      "Sklearn:  1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "dataNames = [\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "    \"WINFUT_F_0_30min\"\n",
    "]\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:21:40.913146: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:40.970409: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:41.989742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:21:48.382857: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:48.443614: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:21:48.690423: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:48.735024: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:48.750652: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:48.793003: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:21:49.523385: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:49.576489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-20 08:21:49.592764: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 08:21:50.026516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-20 08:21:50.250200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 1 WINFUT_F_0_60min - Gerando base de dados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:21:50.928319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 1 WINFUT_F_0_30min - Gerando base de dados\n",
      "    | Etapa 1 WDOFUT_F_0_30min - Gerando base de dados\n",
      "    | Etapa 1 PETR3_B_0_60min - Gerando base de dados\n",
      "    | Etapa 1 PETR3_B_0_60min - Time: 912.2788763046265\n",
      "    | Etapa 1 PETR3_B_0_30min - Gerando base de dados\n",
      "    | Etapa 1 WINFUT_F_0_60min - Time: 1319.5544652938843\n",
      "    | Etapa 1 PETR3_B_0_30min - Time: 1589.1779725551605\n",
      "    | Etapa 1 WDOFUT_F_0_30min - Time: 2628.3200373649597\n",
      "    | Etapa 1 WINFUT_F_0_30min - Time: 2638.2117297649384\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 2 WINFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_60min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_60min - X_train: (3205, 4) | X_test: (3205, 4) | Y_train: (3205,) | Y_test: (3205,)\n",
      "                 * WINFUT_F_0_60min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "    | Etapa 2 PETR3_B_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_60min - Obtendo modelos de classificação otimizados\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WDOFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_30min - X_train: (6439, 4) | X_test: (6439, 4) | Y_train: (6439,) | Y_test: (6439,)\n",
      "                 * WDOFUT_F_0_30min - SVM\n",
      "             -- PETR3_B_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_60min - X_train: (2728, 4) | X_test: (2728, 4) | Y_train: (2728,) | Y_test: (2728,)\n",
      "                 * PETR3_B_0_60min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 09:06:01.081576: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 09:06:01.269395: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 09:06:05.348790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 2 WINFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_30min - X_train: (6440, 4) | X_test: (6440, 4) | Y_train: (6440,) | Y_test: (6440,)\n",
      "                 * WINFUT_F_0_30min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_60min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_60min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 PETR3_B_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_60min -X_train: (227, 1) | X_test: (152, 1) | Y_train: (227, 2) | Y_test: (152, 2)\n",
      "                     * PETR3_B_0_60min - ARIMA \n",
      "                     * PETR3_B_0_60min - SARIMA \n",
      "                     * PETR3_B_0_60min - GARCH \n",
      "        - Etapa 2.3 PETR3_B_0_60min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/rnn/tuner0.json\n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos de Regressão \n",
      "                     * PETR3_B_0_60min - LSTM \n",
      "                     * PETR3_B_0_60min - MLP \n",
      "                     * PETR3_B_0_60min - RNN \n",
      "    | Etapa 2 PETR3_B_0_60min - Time: 5500.887885808945\n",
      "    | Etapa 2 PETR3_B_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- PETR3_B_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_30min - X_train: (5364, 4) | X_test: (5364, 4) | Y_train: (5364,) | Y_test: (5364,)\n",
      "                 * PETR3_B_0_30min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_30min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_30min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 PETR3_B_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_30min -X_train: (447, 1) | X_test: (299, 1) | Y_train: (447, 2) | Y_test: (299, 2)\n",
      "                     * PETR3_B_0_30min - ARIMA \n",
      "                     * PETR3_B_0_30min - SARIMA \n",
      "                 * WINFUT_F_0_60min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * WINFUT_F_0_60min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 WINFUT_F_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_60min -X_train: (267, 1) | X_test: (179, 1) | Y_train: (267, 2) | Y_test: (179, 2)\n",
      "                     * WINFUT_F_0_60min - ARIMA \n",
      "                     * WINFUT_F_0_60min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WINFUT_F_0_60min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/rnn/tuner0.json\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WINFUT_F_0_60min - LSTM \n",
      "                     * WINFUT_F_0_60min - MLP \n",
      "                     * WINFUT_F_0_60min - RNN \n",
      "    | Etapa 2 WINFUT_F_0_60min - Time: 11793.951605081558\n",
      "                     * PETR3_B_0_30min - GARCH \n",
      "        - Etapa 2.3 PETR3_B_0_30min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/rnn/tuner0.json\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * PETR3_B_0_30min - LSTM \n",
      "                     * PETR3_B_0_30min - MLP \n",
      "                     * PETR3_B_0_30min - RNN \n",
      "    | Etapa 2 PETR3_B_0_30min - Time: 12148.355786800385\n",
      "                 * WINFUT_F_0_30min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * WINFUT_F_0_30min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 WINFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WINFUT_F_0_30min - ARIMA \n",
      "                     * WINFUT_F_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WINFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/rnn/tuner0.json\n",
      "                 -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WINFUT_F_0_30min - LSTM \n",
      "                     * WINFUT_F_0_30min - MLP \n",
      "                     * WINFUT_F_0_30min - RNN \n",
      "    | Etapa 2 WINFUT_F_0_30min - Time: 22447.712065935135\n",
      "                 * WDOFUT_F_0_30min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * WDOFUT_F_0_30min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 WDOFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WDOFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WDOFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WDOFUT_F_0_30min - ARIMA \n",
      "                     * WDOFUT_F_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WDOFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WDOFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/rnn/tuner0.json\n",
      "                 -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WDOFUT_F_0_30min - LSTM \n",
      "                     * WDOFUT_F_0_30min - MLP \n",
      "                     * WDOFUT_F_0_30min - RNN \n",
      "    | Etapa 2 WDOFUT_F_0_30min - Time: 65306.89028763771\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getOptmizedModels, trainModels, getEnsambles, getResults, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "dataNames = [\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "    \"WINFUT_F_0_30min\"\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models optimized {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 3 WINFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 WINFUT_F_0_60min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WINFUT_F_0_60min - Treinando modelos de regressão\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 03:14:27.247129: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:27.262430: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:27.304197: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:27.323209: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:27.420645: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:27.482666: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 03:14:28.461575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 03:14:28.503096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 03:14:28.596376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 3ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      " 37/101 [=========>....................] - ETA: 0s    | Etapa 3 WDOFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      " 70/101 [===================>..........] - ETA: 0s    | Etapa 3 PETR3_B_0_60min - Obtendo modelos já otimizados!\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "    | Etapa 3 WINFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "        - Etapa 4.3 WINFUT_F_0_60min - Treinando modelos de estatística\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WDOFUT_F_0_30min - Treinando modelos de classificação\n",
      "    | Etapa 4 PETR3_B_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_60min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 PETR3_B_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 4 WINFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WINFUT_F_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WDOFUT_F_0_30min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 WINFUT_F_0_30min - Treinando modelos de regressão\n",
      "22/22 [==============================] - 1s 3ms/step\n",
      "51/51 [==============================] - 1s 3ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 2s 3ms/step\n",
      "22/22 [==============================] - 1s 2ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 1s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 1s 3ms/step\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      " 79/202 [==========>...................] - ETA: 0s        - Etapa 4.3 PETR3_B_0_60min - Treinando modelos de estatística\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "101/202 [==============>...............] - ETA: 0s        - Etapa 4.3 WDOFUT_F_0_30min - Treinando modelos de estatística\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "        - Etapa 4.3 WINFUT_F_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WINFUT_F_0_60min - Time: 2060.458862066269\n",
      "    | Etapa 3 PETR3_B_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 PETR3_B_0_30min - Treinando modelos de regressão\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "168/168 [==============================] - 0s 1ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "        - Etapa 4.3 PETR3_B_0_30min - Treinando modelos de estatística\n",
      "    | Etapa 4 PETR3_B_0_60min - Time: 2541.0995466709137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WDOFUT_F_0_30min - Time: 3882.938005208969\n",
      "    | Etapa 4 WINFUT_F_0_30min - Time: 4729.079773187637\n",
      "    | Etapa 4 PETR3_B_0_30min - Time: 3030.7994544506073\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models trained {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 WINFUT_F_0_60min - Obtendo ensambles!\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 04:39:24.695706: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:24.753443: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:24.769222: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:24.794686: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:24.827868: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:24.854765: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 04:39:26.056259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 04:39:26.065231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 04:39:26.085535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 WINFUT_F_0_30min - Obtendo ensambles!\n",
      "    | Etapa 5 PETR3_B_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 0.3546 - accuracy: 0.8628 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4.8214e-04 - accuracy: 1.0000 - val_loss: 7.5012e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.0809e-04 - accuracy: 1.0000 - val_loss: 3.8806e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 2.3971e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.8446e-05 - accuracy: 1.0000 - val_loss: 1.6024e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.5267e-05 - accuracy: 1.0000 - val_loss: 1.1299e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.2409e-05 - accuracy: 1.0000 - val_loss: 8.4901e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4640e-05 - accuracy: 1.0000 - val_loss: 6.7488e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.9394e-05 - accuracy: 1.0000 - val_loss: 5.4868e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5670e-05 - accuracy: 1.0000 - val_loss: 4.5282e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2915e-05 - accuracy: 1.0000 - val_loss: 3.8129e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1.0808e-05 - accuracy: 1.0000 - val_loss: 3.2761e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.1675e-06 - accuracy: 1.0000 - val_loss: 2.8307e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.8639e-06 - accuracy: 1.0000 - val_loss: 2.4696e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.8091e-06 - accuracy: 1.0000 - val_loss: 2.1547e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.9401e-06 - accuracy: 1.0000 - val_loss: 1.9191e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.2315e-06 - accuracy: 1.0000 - val_loss: 1.7123e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.6347e-06 - accuracy: 1.0000 - val_loss: 1.5349e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.1287e-06 - accuracy: 1.0000 - val_loss: 1.3831e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.6904e-06 - accuracy: 1.0000 - val_loss: 1.2551e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.3184e-06 - accuracy: 1.0000 - val_loss: 1.1406e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9991e-06 - accuracy: 1.0000 - val_loss: 1.0394e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7203e-06 - accuracy: 1.0000 - val_loss: 9.5131e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4766e-06 - accuracy: 1.0000 - val_loss: 8.7091e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.2581e-06 - accuracy: 1.0000 - val_loss: 8.0218e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0637e-06 - accuracy: 1.0000 - val_loss: 7.4095e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8923e-06 - accuracy: 1.0000 - val_loss: 6.8469e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7445e-06 - accuracy: 1.0000 - val_loss: 6.3172e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6142e-06 - accuracy: 1.0000 - val_loss: 5.8796e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4873e-06 - accuracy: 1.0000 - val_loss: 5.4574e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3722e-06 - accuracy: 1.0000 - val_loss: 5.0899e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.2721e-06 - accuracy: 1.0000 - val_loss: 4.7515e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1805e-06 - accuracy: 1.0000 - val_loss: 4.4282e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0942e-06 - accuracy: 1.0000 - val_loss: 4.1313e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0169e-06 - accuracy: 1.0000 - val_loss: 3.8638e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.4503e-07 - accuracy: 1.0000 - val_loss: 3.6234e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.8152e-07 - accuracy: 1.0000 - val_loss: 3.4006e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.2320e-07 - accuracy: 1.0000 - val_loss: 3.1843e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.6725e-07 - accuracy: 1.0000 - val_loss: 3.0017e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.2364e-07 - accuracy: 1.0000 - val_loss: 2.8244e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.7895e-07 - accuracy: 1.0000 - val_loss: 2.6677e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.4264e-07 - accuracy: 1.0000 - val_loss: 2.5147e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.9785e-07 - accuracy: 1.0000 - val_loss: 2.3693e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.7249e-07 - accuracy: 1.0000 - val_loss: 2.2475e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.3562e-07 - accuracy: 1.0000 - val_loss: 2.1231e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.9844e-07 - accuracy: 1.0000 - val_loss: 2.0059e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.7889e-07 - accuracy: 1.0000 - val_loss: 1.9059e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.4238e-07 - accuracy: 1.0000 - val_loss: 1.8082e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.1790e-07 - accuracy: 1.0000 - val_loss: 1.7021e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.9527e-07 - accuracy: 1.0000 - val_loss: 1.6236e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7362e-07 - accuracy: 1.0000 - val_loss: 1.5392e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.3788e-07 - accuracy: 1.0000 - val_loss: 1.4389e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1777e-07 - accuracy: 1.0000 - val_loss: 1.3741e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.0399e-07 - accuracy: 1.0000 - val_loss: 1.3139e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8825e-07 - accuracy: 1.0000 - val_loss: 1.2421e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7663e-07 - accuracy: 1.0000 - val_loss: 1.1805e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6403e-07 - accuracy: 1.0000 - val_loss: 1.1261e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4140e-07 - accuracy: 1.0000 - val_loss: 1.0697e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.3369e-07 - accuracy: 1.0000 - val_loss: 1.0269e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2443e-07 - accuracy: 1.0000 - val_loss: 9.8275e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1507e-07 - accuracy: 1.0000 - val_loss: 9.3623e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.0741e-07 - accuracy: 1.0000 - val_loss: 8.8767e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.9290e-07 - accuracy: 1.0000 - val_loss: 8.3912e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.8133e-07 - accuracy: 1.0000 - val_loss: 7.9463e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7465e-07 - accuracy: 1.0000 - val_loss: 7.7021e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.6472e-07 - accuracy: 1.0000 - val_loss: 7.2543e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4765e-07 - accuracy: 1.0000 - val_loss: 6.9229e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4256e-07 - accuracy: 1.0000 - val_loss: 6.7106e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3834e-07 - accuracy: 1.0000 - val_loss: 6.4228e-07 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.1191 - accuracy: 0.9482 - val_loss: 4.5989e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 2.0272e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.8262e-06 - accuracy: 1.0000 - val_loss: 7.8601e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.7696e-06 - accuracy: 1.0000 - val_loss: 6.9721e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.9912e-06 - accuracy: 1.0000 - val_loss: 6.1551e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6.2572e-06 - accuracy: 1.0000 - val_loss: 5.4321e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.5997e-06 - accuracy: 1.0000 - val_loss: 4.7782e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.0157e-06 - accuracy: 1.0000 - val_loss: 4.1993e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.4949e-06 - accuracy: 1.0000 - val_loss: 3.7007e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0320e-06 - accuracy: 1.0000 - val_loss: 3.2558e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.6304e-06 - accuracy: 1.0000 - val_loss: 2.8825e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.2762e-06 - accuracy: 1.0000 - val_loss: 2.5650e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.9627e-06 - accuracy: 1.0000 - val_loss: 2.2955e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6829e-06 - accuracy: 1.0000 - val_loss: 2.0437e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4417e-06 - accuracy: 1.0000 - val_loss: 1.8332e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2244e-06 - accuracy: 1.0000 - val_loss: 1.6486e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0338e-06 - accuracy: 1.0000 - val_loss: 1.4982e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8610e-06 - accuracy: 1.0000 - val_loss: 1.3453e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7085e-06 - accuracy: 1.0000 - val_loss: 1.2215e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5718e-06 - accuracy: 1.0000 - val_loss: 1.1168e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4498e-06 - accuracy: 1.0000 - val_loss: 1.0162e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3400e-06 - accuracy: 1.0000 - val_loss: 9.2198e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.2399e-06 - accuracy: 1.0000 - val_loss: 8.4609e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.1512e-06 - accuracy: 1.0000 - val_loss: 7.7544e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0671e-06 - accuracy: 1.0000 - val_loss: 7.1409e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9.9620e-07 - accuracy: 1.0000 - val_loss: 6.6059e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.2533e-07 - accuracy: 1.0000 - val_loss: 6.1087e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.6804e-07 - accuracy: 1.0000 - val_loss: 5.5796e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.0479e-07 - accuracy: 1.0000 - val_loss: 5.1405e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.5485e-07 - accuracy: 1.0000 - val_loss: 4.8207e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.0677e-07 - accuracy: 1.0000 - val_loss: 4.4747e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.6341e-07 - accuracy: 1.0000 - val_loss: 4.1171e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.1893e-07 - accuracy: 1.0000 - val_loss: 3.8263e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.8339e-07 - accuracy: 1.0000 - val_loss: 3.5094e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.4451e-07 - accuracy: 1.0000 - val_loss: 3.3146e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.1397e-07 - accuracy: 1.0000 - val_loss: 3.0180e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.8656e-07 - accuracy: 1.0000 - val_loss: 2.8726e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.5842e-07 - accuracy: 1.0000 - val_loss: 2.6546e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.3317e-07 - accuracy: 1.0000 - val_loss: 2.4801e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0401e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.8293e-07 - accuracy: 1.0000 - val_loss: 2.1865e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.6164e-07 - accuracy: 1.0000 - val_loss: 2.0644e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.4564e-07 - accuracy: 1.0000 - val_loss: 1.9888e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2852e-07 - accuracy: 1.0000 - val_loss: 1.8114e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.1011e-07 - accuracy: 1.0000 - val_loss: 1.7765e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.9617e-07 - accuracy: 1.0000 - val_loss: 1.6224e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7987e-07 - accuracy: 1.0000 - val_loss: 1.5555e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6125e-07 - accuracy: 1.0000 - val_loss: 1.4014e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4819e-07 - accuracy: 1.0000 - val_loss: 1.2997e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.3888e-07 - accuracy: 1.0000 - val_loss: 1.2532e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2705e-07 - accuracy: 1.0000 - val_loss: 1.1572e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1440e-07 - accuracy: 1.0000 - val_loss: 1.1281e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.0262e-07 - accuracy: 1.0000 - val_loss: 1.0409e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.8936e-07 - accuracy: 1.0000 - val_loss: 9.9438e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7737e-07 - accuracy: 1.0000 - val_loss: 8.8389e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6827e-07 - accuracy: 1.0000 - val_loss: 8.4900e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6246e-07 - accuracy: 1.0000 - val_loss: 8.1993e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5567e-07 - accuracy: 1.0000 - val_loss: 7.9085e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4657e-07 - accuracy: 1.0000 - val_loss: 7.8213e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4040e-07 - accuracy: 1.0000 - val_loss: 7.5305e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.3556e-07 - accuracy: 1.0000 - val_loss: 6.6583e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2800e-07 - accuracy: 1.0000 - val_loss: 6.1349e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2137e-07 - accuracy: 1.0000 - val_loss: 5.5534e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1746e-07 - accuracy: 1.0000 - val_loss: 5.4953e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1304e-07 - accuracy: 1.0000 - val_loss: 5.1754e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0553e-07 - accuracy: 1.0000 - val_loss: 5.0591e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0049e-07 - accuracy: 1.0000 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.6787e-08 - accuracy: 1.0000 - val_loss: 4.7102e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.9021e-08 - accuracy: 1.0000 - val_loss: 4.7102e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.4496e-08 - accuracy: 1.0000 - val_loss: 3.8380e-08 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.2130e-08 - accuracy: 1.0000 - val_loss: 3.8380e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.9661e-08 - accuracy: 1.0000 - val_loss: 3.5181e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.4519e-08 - accuracy: 1.0000 - val_loss: 3.3727e-08 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.1639e-08 - accuracy: 1.0000 - val_loss: 3.3146e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.9273e-08 - accuracy: 1.0000 - val_loss: 3.2855e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.6393e-08 - accuracy: 1.0000 - val_loss: 2.9948e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.5776e-08 - accuracy: 1.0000 - val_loss: 2.9948e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.1919e-08 - accuracy: 1.0000 - val_loss: 2.9948e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 2.7040e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.6262e-08 - accuracy: 1.0000 - val_loss: 2.7040e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.6159e-08 - accuracy: 1.0000 - val_loss: 2.7040e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.2662e-08 - accuracy: 1.0000 - val_loss: 2.6459e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.9113e-08 - accuracy: 1.0000 - val_loss: 2.1225e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.7519e-08 - accuracy: 1.0000 - val_loss: 1.8899e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.5359e-08 - accuracy: 1.0000 - val_loss: 1.8899e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.3971e-08 - accuracy: 1.0000 - val_loss: 1.8318e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0165e-08 - accuracy: 1.0000 - val_loss: 1.8318e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.9239e-08 - accuracy: 1.0000 - val_loss: 1.8318e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.9136e-08 - accuracy: 1.0000 - val_loss: 1.5991e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.6154e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3.1782e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.0651e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.0034e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6845e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6845e-08 - accuracy: 1.0000 - val_loss: 9.5949e-09 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.6845e-08 - accuracy: 1.0000 - val_loss: 9.0134e-09 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6794e-08 - accuracy: 1.0000 - val_loss: 6.3966e-09 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2988e-08 - accuracy: 1.0000 - val_loss: 6.3966e-09 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1342e-08 - accuracy: 1.0000 - val_loss: 6.3966e-09 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1342e-08 - accuracy: 1.0000 - val_loss: 6.3966e-09 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 PETR3_B_0_60min - Time: 2941.5200254917145\n",
      "    | Etapa 5 PETR3_B_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 7ms/step - loss: 0.6907 - accuracy: 0.5257 - val_loss: 0.6584 - val_accuracy: 0.6486\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.6039 - val_loss: 0.6521 - val_accuracy: 0.6486\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.5995 - val_loss: 0.6657 - val_accuracy: 0.6486\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6039 - val_loss: 0.6605 - val_accuracy: 0.6486\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6522 - val_accuracy: 0.6486\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6024 - val_loss: 0.6528 - val_accuracy: 0.6486\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6039 - val_loss: 0.6556 - val_accuracy: 0.6486\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6039 - val_loss: 0.6594 - val_accuracy: 0.6486\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6039 - val_loss: 0.6529 - val_accuracy: 0.6486\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6600 - val_accuracy: 0.6486\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6039 - val_loss: 0.6530 - val_accuracy: 0.6486\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.6039 - val_loss: 0.6553 - val_accuracy: 0.6486\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6039 - val_loss: 0.6561 - val_accuracy: 0.6486\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6039 - val_loss: 0.6528 - val_accuracy: 0.6486\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6039 - val_loss: 0.6588 - val_accuracy: 0.6486\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6039 - val_loss: 0.6555 - val_accuracy: 0.6486\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6039 - val_loss: 0.6546 - val_accuracy: 0.6486\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6039 - val_loss: 0.6512 - val_accuracy: 0.6486\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.6039 - val_loss: 0.6577 - val_accuracy: 0.6486\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6035 - val_loss: 0.6528 - val_accuracy: 0.6486\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6039 - val_loss: 0.6542 - val_accuracy: 0.6486\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6039 - val_loss: 0.6583 - val_accuracy: 0.6486\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6539 - val_accuracy: 0.6486\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6039 - val_loss: 0.6575 - val_accuracy: 0.6486\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6039 - val_loss: 0.6553 - val_accuracy: 0.6486\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6534 - val_accuracy: 0.6486\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6039 - val_loss: 0.6528 - val_accuracy: 0.6486\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.6039 - val_loss: 0.6563 - val_accuracy: 0.6486\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.6039 - val_loss: 0.6523 - val_accuracy: 0.6486\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6039 - val_loss: 0.6527 - val_accuracy: 0.6486\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6039 - val_loss: 0.6522 - val_accuracy: 0.6486\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6039 - val_loss: 0.6527 - val_accuracy: 0.6486\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6655 - val_accuracy: 0.6486\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.6039 - val_loss: 0.6530 - val_accuracy: 0.6486\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6039 - val_loss: 0.6593 - val_accuracy: 0.6486\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6039 - val_loss: 0.6537 - val_accuracy: 0.6486\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6039 - val_loss: 0.6586 - val_accuracy: 0.6486\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.6039 - val_loss: 0.6563 - val_accuracy: 0.6486\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6039 - val_loss: 0.6583 - val_accuracy: 0.6486\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6039 - val_loss: 0.6524 - val_accuracy: 0.6486\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6039 - val_loss: 0.6549 - val_accuracy: 0.6486\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6039 - val_loss: 0.6514 - val_accuracy: 0.6486\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.6039 - val_loss: 0.6611 - val_accuracy: 0.6486\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6039 - val_loss: 0.6558 - val_accuracy: 0.6486\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6039 - val_loss: 0.6544 - val_accuracy: 0.6486\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6039 - val_loss: 0.6578 - val_accuracy: 0.6486\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5954 - val_loss: 0.6534 - val_accuracy: 0.6486\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6039 - val_loss: 0.6572 - val_accuracy: 0.6486\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6039 - val_loss: 0.6513 - val_accuracy: 0.6486\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6039 - val_loss: 0.6572 - val_accuracy: 0.6486\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6039 - val_loss: 0.6596 - val_accuracy: 0.6486\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5977 - val_loss: 0.6538 - val_accuracy: 0.6486\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6039 - val_loss: 0.6555 - val_accuracy: 0.6486\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6039 - val_loss: 0.6538 - val_accuracy: 0.6486\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6039 - val_loss: 0.6517 - val_accuracy: 0.6486\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.6039 - val_loss: 0.6578 - val_accuracy: 0.6486\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6024 - val_loss: 0.6566 - val_accuracy: 0.6486\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6039 - val_loss: 0.6571 - val_accuracy: 0.6486\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6039 - val_loss: 0.6534 - val_accuracy: 0.6486\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6039 - val_loss: 0.6553 - val_accuracy: 0.6486\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6039 - val_loss: 0.6550 - val_accuracy: 0.6486\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6039 - val_loss: 0.6527 - val_accuracy: 0.6486\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.6039 - val_loss: 0.6567 - val_accuracy: 0.6486\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6039 - val_loss: 0.6527 - val_accuracy: 0.6486\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6039 - val_loss: 0.6536 - val_accuracy: 0.6486\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6028 - val_loss: 0.6559 - val_accuracy: 0.6486\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6039 - val_loss: 0.6562 - val_accuracy: 0.6486\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6039 - val_loss: 0.6532 - val_accuracy: 0.6486\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6039 - val_loss: 0.6548 - val_accuracy: 0.6486\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6039 - val_loss: 0.6535 - val_accuracy: 0.6486\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.4930 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4894 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4916 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4813 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5070 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.4923 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5011 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4886 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.4908 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4908 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4901 - val_loss: 0.6940 - val_accuracy: 0.4927\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4967 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4739 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4798 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4982 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4974 - val_loss: 0.6948 - val_accuracy: 0.4927\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5004 - val_loss: 0.6951 - val_accuracy: 0.4927\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4930 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5011 - val_loss: 0.6947 - val_accuracy: 0.4927\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.4982 - val_loss: 0.6942 - val_accuracy: 0.4927\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5121 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5018 - val_loss: 0.6936 - val_accuracy: 0.4927\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4945 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5092 - val_loss: 0.6947 - val_accuracy: 0.4927\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4908 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4967 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4857 - val_loss: 0.6941 - val_accuracy: 0.4927\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.4835 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4798 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4945 - val_loss: 0.6941 - val_accuracy: 0.4927\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5070 - val_loss: 0.6942 - val_accuracy: 0.4927\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4960 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4938 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4916 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4960 - val_loss: 0.6939 - val_accuracy: 0.4927\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5143 - val_loss: 0.6933 - val_accuracy: 0.5073\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5070 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4930 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.4849 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5004 - val_loss: 0.6940 - val_accuracy: 0.4927\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.4927\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4805 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4916 - val_loss: 0.6940 - val_accuracy: 0.4927\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4960 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5114 - val_loss: 0.6945 - val_accuracy: 0.4927\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4952 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4930 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4798 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4927\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4725 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4805 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5026 - val_loss: 0.6934 - val_accuracy: 0.4927\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5011 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5040 - val_loss: 0.6941 - val_accuracy: 0.4927\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4982 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4930 - val_loss: 0.6942 - val_accuracy: 0.4927\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4952 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4739 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5055 - val_loss: 0.6937 - val_accuracy: 0.4927\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.4835 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4886 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6946 - val_accuracy: 0.4927\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.4927\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6958 - val_accuracy: 0.4927\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4908 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5004 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5018 - val_loss: 0.6946 - val_accuracy: 0.4927\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4989 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4908 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4974 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.6933 - val_accuracy: 0.5073\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4879 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4827 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.4916 - val_loss: 0.6935 - val_accuracy: 0.4927\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5062 - val_loss: 0.6931 - val_accuracy: 0.5073\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 WINFUT_F_0_60min - Time: 3482.1127512454987\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.6629 - accuracy: 0.6253 - val_loss: 0.6657 - val_accuracy: 0.6460\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6380 - val_loss: 0.6842 - val_accuracy: 0.5424\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6377 - val_loss: 0.7110 - val_accuracy: 0.5424\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6380 - val_loss: 0.6840 - val_accuracy: 0.5424\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.6380 - val_loss: 0.7116 - val_accuracy: 0.5424\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6380 - val_loss: 0.6870 - val_accuracy: 0.5424\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6567 - accuracy: 0.6380 - val_loss: 0.7083 - val_accuracy: 0.5424\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6380 - val_loss: 0.7040 - val_accuracy: 0.5424\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6380 - val_loss: 0.6956 - val_accuracy: 0.5424\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6380 - val_loss: 0.7138 - val_accuracy: 0.5424\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6380 - val_loss: 0.7049 - val_accuracy: 0.5424\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6380 - val_loss: 0.7028 - val_accuracy: 0.5424\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6380 - val_loss: 0.6942 - val_accuracy: 0.5424\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6380 - val_loss: 0.6948 - val_accuracy: 0.5424\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6380 - val_loss: 0.7242 - val_accuracy: 0.5424\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6320 - val_loss: 0.6532 - val_accuracy: 0.6460\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6371 - val_loss: 0.6501 - val_accuracy: 0.6460\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6572 - accuracy: 0.6371 - val_loss: 0.6518 - val_accuracy: 0.6460\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6371 - val_loss: 0.6566 - val_accuracy: 0.6460\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6371 - val_loss: 0.6498 - val_accuracy: 0.6460\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6371 - val_loss: 0.6516 - val_accuracy: 0.6460\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6371 - val_loss: 0.6498 - val_accuracy: 0.6460\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6371 - val_loss: 0.6546 - val_accuracy: 0.6460\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6371 - val_loss: 0.6499 - val_accuracy: 0.6460\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6371 - val_loss: 0.6499 - val_accuracy: 0.6460\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6371 - val_loss: 0.6510 - val_accuracy: 0.6460\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6366 - val_loss: 0.6585 - val_accuracy: 0.6460\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6382 - val_loss: 0.7094 - val_accuracy: 0.5424\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6380 - val_loss: 0.6941 - val_accuracy: 0.5424\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6380 - val_loss: 0.6998 - val_accuracy: 0.5424\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6380 - val_loss: 0.7002 - val_accuracy: 0.5424\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6556 - accuracy: 0.6380 - val_loss: 0.7136 - val_accuracy: 0.5424\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6380 - val_loss: 0.7106 - val_accuracy: 0.5424\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6380 - val_loss: 0.7039 - val_accuracy: 0.5424\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6380 - val_loss: 0.7070 - val_accuracy: 0.5424\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6380 - val_loss: 0.7212 - val_accuracy: 0.5424\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6245 - val_loss: 0.7006 - val_accuracy: 0.5424\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6380 - val_loss: 0.7081 - val_accuracy: 0.5424\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6380 - val_loss: 0.7180 - val_accuracy: 0.5424\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6380 - val_loss: 0.7025 - val_accuracy: 0.5424\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6380 - val_loss: 0.7039 - val_accuracy: 0.5424\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6546 - accuracy: 0.6380 - val_loss: 0.7015 - val_accuracy: 0.5424\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6380 - val_loss: 0.7029 - val_accuracy: 0.5424\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6380 - val_loss: 0.7078 - val_accuracy: 0.5424\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6380 - val_loss: 0.7156 - val_accuracy: 0.5424\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6380 - val_loss: 0.7134 - val_accuracy: 0.5424\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6560 - accuracy: 0.6380 - val_loss: 0.7079 - val_accuracy: 0.5424\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6380 - val_loss: 0.7091 - val_accuracy: 0.5424\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6380 - val_loss: 0.7062 - val_accuracy: 0.5424\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6380 - val_loss: 0.7076 - val_accuracy: 0.5424\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6380 - val_loss: 0.7087 - val_accuracy: 0.5424\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6380 - val_loss: 0.7080 - val_accuracy: 0.5424\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6380 - val_loss: 0.7013 - val_accuracy: 0.5424\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6380 - val_loss: 0.6998 - val_accuracy: 0.5424\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6380 - val_loss: 0.7094 - val_accuracy: 0.5424\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6380 - val_loss: 0.7020 - val_accuracy: 0.5424\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6380 - val_loss: 0.7044 - val_accuracy: 0.5424\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6320 - val_loss: 0.7040 - val_accuracy: 0.5424\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6380 - val_loss: 0.7028 - val_accuracy: 0.5424\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6380 - val_loss: 0.7120 - val_accuracy: 0.5424\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6380 - val_loss: 0.7041 - val_accuracy: 0.5424\n",
      "Epoch 62/70\n",
      " 57/172 [========>.....................] - ETA: 0s - loss: 0.6658 - accuracy: 0.6212Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying/tuner0.json\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6380 - val_loss: 0.7079 - val_accuracy: 0.5424\n",
      "Epoch 63/70\n",
      " 23/172 [===>..........................] - ETA: 0s - loss: 0.6561 - accuracy: 0.6399Epoch 1/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6380 - val_loss: 0.7131 - val_accuracy: 0.5424\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6380 - val_loss: 0.7072 - val_accuracy: 0.5424\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6380 - val_loss: 0.6996 - val_accuracy: 0.5424\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6380 - val_loss: 0.6976 - val_accuracy: 0.5424\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 2s 5ms/step - loss: 0.0616 - accuracy: 0.9755 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6380 - val_loss: 0.7139 - val_accuracy: 0.5424\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6551 - accuracy: 0.6380 - val_loss: 0.7039 - val_accuracy: 0.5424\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6380 - val_loss: 0.7115 - val_accuracy: 0.5424\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6380 - val_loss: 0.7073 - val_accuracy: 0.5424\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "51/51 [==============================] - 0s 2ms/step loss: 0.0000e+00 - accuracy: 1.00\n",
      " 25/172 [===>..........................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying2/tuner0.json\n",
      "144/172 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000Epoch 1/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.6665 - accuracy: 0.6187 - val_loss: 0.6529 - val_accuracy: 0.6449\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6327 - val_loss: 0.6505 - val_accuracy: 0.6470\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6369 - val_loss: 0.6519 - val_accuracy: 0.6470\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      " 51/172 [=======>......................] - ETA: 0s - loss: 0.6497 - accuracy: 0.6477Epoch 36/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6371 - val_loss: 0.6508 - val_accuracy: 0.6470\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6364 - val_loss: 0.6511 - val_accuracy: 0.6470\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6371 - val_loss: 0.6532 - val_accuracy: 0.6470\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6375 - val_loss: 0.6528 - val_accuracy: 0.6470\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6556 - accuracy: 0.6371 - val_loss: 0.6512 - val_accuracy: 0.6470\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6369 - val_loss: 0.6543 - val_accuracy: 0.6470\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6371 - val_loss: 0.6534 - val_accuracy: 0.6460\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6371 - val_loss: 0.6532 - val_accuracy: 0.6470\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6369 - val_loss: 0.6542 - val_accuracy: 0.6460\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6553 - accuracy: 0.6368 - val_loss: 0.6564 - val_accuracy: 0.6460\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6353 - val_loss: 0.6506 - val_accuracy: 0.6470\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6373 - val_loss: 0.6546 - val_accuracy: 0.6460\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6550 - accuracy: 0.6371 - val_loss: 0.6519 - val_accuracy: 0.6460\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6366 - val_loss: 0.6508 - val_accuracy: 0.6470\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6371 - val_loss: 0.6509 - val_accuracy: 0.6470\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6371 - val_loss: 0.6578 - val_accuracy: 0.6460\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6550 - accuracy: 0.6373 - val_loss: 0.6520 - val_accuracy: 0.6470\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6377 - val_loss: 0.6537 - val_accuracy: 0.6460\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.6368 - val_loss: 0.6548 - val_accuracy: 0.6460\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6371 - val_loss: 0.6546 - val_accuracy: 0.6460\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6369 - val_loss: 0.6564 - val_accuracy: 0.6460\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6377 - val_loss: 0.6576 - val_accuracy: 0.6377\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6373 - val_loss: 0.6559 - val_accuracy: 0.6377\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6371 - val_loss: 0.6627 - val_accuracy: 0.6356\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6373 - val_loss: 0.6638 - val_accuracy: 0.6356\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6364 - val_loss: 0.6613 - val_accuracy: 0.6356\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6380 - val_loss: 0.6758 - val_accuracy: 0.5704\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6538 - accuracy: 0.6369 - val_loss: 0.6612 - val_accuracy: 0.6356\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6375 - val_loss: 0.6655 - val_accuracy: 0.5704\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6380 - val_loss: 0.6706 - val_accuracy: 0.5704\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6369 - val_loss: 0.6680 - val_accuracy: 0.5704\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6373 - val_loss: 0.6674 - val_accuracy: 0.5704\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6369 - val_loss: 0.6720 - val_accuracy: 0.5704\n",
      " 70/172 [===========>..................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000Epoch 37/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6379 - val_loss: 0.6781 - val_accuracy: 0.5704\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6382 - val_loss: 0.6764 - val_accuracy: 0.5704\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6379 - val_loss: 0.6792 - val_accuracy: 0.5704\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6379 - val_loss: 0.6760 - val_accuracy: 0.5704\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6375 - val_loss: 0.6844 - val_accuracy: 0.5725\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6386 - val_loss: 0.6789 - val_accuracy: 0.5704\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6384 - val_loss: 0.6826 - val_accuracy: 0.5725\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6377 - val_loss: 0.6726 - val_accuracy: 0.5704\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6379 - val_loss: 0.6771 - val_accuracy: 0.5725\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6379 - val_loss: 0.6751 - val_accuracy: 0.5704\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6379 - val_loss: 0.6778 - val_accuracy: 0.5704\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6379 - val_loss: 0.6718 - val_accuracy: 0.5704\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6373 - val_loss: 0.6752 - val_accuracy: 0.5704\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6380 - val_loss: 0.6799 - val_accuracy: 0.5704\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6375 - val_loss: 0.6778 - val_accuracy: 0.5704\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6382 - val_loss: 0.6776 - val_accuracy: 0.5725\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6371 - val_loss: 0.6785 - val_accuracy: 0.5725\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6377 - val_loss: 0.6845 - val_accuracy: 0.5725\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6375 - val_loss: 0.6759 - val_accuracy: 0.5704\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6379 - val_loss: 0.6791 - val_accuracy: 0.5704\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6382 - val_loss: 0.6774 - val_accuracy: 0.5725\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6375 - val_loss: 0.6675 - val_accuracy: 0.5704\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6384 - val_loss: 0.6775 - val_accuracy: 0.5725\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6373 - val_loss: 0.6669 - val_accuracy: 0.6242\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6369 - val_loss: 0.6664 - val_accuracy: 0.6242\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6351 - val_loss: 0.6817 - val_accuracy: 0.5725\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6368 - val_loss: 0.6836 - val_accuracy: 0.5725\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 1ms/step loss: 0.6565 - accuracy: 0.6316\n",
      "142/172 [=======================>......] - ETA: 0s - loss: 0.6533 - accuracy: 0.6371Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying2/tuner0.json\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6373 - val_loss: 0.6811 - val_accuracy: 0.5704\n",
      "Epoch 65/100\n",
      " 46/172 [=======>......................] - ETA: 0s - loss: 0.6459 - accuracy: 0.6488Epoch 1/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6384 - val_loss: 0.6810 - val_accuracy: 0.5725\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6371 - val_loss: 0.6861 - val_accuracy: 0.5424\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6535 - accuracy: 0.6384 - val_loss: 0.6762 - val_accuracy: 0.5704\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6379 - val_loss: 0.6833 - val_accuracy: 0.5725\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6379 - val_loss: 0.6808 - val_accuracy: 0.5725\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9556e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      " 90/172 [==============>...............] - ETA: 0s - loss: 0.6503 - accuracy: 0.6441Epoch 3/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6375 - val_loss: 0.6786 - val_accuracy: 0.5704\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.9051e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6380 - val_loss: 0.6843 - val_accuracy: 0.5725\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.6168e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6382 - val_loss: 0.6841 - val_accuracy: 0.5725\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.0706e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6373 - val_loss: 0.6863 - val_accuracy: 0.5725\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.1342e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6380 - val_loss: 0.6765 - val_accuracy: 0.5704\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5897e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6377 - val_loss: 0.6821 - val_accuracy: 0.5725\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.2631e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6379 - val_loss: 0.6808 - val_accuracy: 0.5725\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.0018e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6379 - val_loss: 0.6782 - val_accuracy: 0.5704\n",
      "143/172 [=======================>......] - ETA: 0s - loss: 9.6389e-10 - accuracy: 1.0000Epoch 78/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 8.0576e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6382 - val_loss: 0.6816 - val_accuracy: 0.5725\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.1865e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "118/172 [===================>..........] - ETA: 0s - loss: 0.6544 - accuracy: 0.6364Epoch 12/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6390 - val_loss: 0.6761 - val_accuracy: 0.5704\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.6621e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6379 - val_loss: 0.6708 - val_accuracy: 0.5704\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.0088e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6377 - val_loss: 0.6750 - val_accuracy: 0.5704\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.3555e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6375 - val_loss: 0.6756 - val_accuracy: 0.5704\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.9199e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6382 - val_loss: 0.6743 - val_accuracy: 0.5704\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.2666e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.6373 - val_loss: 0.6840 - val_accuracy: 0.5725\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 3.0488e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6384 - val_loss: 0.6796 - val_accuracy: 0.5725\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6133e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "155/172 [==========================>...] - ETA: 0s - loss: 0.6521 - accuracy: 0.6383Epoch 19/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6379 - val_loss: 0.6776 - val_accuracy: 0.5725\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 2.6133e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6531 - accuracy: 0.6373 - val_loss: 0.6803 - val_accuracy: 0.5631\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.3955e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6386 - val_loss: 0.6825 - val_accuracy: 0.5725\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6133e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "146/172 [========================>.....] - ETA: 0s - loss: 0.6531 - accuracy: 0.6351Epoch 22/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6371 - val_loss: 0.6810 - val_accuracy: 0.5631\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.0488e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6371 - val_loss: 0.6767 - val_accuracy: 0.5611\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.2666e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6373 - val_loss: 0.6880 - val_accuracy: 0.5745\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9600e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6379 - val_loss: 0.6810 - val_accuracy: 0.5652\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.7422e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6380 - val_loss: 0.6775 - val_accuracy: 0.5611\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6377 - val_loss: 0.6790 - val_accuracy: 0.5631\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9600e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6382 - val_loss: 0.6812 - val_accuracy: 0.5652\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6386 - val_loss: 0.6786 - val_accuracy: 0.5631\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6382 - val_loss: 0.6834 - val_accuracy: 0.5631\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6379 - val_loss: 0.6815 - val_accuracy: 0.5652\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5244e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6377 - val_loss: 0.6744 - val_accuracy: 0.5631\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.7422e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6382 - val_loss: 0.6813 - val_accuracy: 0.5652\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 2ms/step loss: 1.0798e-10 - accuracy: 1.00\n",
      "120/172 [===================>..........] - ETA: 0s - loss: 1.2418e-10 - accuracy: 1.0000    | Etapa 5 WDOFUT_F_0_30min - Time: 6406.429587364197\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3066e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.0889e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1777e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.5332e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1777e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1777e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.3555e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1777e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WINFUT_F_0_30min - Time: 6472.692547798157\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "143/143 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5065 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 2/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 3/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 4/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 5/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 6/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 7/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 8/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 9/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 10/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 11/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 12/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 13/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 14/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 15/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 16/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 17/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 18/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 19/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 20/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 21/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 22/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 23/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 24/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 25/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 26/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 27/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 28/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 29/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 30/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 31/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 32/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 33/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 34/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 35/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 36/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 37/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 38/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 39/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 40/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 41/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 42/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 43/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 44/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 45/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 46/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 47/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 48/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 49/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 50/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 51/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 52/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 53/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 54/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 55/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 56/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 57/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 58/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 59/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 60/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 61/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 62/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 63/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 64/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 65/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 66/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 67/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 68/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 69/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 70/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "42/42 [==============================] - 0s 963us/step\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 4ms/step - loss: 0.3791 - accuracy: 0.8414 - val_loss: 0.1103 - val_accuracy: 0.9280\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 6.0902e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 9.9603e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.8320e-04 - accuracy: 1.0000 - val_loss: 6.1080e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.4754e-04 - accuracy: 0.9996 - val_loss: 0.0081 - val_accuracy: 0.9988\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.3099e-04 - accuracy: 1.0000 - val_loss: 2.1097e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.8632e-05 - accuracy: 1.0000 - val_loss: 2.5837e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.5544e-05 - accuracy: 1.0000 - val_loss: 1.4256e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.2572e-05 - accuracy: 1.0000 - val_loss: 1.1925e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.9721e-05 - accuracy: 1.0000 - val_loss: 1.0870e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.6128e-05 - accuracy: 1.0000 - val_loss: 1.0158e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.3665e-05 - accuracy: 1.0000 - val_loss: 8.6069e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.1559e-05 - accuracy: 1.0000 - val_loss: 7.0655e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.0193e-05 - accuracy: 1.0000 - val_loss: 6.1775e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.8207e-06 - accuracy: 1.0000 - val_loss: 5.2652e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.0352e-06 - accuracy: 1.0000 - val_loss: 5.2240e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.8775e-06 - accuracy: 1.0000 - val_loss: 4.5753e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.0080e-06 - accuracy: 1.0000 - val_loss: 3.7794e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.5611e-06 - accuracy: 1.0000 - val_loss: 3.5654e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.9160e-06 - accuracy: 1.0000 - val_loss: 3.0277e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.4557e-06 - accuracy: 1.0000 - val_loss: 2.9124e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.9944e-06 - accuracy: 1.0000 - val_loss: 2.5343e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.4850e-06 - accuracy: 1.0000 - val_loss: 2.1295e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.2554e-06 - accuracy: 1.0000 - val_loss: 2.0054e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.8822e-06 - accuracy: 1.0000 - val_loss: 1.8565e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.5441e-06 - accuracy: 1.0000 - val_loss: 1.5290e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.4121e-06 - accuracy: 1.0000 - val_loss: 1.4730e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1074e-06 - accuracy: 1.0000 - val_loss: 1.2673e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.9790e-06 - accuracy: 1.0000 - val_loss: 1.1742e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.7821e-06 - accuracy: 1.0000 - val_loss: 1.0628e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.6032e-06 - accuracy: 1.0000 - val_loss: 9.1561e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.4941e-06 - accuracy: 1.0000 - val_loss: 8.6230e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.3382e-06 - accuracy: 1.0000 - val_loss: 8.1951e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.1908e-06 - accuracy: 1.0000 - val_loss: 7.1200e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.1036e-06 - accuracy: 1.0000 - val_loss: 6.6935e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.0057e-06 - accuracy: 1.0000 - val_loss: 5.9264e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 9.1955e-07 - accuracy: 1.0000 - val_loss: 5.2822e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.4310e-07 - accuracy: 1.0000 - val_loss: 4.6751e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 7.6957e-07 - accuracy: 1.0000 - val_loss: 4.2619e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.8722e-07 - accuracy: 1.0000 - val_loss: 3.8828e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.2617e-07 - accuracy: 1.0000 - val_loss: 3.5748e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.6224e-07 - accuracy: 1.0000 - val_loss: 3.3186e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.0967e-07 - accuracy: 1.0000 - val_loss: 2.9839e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.5830e-07 - accuracy: 1.0000 - val_loss: 2.8092e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.1336e-07 - accuracy: 1.0000 - val_loss: 2.5426e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.7148e-07 - accuracy: 1.0000 - val_loss: 2.3161e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.4195e-07 - accuracy: 1.0000 - val_loss: 2.1458e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.1795e-07 - accuracy: 1.0000 - val_loss: 1.9488e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.9047e-07 - accuracy: 1.0000 - val_loss: 1.8452e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.5716e-07 - accuracy: 1.0000 - val_loss: 1.7163e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.3988e-07 - accuracy: 1.0000 - val_loss: 1.6023e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1229e-07 - accuracy: 1.0000 - val_loss: 1.4231e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.9702e-07 - accuracy: 1.0000 - val_loss: 1.3135e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.8648e-07 - accuracy: 1.0000 - val_loss: 1.2795e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.6808e-07 - accuracy: 1.0000 - val_loss: 1.1003e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.4177e-07 - accuracy: 1.0000 - val_loss: 1.0514e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.3165e-07 - accuracy: 1.0000 - val_loss: 9.7144e-08 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.2284e-07 - accuracy: 1.0000 - val_loss: 8.7223e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.1594e-07 - accuracy: 1.0000 - val_loss: 8.2928e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.0702e-07 - accuracy: 1.0000 - val_loss: 7.8189e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 9.7636e-08 - accuracy: 1.0000 - val_loss: 7.6116e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.8510e-08 - accuracy: 1.0000 - val_loss: 6.8268e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.2915e-08 - accuracy: 1.0000 - val_loss: 6.1308e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 7.9385e-08 - accuracy: 1.0000 - val_loss: 5.7013e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 7.4182e-08 - accuracy: 1.0000 - val_loss: 5.5088e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 7.0233e-08 - accuracy: 1.0000 - val_loss: 5.0794e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.7944e-08 - accuracy: 1.0000 - val_loss: 4.7536e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.1224e-08 - accuracy: 1.0000 - val_loss: 3.9687e-08 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.8452e-08 - accuracy: 1.0000 - val_loss: 3.9687e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.4922e-08 - accuracy: 1.0000 - val_loss: 3.7466e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.3641e-08 - accuracy: 1.0000 - val_loss: 3.7318e-08 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.9693e-08 - accuracy: 1.0000 - val_loss: 2.7396e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.7078e-08 - accuracy: 1.0000 - val_loss: 2.9321e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.2894e-08 - accuracy: 1.0000 - val_loss: 2.7100e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.8710e-08 - accuracy: 1.0000 - val_loss: 2.2805e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.6096e-08 - accuracy: 1.0000 - val_loss: 2.2805e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.4710e-08 - accuracy: 1.0000 - val_loss: 2.0880e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.3455e-08 - accuracy: 1.0000 - val_loss: 2.0880e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.2461e-08 - accuracy: 1.0000 - val_loss: 2.0880e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1834e-08 - accuracy: 1.0000 - val_loss: 1.6586e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.0186e-08 - accuracy: 1.0000 - val_loss: 1.6586e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.5114e-08 - accuracy: 1.0000 - val_loss: 1.6586e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.3231e-08 - accuracy: 1.0000 - val_loss: 1.4364e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.1453e-08 - accuracy: 1.0000 - val_loss: 1.4364e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.0512e-08 - accuracy: 1.0000 - val_loss: 1.0810e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 9.1518e-09 - accuracy: 1.0000 - val_loss: 1.0810e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 8.9426e-09 - accuracy: 1.0000 - val_loss: 1.0810e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 7.6614e-09 - accuracy: 1.0000 - val_loss: 1.0810e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 7.7921e-09 - accuracy: 1.0000 - val_loss: 6.5158e-09 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 6.4586e-09 - accuracy: 1.0000 - val_loss: 6.5158e-09 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.5434e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.4911e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.0989e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 5.1512e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.4713e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 4.0007e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.6869e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 3.0855e-09 - accuracy: 1.0000 - val_loss: 4.5907e-09 - val_accuracy: 1.0000\n",
      "42/42 [==============================] - 0s 926us/step\n",
      "    | Etapa 5 PETR3_B_0_30min - Time: 4968.1819887161255\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WINFUT_F_0_60min - Obtendo resultados!\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "    | Etapa 6 PETR3_B_0_30min - Obtendo resultados!\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 06:51:28.218601: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:28.279023: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:28.368979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:28.429883: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:28.443530: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:28.511130: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 06:51:29.471540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 06:51:29.543085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-21 06:51:29.689998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 PETR3_B_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 WINFUT_F_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 WDOFUT_F_0_30min - Obtendo resultados!\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerando estrategias...\n",
      "Files: ['PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/classification \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/regression \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_30min_Predictions.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/statistic \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble1 \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble2 \n",
      "\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\", \"main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
