{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "dataNames = [\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "    \"WINFUT_F_0_30min\"\n",
    "]\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll2 import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 11:38:51.263327: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:38:51.938784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:38:51.941277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 11:38:53.805484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 11:39:01.844888: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.000786: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.002036: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 11:39:02.056709: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.152196: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.153010: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 11:39:02.337932: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.436669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:02.437434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 11:39:03.345724: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:03.481639: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-25 11:39:03.482401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 11:39:04.113645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-25 11:39:04.197848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-25 11:39:04.833806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-25 11:39:05.639440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 2 PETR3_B_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_60min - Obtendo modelos de classificação otimizados\n",
      "             -- PETR3_B_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_60min - X_train: (2728, 4) | X_test: (2728, 4) | Y_train: (2728,) | Y_test: (2728,)\n",
      "                 * PETR3_B_0_60min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "    | Etapa 2 WDOFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WDOFUT_F_0_60min - Obtendo modelos de classificação otimizados\n",
      "             -- WDOFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_60min - X_train: (3206, 4) | X_test: (3206, 4) | Y_train: (3206,) | Y_test: (3206,)\n",
      "                 * WDOFUT_F_0_60min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "    | Etapa 2 WINFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_60min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_60min - X_train: (3205, 4) | X_test: (3205, 4) | Y_train: (3205,) | Y_test: (3205,)\n",
      "                 * WINFUT_F_0_60min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "    | Etapa 2 PETR3_B_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- PETR3_B_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_30min - X_train: (5364, 4) | X_test: (5364, 4) | Y_train: (5364,) | Y_test: (5364,)\n",
      "                 * PETR3_B_0_30min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_60min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_60min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 PETR3_B_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_60min -X_train: (227, 1) | X_test: (152, 1) | Y_train: (227, 2) | Y_test: (152, 2)\n",
      "                     * PETR3_B_0_60min - ARIMA \n",
      "                     * PETR3_B_0_60min - SARIMA \n",
      "                 * PETR3_B_0_30min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * PETR3_B_0_30min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 PETR3_B_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_30min -X_train: (447, 1) | X_test: (299, 1) | Y_train: (447, 2) | Y_test: (299, 2)\n",
      "                     * PETR3_B_0_30min - ARIMA \n",
      "LU decomposition error.\n",
      "                     * PETR3_B_0_30min - SARIMA \n",
      "                     * PETR3_B_0_60min - GARCH \n",
      "        - Etapa 2.3 PETR3_B_0_60min - Obtendo modelos de regressão otimizados\n",
      "PETR3_B_0_60min Shape:  (2318, 1, 4)\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/lstm/tuner0.json\n",
      "                     * PETR3_B_0_60min - LSTM \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 13:35:39.239565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-25 13:35:39.243104: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     * PETR3_B_0_60min - LSTM \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 100)            42000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 80)             57920     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20)                8080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108021 (421.96 KB)\n",
      "Trainable params: 108021 (421.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "LSTM:  None\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/mlp/tuner0.json\n",
      "                     * PETR3_B_0_60min - MLP \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 60)             300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 44)             2684      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 12)             540       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 44)             572       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 1)              45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4141 (16.18 KB)\n",
      "Trainable params: 4141 (16.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "MLP:   None\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/regression/rnn/tuner0.json\n",
      "                     * PETR3_B_0_60min - RNN \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1, 112)            13104     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 112)            0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 1, 80)             15440     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 80)             0         \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 1, 96)             16992     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 96)             0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 1, 80)             14160     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 80)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59777 (233.50 KB)\n",
      "Trainable params: 59777 (233.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "RNN:   None\n",
      "    | Etapa 2 PETR3_B_0_60min - Time: 7010.076345443726\n",
      "    | Etapa 2 WINFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_30min - X_train: (6440, 4) | X_test: (6440, 4) | Y_train: (6440,) | Y_test: (6440,)\n",
      "                 * WINFUT_F_0_30min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * WINFUT_F_0_60min - KNN \n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "                 * WINFUT_F_0_60min - LR\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "        - Etapa 2.2 WINFUT_F_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_60min -X_train: (267, 1) | X_test: (179, 1) | Y_train: (267, 2) | Y_test: (179, 2)\n",
      "                     * WINFUT_F_0_60min - ARIMA \n",
      "                     * WINFUT_F_0_60min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * PETR3_B_0_30min - GARCH \n",
      "                     * WINFUT_F_0_60min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "WINFUT_F_0_60min Shape:  (2724, 1, 4)\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/lstm/tuner0.json\n",
      "                     * WINFUT_F_0_60min - LSTM \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 18:05:44.576154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-25 18:05:44.578442: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     * WINFUT_F_0_60min - LSTM \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 40)             7200      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 60)             24240     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 80)                45120     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76641 (299.38 KB)\n",
      "Trainable params: 76641 (299.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "LSTM:  None\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/mlp/tuner0.json\n",
      "                     * WINFUT_F_0_60min - MLP \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 60)             300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 44)             2684      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 44)             1980      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 12)             540       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 1)              13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5517 (21.55 KB)\n",
      "Trainable params: 5517 (21.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "MLP:   None\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/rnn/tuner0.json\n",
      "                     * WINFUT_F_0_60min - RNN \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1, 128)            17024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 128)            0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 1, 32)             5152      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 32)             0         \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 32)             0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 1, 128)            20608     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1)              129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44993 (175.75 KB)\n",
      "Trainable params: 44993 (175.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "RNN:   None\n",
      "    | Etapa 2 WINFUT_F_0_60min - Time: 23216.584857463837\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WDOFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_30min - X_train: (6439, 4) | X_test: (6439, 4) | Y_train: (6439,) | Y_test: (6439,)\n",
      "                 * WDOFUT_F_0_30min - SVM\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "        - Etapa 2.3 PETR3_B_0_30min - Obtendo modelos de regressão otimizados\n",
      "PETR3_B_0_30min Shape:  (4559, 1, 4)\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/lstm/tuner0.json\n",
      "                     * PETR3_B_0_30min - LSTM \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 18:29:02.569810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-25 18:29:02.572650: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     * PETR3_B_0_30min - LSTM \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 40)             7200      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 80)             38720     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60)                33840     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79821 (311.80 KB)\n",
      "Trainable params: 79821 (311.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "LSTM:  None\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/mlp/tuner0.json\n",
      "                     * PETR3_B_0_30min - MLP \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 60)             300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 12)             732       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 44)             572       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 60)             2700      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4365 (17.05 KB)\n",
      "Trainable params: 4365 (17.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "MLP:   None\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/regression/rnn/tuner0.json\n",
      "                     * PETR3_B_0_30min - RNN \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1, 112)            13104     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 112)            0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 1, 80)             15440     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 80)             0         \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 1, 80)             12880     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 80)             0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 1, 96)             16992     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 96)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 1)              97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58513 (228.57 KB)\n",
      "Trainable params: 58513 (228.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "RNN:   None\n",
      "    | Etapa 2 PETR3_B_0_30min - Time: 24617.549162626266\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sr-souza/Desktop/TCC-AI/src/runAll.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sr-souza/Desktop/TCC-AI/src/runAll.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m setDivision \u001b[39m=\u001b[39m [\u001b[39m0.1\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.2\u001b[39m]              \u001b[39m# Size of the [optimization, train, test] set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sr-souza/Desktop/TCC-AI/src/runAll.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m outputName  \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFechamento\u001b[39m\u001b[39m\"\u001b[39m                 \u001b[39m# Name of the output variable0\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sr-souza/Desktop/TCC-AI/src/runAll.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(delayed(getOptmizedModels)(dataName, setDivision) \u001b[39mfor\u001b[39;49;00m dataName \u001b[39min\u001b[39;49;00m dataNames)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sr-souza/Desktop/TCC-AI/src/runAll.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m commit_and_push(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels optimized \u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll2 import getOptmizedModels, trainModels, getEnsambles, getResults, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "dataNames = [\n",
    "    \"PETR3_B_0_60min\",\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"WDOFUT_F_0_60min\",\n",
    "\n",
    "    \"PETR3_B_0_30min\",\n",
    "    \"WINFUT_F_0_30min\",\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models optimized {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models trained {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
