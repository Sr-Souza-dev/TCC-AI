{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala todas as Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/sr-souza/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/sr-souza/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting enum\n",
      "  Using cached enum-0.4.7.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m Error in sys.excepthook:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 62, in apport_excepthook\n",
      "  \u001b[31m   \u001b[0m     if not enabled():\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 24, in enabled\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Original exception was:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/tokenize.py\", line 33, in <module>\n",
      "  \u001b[31m   \u001b[0m     import re\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/re.py\", line 145, in <module>\n",
      "  \u001b[31m   \u001b[0m     class RegexFlag(enum.IntFlag):\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'enum' has no attribute 'IntFlag'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: enum34 in /home/sr-souza/.local/lib/python3.10/site-packages (1.1.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/sr-souza/.local/lib/python3.10/site-packages (1.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /home/sr-souza/.local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/lib/python3/dist-packages (from statsmodels) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arch in /home/sr-souza/.local/lib/python3.10/site-packages (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/lib/python3/dist-packages (from arch) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (2.0.3)\n",
      "Requirement already satisfied: statsmodels>=0.12 in /home/sr-souza/.local/lib/python3.10/site-packages (from arch) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1->arch) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from pandas>=1.1->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from statsmodels>=0.12->arch) (23.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels>=0.12->arch) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/sr-souza/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sr-souza/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/sr-souza/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tuner in /home/sr-souza/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: keras-core in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
      "Requirement already satisfied: packaging in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
      "Requirement already satisfied: namex in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.9.0)\n",
      "Requirement already satisfied: dm-tree in /home/sr-souza/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sr-souza/.local/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/sr-souza/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in /home/sr-souza/.local/lib/python3.10/site-packages (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gitpython in /home/sr-souza/.local/lib/python3.10/site-packages (3.1.40)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from gitpython) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/sr-souza/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install enum\n",
    "%pip install enum34\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install arch\n",
    "%pip install tensorflow\n",
    "%pip install keras-tuner\n",
    "%pip install joblib\n",
    "%pip install gitpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versões de bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:   3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "Pandas:   2.0.3\n",
      "Numpy:    1.24.3\n",
      "Matplt:   3.5.1\n",
      "Sklearn:  1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mt\n",
    "import sys\n",
    "\n",
    "print(\"Python:  \", sys.version)\n",
    "print(\"Pandas:  \", pd.__version__)\n",
    "print(\"Numpy:   \", np.__version__)\n",
    "print(\"Matplt:  \", mt.__version__)\n",
    "print(\"Sklearn: \", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define as Variaveis de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataNames = [\n",
    "#     \"PETR3_B_0_1min\", \"PETR3_B_0_5min\", \"PETR3_B_0_15min\", \"PETR3_B_0_30min\", \"PETR3_B_0_60min\",\n",
    "#     \"PETR4_B_0_1min\", \"PETR4_B_0_5min\", \"PETR4_B_0_15min\", \"PETR4_B_0_30min\", \"PETR4_B_0_60min\",\n",
    "#     \"WDOFUT_F_0_1min\", \"WDOFUT_F_0_5min\", \"WDOFUT_F_0_15min\", \"WDOFUT_F_0_30min\", \"WDOFUT_F_0_60min\",\n",
    "#     \"WINFUT_F_0_1min\", \"WINFUT_F_0_5min\", \"WINFUT_F_0_15min\", \"WINFUT_F_0_30min\", \"WINFUT_F_0_60min\",\n",
    "# ]\n",
    "dataNames = [\n",
    "    \"WINFUT_F_0_60min\",\n",
    "    \"PETR3_B_0_60min\",\n",
    "\n",
    "    \"WDOFUT_F_0_30min\",\n",
    "    \"WINFUT_F_0_30min\", \n",
    "    \"PETR3_B_0_30min\"\n",
    "]\n",
    "\n",
    "# [\"PETR3_B_0_60min\", \"PETR4_B_0_15min\",]\n",
    "\n",
    "setDivision = [0.1, 0.7, 0.2]              # Size of the [optimization, train, test] set\n",
    "outputName  = \"Fechamento\"                 # Name of the output variable0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executa o código em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:00:36.558703: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:00:37.177578: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:00:38.982539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from executeAll import getDatabase, getOptmizedModels, trainModels, getEnsambles, getResults, RunSolution, commit_and_push\n",
    "from datetime import datetime\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(delayed(RunSolution)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "# print(results)\n",
    "commit_and_push(f\"Variaveis definidas {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:25:38.056764: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:38.115440: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:25:38.524514: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:38.585627: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:25:38.950387: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:39.010040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:39.033786: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:39.113975: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 15:25:39.256046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-18 15:25:40.133228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 1 WDOFUT_F_0_30min - Gerando base de dados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:25:40.493298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-18 15:25:40.596943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 1 WINFUT_F_0_60min - Gerando base de dados\n",
      "    | Etapa 1 WINFUT_F_0_30min - Gerando base de dados\n",
      "    | Etapa 1 PETR3_B_0_60min - Gerando base de dados\n",
      "    | Etapa 1 PETR3_B_0_60min - Time: 876.1824910640717\n",
      "    | Etapa 1 PETR3_B_0_30min - Gerando base de dados\n",
      "    | Etapa 1 WINFUT_F_0_60min - Time: 1284.5878505706787\n",
      "    | Etapa 1 PETR3_B_0_30min - Time: 1586.9180657863617\n",
      "    | Etapa 1 WDOFUT_F_0_30min - Time: 2525.679513692856\n",
      "    | Etapa 1 WINFUT_F_0_30min - Time: 2572.131720304489\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getDatabase)(dataName, outputName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database generated {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 2 WINFUT_F_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_60min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_60min - X_train: (3205, 4) | X_test: (3205, 4) | Y_train: (3205,) | Y_test: (3205,)\n",
      "                 * WINFUT_F_0_60min - SVM\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "    | Etapa 2 PETR3_B_0_60min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_60min - Obtendo modelos de classificação otimizados\n",
      "    | Etapa 2 WDOFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WDOFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- PETR3_B_0_60min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_60min - X_train: (2728, 4) | X_test: (2728, 4) | Y_train: (2728,) | Y_test: (2728,)\n",
      "                 * PETR3_B_0_60min - SVM\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "             -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WDOFUT_F_0_30min - X_train: (6439, 4) | X_test: (6439, 4) | Y_train: (6439,) | Y_test: (6439,)\n",
      "                 * WDOFUT_F_0_30min - SVM\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:08:45.141752: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 16:08:45.353772: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 16:08:49.010611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 * PETR3_B_0_60min - KNN \n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "    | Etapa 2 WINFUT_F_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 WINFUT_F_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                WINFUT_F_0_30min - X_train: (6440, 4) | X_test: (6440, 4) | Y_train: (6440,) | Y_test: (6440,)\n",
      "                 * WINFUT_F_0_30min - SVM\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "                 * PETR3_B_0_60min - LR\n",
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "        - Etapa 2.2 PETR3_B_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_60min -X_train: (227, 1) | X_test: (152, 1) | Y_train: (227, 2) | Y_test: (152, 2)\n",
      "                     * PETR3_B_0_60min - ARIMA \n",
      "                     * PETR3_B_0_60min - SARIMA \n",
      "                 * WINFUT_F_0_60min - KNN \n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "                 * WINFUT_F_0_60min - LR\n",
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "        - Etapa 2.2 WINFUT_F_0_60min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_60min -X_train: (267, 1) | X_test: (179, 1) | Y_train: (267, 2) | Y_test: (179, 2)\n",
      "                     * WINFUT_F_0_60min - ARIMA \n",
      "                     * WINFUT_F_0_60min - SARIMA \n",
      "                     * PETR3_B_0_60min - GARCH \n",
      "        - Etapa 2.3 PETR3_B_0_60min - Obtendo modelos de regressão otimizados\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                 * WINFUT_F_0_30min - KNN \n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "                 * WINFUT_F_0_30min - LR\n",
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "        - Etapa 2.2 WINFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WINFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WINFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WINFUT_F_0_30min - ARIMA \n",
      "                     * WINFUT_F_0_60min - GARCH \n",
      "                     * WINFUT_F_0_30min - SARIMA \n",
      "        - Etapa 2.3 WINFUT_F_0_60min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/regression/rnn/tuner0.json\n",
      "                 -- WINFUT_F_0_60min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WINFUT_F_0_60min - LSTM \n",
      "                     * WINFUT_F_0_60min - MLP \n",
      "                     * WINFUT_F_0_60min - RNN \n",
      "    | Etapa 2 WINFUT_F_0_60min - Time: 7210.851075410843\n",
      "    | Etapa 2 PETR3_B_0_30min - Obtendo modelos otimizados!\n",
      "        - Etapa 2.1 PETR3_B_0_30min - Obtendo modelos de classificação otimizados\n",
      "             -- PETR3_B_0_30min - Inicio da otimização dos modelos de Classificação \n",
      "                PETR3_B_0_30min - X_train: (5364, 4) | X_test: (5364, 4) | Y_train: (5364,) | Y_test: (5364,)\n",
      "                 * PETR3_B_0_30min - SVM\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "                 * PETR3_B_0_30min - KNN \n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "                 * PETR3_B_0_30min - LR\n",
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "        - Etapa 2.2 PETR3_B_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    PETR3_B_0_30min -X_train: (447, 1) | X_test: (299, 1) | Y_train: (447, 2) | Y_test: (299, 2)\n",
      "                     * PETR3_B_0_30min - ARIMA \n",
      "LU decomposition error.\n",
      "                     * PETR3_B_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                     * WINFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WINFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/regression/rnn/tuner0.json\n",
      "                 -- WINFUT_F_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WINFUT_F_0_30min - LSTM \n",
      "                     * WINFUT_F_0_30min - MLP \n",
      "                     * WINFUT_F_0_30min - RNN \n",
      "    | Etapa 2 WINFUT_F_0_30min - Time: 13785.162484407425\n",
      "                     * PETR3_B_0_30min - GARCH \n",
      "                 -- PETR3_B_0_60min - Inicio da otimização dos modelos de Regressão \n",
      "                     * PETR3_B_0_60min - LSTM \n",
      "                     * PETR3_B_0_60min - MLP \n",
      "                     * PETR3_B_0_60min - RNN \n",
      "    | Etapa 2 PETR3_B_0_60min - Time: 15757.293642520905\n",
      "        - Etapa 2.3 PETR3_B_0_30min - Obtendo modelos de regressão otimizados\n",
      "                 * WDOFUT_F_0_30min - KNN \n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "                 * WDOFUT_F_0_30min - LR\n",
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "        - Etapa 2.2 WDOFUT_F_0_30min - Obtendo modelos estatisticos otimizados\n",
      "                 -- WDOFUT_F_0_30min - Inicio da otimização dos modelos Estatisticos \n",
      "                    WDOFUT_F_0_30min -X_train: (537, 1) | X_test: (358, 1) | Y_train: (537, 2) | Y_test: (358, 2)\n",
      "                     * WDOFUT_F_0_30min - ARIMA \n",
      "                     * WDOFUT_F_0_30min - SARIMA \n",
      "LU decomposition error.\n",
      "LU decomposition error.\n",
      "                 -- PETR3_B_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * PETR3_B_0_30min - LSTM \n",
      "                     * PETR3_B_0_30min - MLP \n",
      "                     * PETR3_B_0_30min - RNN \n",
      "    | Etapa 2 PETR3_B_0_30min - Time: 23100.27754354477\n",
      "                     * WDOFUT_F_0_30min - GARCH \n",
      "        - Etapa 2.3 WDOFUT_F_0_30min - Obtendo modelos de regressão otimizados\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/lstm/tuner0.json\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/mlp/tuner0.json\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/regression/rnn/tuner0.json\n",
      "                 -- WDOFUT_F_0_30min - Inicio da otimização dos modelos de Regressão \n",
      "                     * WDOFUT_F_0_30min - LSTM \n",
      "                     * WDOFUT_F_0_30min - MLP \n",
      "                     * WDOFUT_F_0_30min - RNN \n",
      "    | Etapa 2 WDOFUT_F_0_30min - Time: 33572.31802558899\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getOptmizedModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"models optimized {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:01:18.301819: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:18.362793: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 19:01:18.708682: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:18.721257: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:18.780690: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:18.785323: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:18.931418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:19.001580: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 19:01:19.492054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 19:01:20.072898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 19:01:20.240332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 19:01:20.304425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 3 WINFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 WINFUT_F_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 PETR3_B_0_60min - Obtendo modelos já otimizados!\n",
      "    | Etapa 3 WDOFUT_F_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 WINFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WINFUT_F_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WINFUT_F_0_30min - Treinando modelos de regressão\n",
      "    | Etapa 4 WINFUT_F_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 WINFUT_F_0_60min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 WINFUT_F_0_60min - Treinando modelos de regressão\n",
      "    | Etapa 4 PETR3_B_0_60min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_60min - Treinando modelos de classificação\n",
      "    | Etapa 4 WDOFUT_F_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 WDOFUT_F_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 PETR3_B_0_60min - Treinando modelos de regressão\n",
      "        - Etapa 4.2 WDOFUT_F_0_30min - Treinando modelos de regressão\n",
      "51/51 [==============================] - 2s 3ms/step\n",
      "26/26 [==============================] - 2s 4ms/step\n",
      "22/22 [==============================] - 2s 4ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 2s 3ms/step\n",
      "26/26 [==============================] - 1s 2ms/step\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 1s 2ms/step\n",
      "101/101 [==============================] - 0s 3ms/step\n",
      "22/22 [==============================] - 1s 2ms/step\n",
      "51/51 [==============================] - 1s 2ms/step\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "        - Etapa 4.3 WINFUT_F_0_60min - Treinando modelos de estatística\n",
      "  1/202 [..............................] - ETA: 4s        - Etapa 4.3 PETR3_B_0_60min - Treinando modelos de estatística\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 0s 2ms/step\n",
      "202/202 [==============================] - 1s 3ms/step\n",
      "202/202 [==============================] - 1s 2ms/step\n",
      "        - Etapa 4.3 WDOFUT_F_0_30min - Treinando modelos de estatística\n",
      "        - Etapa 4.3 WINFUT_F_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WINFUT_F_0_60min - Time: 2016.1176371574402\n",
      "    | Etapa 3 PETR3_B_0_30min - Obtendo modelos já otimizados!\n",
      "    | Etapa 4 PETR3_B_0_30min - Treinando modelos!\n",
      "        - Etapa 4.1 PETR3_B_0_30min - Treinando modelos de classificação\n",
      "        - Etapa 4.2 PETR3_B_0_30min - Treinando modelos de regressão\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "42/42 [==============================] - 1s 2ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "168/168 [==============================] - 0s 1ms/step\n",
      "168/168 [==============================] - 0s 2ms/step\n",
      "        - Etapa 4.3 PETR3_B_0_30min - Treinando modelos de estatística\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 PETR3_B_0_60min - Time: 2424.0741589069366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr-souza/.local/lib/python3.10/site-packages/arch/univariate/base.py:766: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 4 WDOFUT_F_0_30min - Time: 3780.0653841495514\n",
      "    | Etapa 4 WINFUT_F_0_30min - Time: 4627.574077606201\n",
      "    | Etapa 4 PETR3_B_0_30min - Time: 3807.023294210434\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(trainModels)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"database trained {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo ensambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 WINFUT_F_0_60min - Obtendo ensambles!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 20:38:32.644752: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:32.702910: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:32.786927: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:32.794895: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:32.849015: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:32.855739: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 20:38:33.816448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 20:38:34.027700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 20:38:34.041707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 5 PETR3_B_0_60min - Obtendo ensambles!\n",
      "    | Etapa 5 WINFUT_F_0_30min - Obtendo ensambles!\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.6446 - accuracy: 0.5302 - val_loss: 0.6304 - val_accuracy: 0.7805\n",
      "Epoch 2/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7506 - val_loss: 0.5623 - val_accuracy: 0.8878\n",
      "Epoch 3/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7916 - val_loss: 0.4760 - val_accuracy: 0.9561\n",
      "Epoch 4/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.9720 - val_loss: 0.3733 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.6100e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.2652e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.2032e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.3411e-04 - accuracy: 1.0000 - val_loss: 8.9525e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.6395e-04 - accuracy: 1.0000 - val_loss: 7.8722e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0577e-04 - accuracy: 1.0000 - val_loss: 6.9678e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.5730e-04 - accuracy: 1.0000 - val_loss: 6.2123e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1659e-04 - accuracy: 1.0000 - val_loss: 5.5616e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8153e-04 - accuracy: 1.0000 - val_loss: 4.9956e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5083e-04 - accuracy: 1.0000 - val_loss: 4.4980e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2444e-04 - accuracy: 1.0000 - val_loss: 4.0740e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0170e-04 - accuracy: 1.0000 - val_loss: 3.6966e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8189e-04 - accuracy: 1.0000 - val_loss: 3.3743e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6450e-04 - accuracy: 1.0000 - val_loss: 3.0851e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4932e-04 - accuracy: 1.0000 - val_loss: 2.8264e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3603e-04 - accuracy: 1.0000 - val_loss: 2.5964e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 2.3946e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1373e-04 - accuracy: 1.0000 - val_loss: 2.2129e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0450e-04 - accuracy: 1.0000 - val_loss: 2.0453e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.6138e-05 - accuracy: 1.0000 - val_loss: 1.8995e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.8699e-05 - accuracy: 1.0000 - val_loss: 1.7657e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.1931e-05 - accuracy: 1.0000 - val_loss: 1.6416e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7.5814e-05 - accuracy: 1.0000 - val_loss: 1.5293e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.0290e-05 - accuracy: 1.0000 - val_loss: 1.4278e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.5259e-05 - accuracy: 1.0000 - val_loss: 1.3331e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.0663e-05 - accuracy: 1.0000 - val_loss: 1.2470e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.6487e-05 - accuracy: 1.0000 - val_loss: 1.1695e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.2683e-05 - accuracy: 1.0000 - val_loss: 1.0978e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.9204e-05 - accuracy: 1.0000 - val_loss: 1.0308e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.5991e-05 - accuracy: 1.0000 - val_loss: 9.6977e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.3029e-05 - accuracy: 1.0000 - val_loss: 9.1183e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.0303e-05 - accuracy: 1.0000 - val_loss: 8.5764e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7781e-05 - accuracy: 1.0000 - val_loss: 8.0856e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.5463e-05 - accuracy: 1.0000 - val_loss: 7.6277e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.3300e-05 - accuracy: 1.0000 - val_loss: 7.2039e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1307e-05 - accuracy: 1.0000 - val_loss: 6.7970e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9449e-05 - accuracy: 1.0000 - val_loss: 6.4265e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.7716e-05 - accuracy: 1.0000 - val_loss: 6.0825e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6109e-05 - accuracy: 1.0000 - val_loss: 5.7543e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4619e-05 - accuracy: 1.0000 - val_loss: 5.4455e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3212e-05 - accuracy: 1.0000 - val_loss: 5.1628e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1908e-05 - accuracy: 1.0000 - val_loss: 4.8908e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0684e-05 - accuracy: 1.0000 - val_loss: 4.6375e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.9547e-05 - accuracy: 1.0000 - val_loss: 4.3988e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8472e-05 - accuracy: 1.0000 - val_loss: 4.1758e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7465e-05 - accuracy: 1.0000 - val_loss: 3.9668e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6517e-05 - accuracy: 1.0000 - val_loss: 3.7642e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5633e-05 - accuracy: 1.0000 - val_loss: 3.5803e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4801e-05 - accuracy: 1.0000 - val_loss: 3.4028e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.4003e-05 - accuracy: 1.0000 - val_loss: 3.2320e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3260e-05 - accuracy: 1.0000 - val_loss: 3.0710e-05 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 6ms/step - loss: 0.4581 - accuracy: 0.8201 - val_loss: 0.1032 - val_accuracy: 0.9732\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9978 - val_loss: 0.0109 - val_accuracy: 0.9902\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9976\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.4156e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9976\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2859e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9976\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1823e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9976\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5400e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9976\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.1471e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9976\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.8027e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.9726e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.6332e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9976\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.6232e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.8635e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9976\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2745e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9976\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.7968e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4175e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1085e-05 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8470e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6326e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4515e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9976\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2963e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1638e-05 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9976\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0481e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.4805e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.5957e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.8194e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.1375e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.5282e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.9944e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.5087e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5.0746e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.6954e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4.3466e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.0331e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7372e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.4707e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2276e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.0016e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8042e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6184e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.4515e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2961e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1548e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0181e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.8962e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7826e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6739e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5738e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4809e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3947e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3161e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2444e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1728e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1079e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.0485e-06 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.9198e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9.3994e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.8990e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8.4644e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8.0165e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.6046e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7.2389e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.8527e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6.4819e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6.1677e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.8694e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.5634e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.3063e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5.0589e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9976\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.7946e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.5760e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.3446e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4.1425e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.9651e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.7624e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.5824e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.4122e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.2626e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.1129e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.9530e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.8187e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.6794e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5457e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2.4654e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3456e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.2381e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.1641e-07 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.0463e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.9707e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.9003e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7974e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.7069e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.6488e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.5742e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4832e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.4312e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3721e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3135e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2348e-07 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "    | Etapa 5 PETR3_B_0_60min - Time: 2696.159694671631\n",
      "    | Etapa 5 PETR3_B_0_30min - Obtendo ensambles!\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "86/86 [==============================] - 2s 7ms/step - loss: 0.6734 - accuracy: 0.6039 - val_loss: 0.6371 - val_accuracy: 0.6736\n",
      "Epoch 2/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6318 - val_loss: 0.6373 - val_accuracy: 0.6736\n",
      "Epoch 3/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6318 - val_loss: 0.6357 - val_accuracy: 0.6736\n",
      "Epoch 4/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6318 - val_loss: 0.6378 - val_accuracy: 0.6736\n",
      "Epoch 5/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6318 - val_loss: 0.6353 - val_accuracy: 0.6736\n",
      "Epoch 6/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6318 - val_loss: 0.6399 - val_accuracy: 0.6736\n",
      "Epoch 7/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6318 - val_loss: 0.6353 - val_accuracy: 0.6736\n",
      "Epoch 8/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6318 - val_loss: 0.6348 - val_accuracy: 0.6736\n",
      "Epoch 9/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6318 - val_loss: 0.6344 - val_accuracy: 0.6736\n",
      "Epoch 10/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6318 - val_loss: 0.6364 - val_accuracy: 0.6736\n",
      "Epoch 11/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6318 - val_loss: 0.6363 - val_accuracy: 0.6736\n",
      "Epoch 12/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6318 - val_loss: 0.6331 - val_accuracy: 0.6736\n",
      "Epoch 13/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6318 - val_loss: 0.6388 - val_accuracy: 0.6736\n",
      "Epoch 14/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6318 - val_loss: 0.6382 - val_accuracy: 0.6736\n",
      "Epoch 15/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6318 - val_loss: 0.6377 - val_accuracy: 0.6736\n",
      "Epoch 16/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6318 - val_loss: 0.6356 - val_accuracy: 0.6736\n",
      "Epoch 17/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6318 - val_loss: 0.6426 - val_accuracy: 0.6736\n",
      "Epoch 18/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6318 - val_loss: 0.6391 - val_accuracy: 0.6736\n",
      "Epoch 19/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6318 - val_loss: 0.6370 - val_accuracy: 0.6736\n",
      "Epoch 20/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6318 - val_loss: 0.6385 - val_accuracy: 0.6736\n",
      "Epoch 21/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6318 - val_loss: 0.6366 - val_accuracy: 0.6736\n",
      "Epoch 22/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6318 - val_loss: 0.6372 - val_accuracy: 0.6736\n",
      "Epoch 23/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6318 - val_loss: 0.6364 - val_accuracy: 0.6736\n",
      "Epoch 24/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6318 - val_loss: 0.6358 - val_accuracy: 0.6736\n",
      "Epoch 25/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6296 - val_loss: 0.6424 - val_accuracy: 0.6736\n",
      "Epoch 26/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6318 - val_loss: 0.6426 - val_accuracy: 0.6736\n",
      "Epoch 27/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6318 - val_loss: 0.6386 - val_accuracy: 0.6736\n",
      "Epoch 28/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6318 - val_loss: 0.6379 - val_accuracy: 0.6736\n",
      "Epoch 29/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6318 - val_loss: 0.6351 - val_accuracy: 0.6736\n",
      "Epoch 30/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.6318 - val_loss: 0.6367 - val_accuracy: 0.6736\n",
      "Epoch 31/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6318 - val_loss: 0.6529 - val_accuracy: 0.6403\n",
      "Epoch 32/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6233 - val_loss: 0.6348 - val_accuracy: 0.6736\n",
      "Epoch 33/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6303 - val_loss: 0.6352 - val_accuracy: 0.6736\n",
      "Epoch 34/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6318 - val_loss: 0.6356 - val_accuracy: 0.6736\n",
      "Epoch 35/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6372 - val_accuracy: 0.6736\n",
      "Epoch 36/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6318 - val_loss: 0.6354 - val_accuracy: 0.6736\n",
      "Epoch 37/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6318 - val_loss: 0.6369 - val_accuracy: 0.6736\n",
      "Epoch 38/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6318 - val_loss: 0.6365 - val_accuracy: 0.6736\n",
      "Epoch 39/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6351 - val_accuracy: 0.6736\n",
      "Epoch 40/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6353 - val_accuracy: 0.6736\n",
      "Epoch 41/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6375 - val_accuracy: 0.6736\n",
      "Epoch 42/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6318 - val_loss: 0.6345 - val_accuracy: 0.6736\n",
      "Epoch 43/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6318 - val_loss: 0.6360 - val_accuracy: 0.6736\n",
      "Epoch 44/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6318 - val_loss: 0.6391 - val_accuracy: 0.6736\n",
      "Epoch 45/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6318 - val_loss: 0.6340 - val_accuracy: 0.6736\n",
      "Epoch 46/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6318 - val_loss: 0.6418 - val_accuracy: 0.6736\n",
      "Epoch 47/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6318 - val_loss: 0.6347 - val_accuracy: 0.6736\n",
      "Epoch 48/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6348 - val_accuracy: 0.6736\n",
      "Epoch 49/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6318 - val_loss: 0.6416 - val_accuracy: 0.6736\n",
      "Epoch 50/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6451 - val_accuracy: 0.6736\n",
      "Epoch 51/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6318 - val_loss: 0.6359 - val_accuracy: 0.6736\n",
      "Epoch 52/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6318 - val_loss: 0.6372 - val_accuracy: 0.6736\n",
      "Epoch 53/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6318 - val_loss: 0.6385 - val_accuracy: 0.6736\n",
      "Epoch 54/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6346 - val_accuracy: 0.6736\n",
      "Epoch 55/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6318 - val_loss: 0.6360 - val_accuracy: 0.6736\n",
      "Epoch 56/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6318 - val_loss: 0.6363 - val_accuracy: 0.6736\n",
      "Epoch 57/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6318 - val_loss: 0.6352 - val_accuracy: 0.6736\n",
      "Epoch 58/70\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6318 - val_loss: 0.6358 - val_accuracy: 0.6736\n",
      "Epoch 59/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6318 - val_loss: 0.6371 - val_accuracy: 0.6736\n",
      "Epoch 60/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6318 - val_loss: 0.6384 - val_accuracy: 0.6736\n",
      "Epoch 61/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6318 - val_loss: 0.6348 - val_accuracy: 0.6736\n",
      "Epoch 62/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6318 - val_loss: 0.6360 - val_accuracy: 0.6736\n",
      "Epoch 63/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6318 - val_loss: 0.6368 - val_accuracy: 0.6736\n",
      "Epoch 64/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6318 - val_loss: 0.6355 - val_accuracy: 0.6736\n",
      "Epoch 65/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6318 - val_loss: 0.6371 - val_accuracy: 0.6736\n",
      "Epoch 66/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6318 - val_loss: 0.6385 - val_accuracy: 0.6736\n",
      "Epoch 67/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6318 - val_loss: 0.6349 - val_accuracy: 0.6736\n",
      "Epoch 68/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6318 - val_loss: 0.6363 - val_accuracy: 0.6736\n",
      "Epoch 69/70\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6384 - val_accuracy: 0.6736\n",
      "Epoch 70/70\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.6318 - val_loss: 0.6355 - val_accuracy: 0.6736\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_60min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 6ms/step - loss: 0.6777 - accuracy: 0.5936 - val_loss: 0.6492 - val_accuracy: 0.6736\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6322 - val_loss: 0.6408 - val_accuracy: 0.6736\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.6270 - val_loss: 0.6442 - val_accuracy: 0.6736\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6274 - val_loss: 0.6445 - val_accuracy: 0.6736\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6263 - val_loss: 0.6396 - val_accuracy: 0.6736\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6318 - val_loss: 0.6371 - val_accuracy: 0.6736\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6314 - val_loss: 0.6352 - val_accuracy: 0.6736\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6318 - val_loss: 0.6398 - val_accuracy: 0.6736\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6281 - val_loss: 0.6382 - val_accuracy: 0.6736\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6303 - val_loss: 0.6482 - val_accuracy: 0.6736\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6318 - val_loss: 0.6419 - val_accuracy: 0.6736\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6303 - val_loss: 0.6401 - val_accuracy: 0.6736\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6311 - val_loss: 0.6336 - val_accuracy: 0.6736\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6303 - val_loss: 0.6434 - val_accuracy: 0.6632\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6336 - val_loss: 0.6403 - val_accuracy: 0.6715\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6303 - val_loss: 0.6364 - val_accuracy: 0.6715\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6311 - val_loss: 0.6490 - val_accuracy: 0.6674\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6311 - val_loss: 0.6436 - val_accuracy: 0.6674\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6314 - val_loss: 0.6372 - val_accuracy: 0.6736\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6263 - val_loss: 0.6331 - val_accuracy: 0.6736\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6289 - val_loss: 0.6348 - val_accuracy: 0.6736\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6292 - val_loss: 0.6441 - val_accuracy: 0.6674\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6307 - val_loss: 0.6453 - val_accuracy: 0.6736\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6322 - val_loss: 0.6417 - val_accuracy: 0.6674\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6336 - val_loss: 0.6427 - val_accuracy: 0.6674\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6333 - val_loss: 0.6479 - val_accuracy: 0.6674\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6329 - val_loss: 0.6443 - val_accuracy: 0.6674\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6344 - val_loss: 0.6385 - val_accuracy: 0.6674\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6333 - val_loss: 0.6417 - val_accuracy: 0.6674\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6325 - val_loss: 0.6398 - val_accuracy: 0.6590\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6322 - val_loss: 0.6445 - val_accuracy: 0.6549\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6303 - val_loss: 0.6430 - val_accuracy: 0.6549\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6325 - val_loss: 0.6418 - val_accuracy: 0.6674\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6318 - val_loss: 0.6452 - val_accuracy: 0.6549\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6197 - val_loss: 0.6532 - val_accuracy: 0.6590\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6267 - val_loss: 0.6425 - val_accuracy: 0.6590\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6318 - val_loss: 0.6366 - val_accuracy: 0.6653\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6322 - val_loss: 0.6402 - val_accuracy: 0.6653\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6307 - val_loss: 0.6504 - val_accuracy: 0.6549\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6329 - val_loss: 0.6437 - val_accuracy: 0.6590\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6340 - val_loss: 0.6392 - val_accuracy: 0.6590\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6336 - val_loss: 0.6402 - val_accuracy: 0.6590\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6322 - val_loss: 0.6439 - val_accuracy: 0.6528\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6296 - val_loss: 0.6406 - val_accuracy: 0.6653\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6285 - val_loss: 0.6737 - val_accuracy: 0.6445\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6300 - val_loss: 0.6378 - val_accuracy: 0.6736\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6318 - val_loss: 0.6457 - val_accuracy: 0.6736\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6318 - val_loss: 0.6490 - val_accuracy: 0.6736\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6314 - val_loss: 0.6500 - val_accuracy: 0.6736\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6300 - val_loss: 0.6384 - val_accuracy: 0.6715\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6314 - val_loss: 0.6438 - val_accuracy: 0.6736\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6322 - val_loss: 0.6406 - val_accuracy: 0.6653\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6322 - val_loss: 0.6488 - val_accuracy: 0.6653\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6314 - val_loss: 0.6510 - val_accuracy: 0.6736\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6300 - val_loss: 0.6443 - val_accuracy: 0.6674\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6311 - val_loss: 0.6413 - val_accuracy: 0.6736\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6318 - val_loss: 0.6388 - val_accuracy: 0.6736\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6322 - val_loss: 0.6405 - val_accuracy: 0.6736\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6314 - val_loss: 0.6436 - val_accuracy: 0.6736\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6311 - val_loss: 0.6342 - val_accuracy: 0.6736\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6318 - val_loss: 0.6409 - val_accuracy: 0.6736\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6314 - val_loss: 0.6372 - val_accuracy: 0.6736\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6322 - val_loss: 0.6425 - val_accuracy: 0.6736\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6318 - val_loss: 0.6398 - val_accuracy: 0.6736\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6241 - val_loss: 0.6404 - val_accuracy: 0.6736\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6307 - val_loss: 0.6457 - val_accuracy: 0.6736\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6318 - val_loss: 0.6403 - val_accuracy: 0.6694\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6322 - val_loss: 0.6440 - val_accuracy: 0.6674\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6296 - val_loss: 0.6467 - val_accuracy: 0.6611\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6314 - val_loss: 0.6513 - val_accuracy: 0.6674\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6303 - val_loss: 0.6380 - val_accuracy: 0.6736\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6292 - val_loss: 0.6362 - val_accuracy: 0.6632\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6127 - val_loss: 0.6587 - val_accuracy: 0.6445\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6131 - val_loss: 0.6409 - val_accuracy: 0.6549\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6285 - val_loss: 0.6419 - val_accuracy: 0.6611\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6285 - val_loss: 0.6499 - val_accuracy: 0.6632\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6303 - val_loss: 0.6427 - val_accuracy: 0.6674\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6336 - val_loss: 0.6453 - val_accuracy: 0.6590\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6281 - val_loss: 0.6527 - val_accuracy: 0.6653\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.6307 - val_loss: 0.6459 - val_accuracy: 0.6590\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6292 - val_loss: 0.6454 - val_accuracy: 0.6528\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6311 - val_loss: 0.6445 - val_accuracy: 0.6590\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6270 - val_loss: 0.6411 - val_accuracy: 0.6653\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6292 - val_loss: 0.6452 - val_accuracy: 0.6611\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6307 - val_loss: 0.6434 - val_accuracy: 0.6653\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6274 - val_loss: 0.6509 - val_accuracy: 0.6091\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6340 - val_loss: 0.6448 - val_accuracy: 0.6674\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6248 - val_loss: 0.6445 - val_accuracy: 0.6611\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6292 - val_loss: 0.6445 - val_accuracy: 0.6611\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6329 - val_loss: 0.6437 - val_accuracy: 0.6590\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6322 - val_loss: 0.6442 - val_accuracy: 0.6590\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6336 - val_loss: 0.6483 - val_accuracy: 0.6674\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6329 - val_loss: 0.6488 - val_accuracy: 0.6674\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6311 - val_loss: 0.6488 - val_accuracy: 0.6507\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6274 - val_loss: 0.6445 - val_accuracy: 0.6590\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6340 - val_loss: 0.6636 - val_accuracy: 0.6674\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6336 - val_loss: 0.6438 - val_accuracy: 0.6653\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6336 - val_loss: 0.6400 - val_accuracy: 0.6653\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6314 - val_loss: 0.6474 - val_accuracy: 0.6528\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6322 - val_loss: 0.6419 - val_accuracy: 0.6653\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WINFUT_F_0_60min - Time: 3311.427442550659\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.1354 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 1.9112e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.4192e-05 - accuracy: 1.0000 - val_loss: 6.1164e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.4342e-05 - accuracy: 1.0000 - val_loss: 2.9785e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 7.8284e-06 - accuracy: 1.0000 - val_loss: 1.7926e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.8871e-06 - accuracy: 1.0000 - val_loss: 1.2075e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 3.3074e-06 - accuracy: 1.0000 - val_loss: 8.4495e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.3638e-06 - accuracy: 1.0000 - val_loss: 6.2825e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.7590e-06 - accuracy: 1.0000 - val_loss: 4.8237e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3497e-06 - accuracy: 1.0000 - val_loss: 3.7781e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.0549e-06 - accuracy: 1.0000 - val_loss: 3.0174e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 8.4810e-07 - accuracy: 1.0000 - val_loss: 2.4575e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.8086e-07 - accuracy: 1.0000 - val_loss: 2.0352e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.6477e-07 - accuracy: 1.0000 - val_loss: 1.6768e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.6627e-07 - accuracy: 1.0000 - val_loss: 1.4005e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.9387e-07 - accuracy: 1.0000 - val_loss: 1.2206e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.1692e-07 - accuracy: 1.0000 - val_loss: 1.0120e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.7013e-07 - accuracy: 1.0000 - val_loss: 8.7260e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.3936e-07 - accuracy: 1.0000 - val_loss: 7.8140e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.1988e-07 - accuracy: 1.0000 - val_loss: 6.6959e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.8743e-07 - accuracy: 1.0000 - val_loss: 5.7075e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.6571e-07 - accuracy: 1.0000 - val_loss: 4.9559e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.2875e-07 - accuracy: 1.0000 - val_loss: 4.4142e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.4683e-08 - accuracy: 1.0000 - val_loss: 3.7182e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 8.1244e-08 - accuracy: 1.0000 - val_loss: 3.3295e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.9415e-08 - accuracy: 1.0000 - val_loss: 3.0173e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 6.5475e-08 - accuracy: 1.0000 - val_loss: 2.6347e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.7350e-08 - accuracy: 1.0000 - val_loss: 2.3435e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.3735e-08 - accuracy: 1.0000 - val_loss: 2.0522e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.2626e-08 - accuracy: 1.0000 - val_loss: 1.7980e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.6070e-08 - accuracy: 1.0000 - val_loss: 1.6277e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 3.1801e-08 - accuracy: 1.0000 - val_loss: 1.4463e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.7575e-08 - accuracy: 1.0000 - val_loss: 1.3032e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6551e-08 - accuracy: 1.0000 - val_loss: 1.1785e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.5833e-08 - accuracy: 1.0000 - val_loss: 1.0749e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.5593e-08 - accuracy: 1.0000 - val_loss: 9.7860e-08 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.1259e-08 - accuracy: 1.0000 - val_loss: 8.6384e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.1130e-08 - accuracy: 1.0000 - val_loss: 8.5026e-08 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 9.3006e-09 - accuracy: 1.0000 - val_loss: 6.7996e-08 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.1917e-09 - accuracy: 1.0000 - val_loss: 6.7996e-08 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 8.4512e-09 - accuracy: 1.0000 - val_loss: 5.0966e-08 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 8.0809e-09 - accuracy: 1.0000 - val_loss: 5.0966e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.9720e-09 - accuracy: 1.0000 - val_loss: 4.8251e-08 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 7.8413e-09 - accuracy: 1.0000 - val_loss: 3.8873e-08 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 7.4710e-09 - accuracy: 1.0000 - val_loss: 3.4060e-08 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.0751e-09 - accuracy: 1.0000 - val_loss: 3.4060e-08 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.4415e-09 - accuracy: 1.0000 - val_loss: 2.6409e-08 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.8969e-09 - accuracy: 1.0000 - val_loss: 2.6409e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8751e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6573e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.6554e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.1108e-09 - accuracy: 1.0000 - val_loss: 1.7030e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 9.5838e-10 - accuracy: 1.0000 - val_loss: 9.3788e-09 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.1482e-10 - accuracy: 1.0000 - val_loss: 9.3788e-09 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.1482e-10 - accuracy: 1.0000 - val_loss: 9.3788e-09 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.2275e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.7425e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1781e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelWDOFUT_F_0_30min/buying2/tuner0.json\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.6764 - accuracy: 0.6012 - val_loss: 0.6628 - val_accuracy: 0.6284\n",
      "Epoch 2/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6105 - val_loss: 0.6634 - val_accuracy: 0.6284\n",
      "Epoch 3/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 4/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6626 - val_accuracy: 0.6284\n",
      "Epoch 5/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6100 - val_loss: 0.6606 - val_accuracy: 0.6284\n",
      "Epoch 6/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6621 - val_accuracy: 0.6284\n",
      "Epoch 7/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 8/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6627 - val_accuracy: 0.6284\n",
      "Epoch 9/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6080 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 10/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6107 - val_loss: 0.6619 - val_accuracy: 0.6284\n",
      "Epoch 11/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6597 - val_accuracy: 0.6284\n",
      "Epoch 12/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 13/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6096 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 14/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6700 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 15/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6601 - val_accuracy: 0.6284\n",
      "Epoch 16/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6596 - val_accuracy: 0.6284\n",
      "Epoch 17/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.6076 - val_loss: 0.6617 - val_accuracy: 0.6284\n",
      "Epoch 18/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6107 - val_loss: 0.6630 - val_accuracy: 0.6284\n",
      "Epoch 19/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6599 - val_accuracy: 0.6284\n",
      "Epoch 20/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6619 - val_accuracy: 0.6284\n",
      "Epoch 21/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6673 - val_accuracy: 0.6284\n",
      "Epoch 22/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6618 - val_accuracy: 0.6284\n",
      "Epoch 23/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6003 - val_loss: 0.6625 - val_accuracy: 0.6284\n",
      "Epoch 24/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6706 - accuracy: 0.6107 - val_loss: 0.6597 - val_accuracy: 0.6284\n",
      "Epoch 25/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6620 - val_accuracy: 0.6284\n",
      "Epoch 26/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6651 - val_accuracy: 0.6284\n",
      "Epoch 27/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 28/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6102 - val_loss: 0.6621 - val_accuracy: 0.6284\n",
      "Epoch 29/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6643 - val_accuracy: 0.6284\n",
      "Epoch 30/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6107 - val_loss: 0.6600 - val_accuracy: 0.6284\n",
      "Epoch 31/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.6089 - val_loss: 0.6600 - val_accuracy: 0.6284\n",
      "Epoch 32/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 33/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6625 - val_accuracy: 0.6284\n",
      "Epoch 34/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "Epoch 35/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6664 - val_accuracy: 0.6284\n",
      "Epoch 36/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6102 - val_loss: 0.6633 - val_accuracy: 0.6284\n",
      "Epoch 37/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6597 - val_accuracy: 0.6284\n",
      "Epoch 38/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6650 - val_accuracy: 0.6284\n",
      "Epoch 39/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6054 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 40/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6627 - val_accuracy: 0.6284\n",
      "Epoch 41/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6624 - val_accuracy: 0.6284\n",
      "Epoch 42/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6709 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 43/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6601 - val_accuracy: 0.6284\n",
      "Epoch 44/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 45/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6597 - val_accuracy: 0.6284\n",
      "Epoch 46/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6107 - val_loss: 0.6672 - val_accuracy: 0.6284\n",
      "Epoch 47/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 48/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6096 - val_loss: 0.6624 - val_accuracy: 0.6284\n",
      "Epoch 49/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6107 - val_loss: 0.6600 - val_accuracy: 0.6284\n",
      "Epoch 50/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6659 - val_accuracy: 0.6284\n",
      "Epoch 51/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6623 - val_accuracy: 0.6284\n",
      "Epoch 52/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 53/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6599 - val_accuracy: 0.6284\n",
      "Epoch 54/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 55/70\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6614 - val_accuracy: 0.6284\n",
      "Epoch 56/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 57/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6599 - val_accuracy: 0.6284\n",
      "Epoch 58/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 59/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6100 - val_loss: 0.6598 - val_accuracy: 0.6284\n",
      "Epoch 60/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6616 - val_accuracy: 0.6284\n",
      "Epoch 61/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6107 - val_loss: 0.6664 - val_accuracy: 0.6284\n",
      "Epoch 62/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 63/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6103 - val_loss: 0.6624 - val_accuracy: 0.6284\n",
      "Epoch 64/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "Epoch 65/70\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.6107 - val_loss: 0.6630 - val_accuracy: 0.6284\n",
      "Epoch 66/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6619 - val_accuracy: 0.6284\n",
      "Epoch 67/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6598 - val_accuracy: 0.6284\n",
      "Epoch 68/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6603 - val_accuracy: 0.6284\n",
      "Epoch 69/70\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 70/70\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Reloading Tuner from optmz/modelWINFUT_F_0_30min/buying2/tuner0.json\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.6801 - accuracy: 0.5828 - val_loss: 0.6612 - val_accuracy: 0.6284\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6085 - val_loss: 0.6622 - val_accuracy: 0.6284\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6103 - val_loss: 0.6643 - val_accuracy: 0.6284\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6100 - val_loss: 0.6601 - val_accuracy: 0.6284\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6695 - accuracy: 0.6098 - val_loss: 0.6623 - val_accuracy: 0.6253\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5994 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6107 - val_loss: 0.6598 - val_accuracy: 0.6284\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6591 - val_accuracy: 0.6284\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6589 - val_accuracy: 0.6284\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6590 - val_accuracy: 0.6284\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6107 - val_loss: 0.6615 - val_accuracy: 0.6284\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6107 - val_loss: 0.6618 - val_accuracy: 0.6284\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6107 - val_loss: 0.6632 - val_accuracy: 0.6284\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6626 - val_accuracy: 0.6284\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6621 - val_accuracy: 0.6284\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6622 - val_accuracy: 0.6284\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6107 - val_loss: 0.6654 - val_accuracy: 0.6284\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6626 - val_accuracy: 0.6284\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6616 - val_accuracy: 0.6284\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6620 - val_accuracy: 0.6284\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6650 - val_accuracy: 0.6284\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6704 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6606 - val_accuracy: 0.6284\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6632 - val_accuracy: 0.6284\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6612 - val_accuracy: 0.6284\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6107 - val_loss: 0.6618 - val_accuracy: 0.6284\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6606 - val_accuracy: 0.6284\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6631 - val_accuracy: 0.6284\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6619 - val_accuracy: 0.6284\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6107 - val_loss: 0.6640 - val_accuracy: 0.6284\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6107 - val_loss: 0.6612 - val_accuracy: 0.6284\n",
      "Epoch 53/100\n",
      "  1/172 [..............................] - ETA: 0s - loss: 0.6844 - accuracy: 0.5625Epoch 1/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6603 - val_accuracy: 0.6284\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 0.2418 - accuracy: 0.9001 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6612 - val_accuracy: 0.6284\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 5.6015e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9990\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 2.2298e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6616 - val_accuracy: 0.6284\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.2461e-04 - accuracy: 1.0000 - val_loss: 7.3741e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6637 - val_accuracy: 0.6284\n",
      " 73/172 [===========>..................] - ETA: 0s - loss: 7.6452e-05 - accuracy: 1.0000Epoch 62/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.4208e-05 - accuracy: 1.0000 - val_loss: 6.3663e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.8079e-05 - accuracy: 1.0000 - val_loss: 5.4071e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6605 - val_accuracy: 0.6284\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.4073e-05 - accuracy: 1.0000 - val_loss: 4.4995e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6606 - val_accuracy: 0.6284\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.5202e-05 - accuracy: 1.0000 - val_loss: 3.3571e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6107 - val_loss: 0.6639 - val_accuracy: 0.6284\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9188e-05 - accuracy: 1.0000 - val_loss: 2.8659e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6107 - val_loss: 0.6620 - val_accuracy: 0.6284\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.4739e-05 - accuracy: 1.0000 - val_loss: 3.0161e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.2152e-05 - accuracy: 1.0000 - val_loss: 2.3376e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6603 - val_accuracy: 0.6284\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.5868e-06 - accuracy: 1.0000 - val_loss: 2.1347e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6616 - val_accuracy: 0.6284\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.9473e-06 - accuracy: 1.0000 - val_loss: 1.5878e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6624 - val_accuracy: 0.6284\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 6.7096e-06 - accuracy: 1.0000 - val_loss: 1.5570e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.6362e-06 - accuracy: 1.0000 - val_loss: 1.2280e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6610 - val_accuracy: 0.6284\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.7891e-06 - accuracy: 1.0000 - val_loss: 1.1181e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6616 - val_accuracy: 0.6284\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.0884e-06 - accuracy: 1.0000 - val_loss: 1.1797e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.5409e-06 - accuracy: 1.0000 - val_loss: 9.4309e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.0357e-06 - accuracy: 1.0000 - val_loss: 8.4911e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6620 - val_accuracy: 0.6284\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6202e-06 - accuracy: 1.0000 - val_loss: 7.6144e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 2.2558e-06 - accuracy: 1.0000 - val_loss: 7.6838e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6697 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9701e-06 - accuracy: 1.0000 - val_loss: 6.9310e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6615 - val_accuracy: 0.6284\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.7222e-06 - accuracy: 1.0000 - val_loss: 6.4027e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.4988e-06 - accuracy: 1.0000 - val_loss: 5.7674e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3379e-06 - accuracy: 1.0000 - val_loss: 5.6825e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.1638e-06 - accuracy: 1.0000 - val_loss: 5.2118e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6609 - val_accuracy: 0.6284\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.0353e-06 - accuracy: 1.0000 - val_loss: 4.7164e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.1047e-07 - accuracy: 1.0000 - val_loss: 4.4951e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6612 - val_accuracy: 0.6284\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 8.1208e-07 - accuracy: 1.0000 - val_loss: 4.1070e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 7.0107e-07 - accuracy: 1.0000 - val_loss: 4.1026e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6107 - val_loss: 0.6617 - val_accuracy: 0.6284\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 6.2412e-07 - accuracy: 1.0000 - val_loss: 3.8508e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6608 - val_accuracy: 0.6284\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.5030e-07 - accuracy: 1.0000 - val_loss: 3.5522e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6702 - accuracy: 0.6107 - val_loss: 0.6613 - val_accuracy: 0.6284\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.8036e-07 - accuracy: 1.0000 - val_loss: 3.5096e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6601 - val_accuracy: 0.6284\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.3077e-07 - accuracy: 1.0000 - val_loss: 3.3164e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6615 - val_accuracy: 0.6284\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.8786e-07 - accuracy: 1.0000 - val_loss: 3.1547e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.5209e-07 - accuracy: 1.0000 - val_loss: 2.9871e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6107 - val_loss: 0.6606 - val_accuracy: 0.6284\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 3.0905e-07 - accuracy: 1.0000 - val_loss: 2.7762e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6615 - val_accuracy: 0.6284\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.7455e-07 - accuracy: 1.0000 - val_loss: 2.5491e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.4569e-07 - accuracy: 1.0000 - val_loss: 2.3961e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.6107 - val_loss: 0.6611 - val_accuracy: 0.6284\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.1925e-07 - accuracy: 1.0000 - val_loss: 2.2586e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6107 - val_loss: 0.6607 - val_accuracy: 0.6284\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9503e-07 - accuracy: 1.0000 - val_loss: 2.0671e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "  1/172 [..............................] - ETA: 0s - loss: 8.5682e-08 - accuracy: 1.0000Epoch 99/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.7403e-07 - accuracy: 1.0000 - val_loss: 1.9818e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6696 - accuracy: 0.6107 - val_loss: 0.6604 - val_accuracy: 0.6284\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.5950e-07 - accuracy: 1.0000 - val_loss: 1.6738e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6107 - val_loss: 0.6602 - val_accuracy: 0.6284\n",
      "51/51 [==============================] - 0s 1ms/step loss: 1.3232e-07 - accuracy: 1.0000\n",
      "154/172 [=========================>....] - ETA: 0s - loss: 1.3331e-07 - accuracy: 1.0000    | Etapa 5 WINFUT_F_0_30min - Time: 7114.391751527786\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4365e-07 - accuracy: 1.0000 - val_loss: 1.5998e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.3143e-07 - accuracy: 1.0000 - val_loss: 1.4959e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.1296e-07 - accuracy: 1.0000 - val_loss: 1.3106e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 9.4683e-08 - accuracy: 1.0000 - val_loss: 1.1986e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 8.4054e-08 - accuracy: 1.0000 - val_loss: 1.0328e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 7.5734e-08 - accuracy: 1.0000 - val_loss: 9.6317e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 7.0789e-08 - accuracy: 1.0000 - val_loss: 8.3920e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.1641e-08 - accuracy: 1.0000 - val_loss: 7.5770e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.4105e-08 - accuracy: 1.0000 - val_loss: 6.9829e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.4173e-08 - accuracy: 1.0000 - val_loss: 6.1828e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.8945e-08 - accuracy: 1.0000 - val_loss: 5.6338e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.5612e-08 - accuracy: 1.0000 - val_loss: 4.9668e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.4218e-08 - accuracy: 1.0000 - val_loss: 4.4123e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.2389e-08 - accuracy: 1.0000 - val_loss: 4.1388e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.5767e-08 - accuracy: 1.0000 - val_loss: 3.6831e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.4787e-08 - accuracy: 1.0000 - val_loss: 3.3167e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.3720e-08 - accuracy: 1.0000 - val_loss: 3.0309e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.2217e-08 - accuracy: 1.0000 - val_loss: 2.7393e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0170e-08 - accuracy: 1.0000 - val_loss: 2.4734e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.6488e-08 - accuracy: 1.0000 - val_loss: 2.2204e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5966e-08 - accuracy: 1.0000 - val_loss: 2.0563e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.0825e-08 - accuracy: 1.0000 - val_loss: 1.8561e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 9.8452e-09 - accuracy: 1.0000 - val_loss: 1.7240e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 9.1482e-09 - accuracy: 1.0000 - val_loss: 1.5410e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 8.4294e-09 - accuracy: 1.0000 - val_loss: 1.4409e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.7087e-09 - accuracy: 1.0000 - val_loss: 1.3334e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.3602e-09 - accuracy: 1.0000 - val_loss: 1.2172e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.9899e-09 - accuracy: 1.0000 - val_loss: 1.1464e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.9245e-09 - accuracy: 1.0000 - val_loss: 1.0942e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.9027e-09 - accuracy: 1.0000 - val_loss: 1.0071e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 5.8374e-09 - accuracy: 1.0000 - val_loss: 9.1615e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.3127e-09 - accuracy: 1.0000 - val_loss: 8.4685e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.5939e-09 - accuracy: 1.0000 - val_loss: 7.7311e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1147e-09 - accuracy: 1.0000 - val_loss: 7.1885e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8534e-09 - accuracy: 1.0000 - val_loss: 6.8431e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9405e-09 - accuracy: 1.0000 - val_loss: 6.4078e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8098e-09 - accuracy: 1.0000 - val_loss: 6.2277e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0910e-09 - accuracy: 1.0000 - val_loss: 5.5826e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.1326e-09 - accuracy: 1.0000 - val_loss: 5.0818e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.3166e-10 - accuracy: 1.0000 - val_loss: 4.8302e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 6.0988e-10 - accuracy: 1.0000 - val_loss: 4.5748e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 5.2275e-10 - accuracy: 1.0000 - val_loss: 4.3824e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.7919e-10 - accuracy: 1.0000 - val_loss: 4.1098e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 4.7919e-10 - accuracy: 1.0000 - val_loss: 3.9346e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.5741e-10 - accuracy: 1.0000 - val_loss: 3.7558e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 4.3563e-10 - accuracy: 1.0000 - val_loss: 3.6312e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.7028e-10 - accuracy: 1.0000 - val_loss: 3.3746e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.4850e-10 - accuracy: 1.0000 - val_loss: 3.2364e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6138e-10 - accuracy: 1.0000 - val_loss: 3.1587e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6138e-10 - accuracy: 1.0000 - val_loss: 2.9847e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6138e-10 - accuracy: 1.0000 - val_loss: 2.7849e-07 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1781e-10 - accuracy: 1.0000 - val_loss: 2.6085e-07 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1781e-10 - accuracy: 1.0000 - val_loss: 2.4900e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.1781e-10 - accuracy: 1.0000 - val_loss: 2.3025e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5247e-10 - accuracy: 1.0000 - val_loss: 2.3050e-07 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3069e-10 - accuracy: 1.0000 - val_loss: 2.1359e-07 - val_accuracy: 1.0000\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "    | Etapa 5 WDOFUT_F_0_30min - Time: 7136.301925420761\n",
      "Reloading Tuner from optmz/modelPETR3_B_0_30min/buying/tuner0.json\n",
      "Epoch 1/70\n",
      "143/143 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5065 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 2/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 3/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 4/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 5/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 6/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 7/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 8/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 9/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 10/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 11/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 12/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 13/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 14/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 15/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 16/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 17/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 18/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 19/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 20/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 21/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 22/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 23/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 24/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 25/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 26/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 27/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 28/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 29/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 30/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 31/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 32/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 33/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 34/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 35/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 36/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 37/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 38/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 39/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 40/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 41/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 42/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 43/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 44/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 45/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 46/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 47/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 48/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 49/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 50/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 51/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 52/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 53/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 54/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 55/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 56/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 57/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 58/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 59/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 60/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 61/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 62/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 63/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 64/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 65/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 66/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 67/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 68/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 69/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "Epoch 70/70\n",
      "143/143 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.5063 - val_loss: nan - val_accuracy: 0.5130\n",
      "42/42 [==============================] - 0s 915us/step\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6941 - accuracy: 0.4977 - val_loss: 0.6924 - val_accuracy: 0.4919\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5521 - val_loss: 0.6835 - val_accuracy: 0.5826\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6258 - val_loss: 0.6733 - val_accuracy: 0.6634\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6624 - val_loss: 0.6618 - val_accuracy: 0.6658\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6657 - val_loss: 0.6508 - val_accuracy: 0.6621\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6648 - val_loss: 0.6456 - val_accuracy: 0.6634\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6677 - val_loss: 0.6438 - val_accuracy: 0.6596\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6653 - val_loss: 0.6436 - val_accuracy: 0.6596\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6679 - val_loss: 0.6407 - val_accuracy: 0.6596\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6703 - val_loss: 0.6398 - val_accuracy: 0.6621\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6719 - val_loss: 0.6391 - val_accuracy: 0.6621\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6725 - val_loss: 0.6379 - val_accuracy: 0.6671\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6683 - val_loss: 0.6377 - val_accuracy: 0.6621\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6719 - val_loss: 0.6377 - val_accuracy: 0.6621\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6712 - val_loss: 0.6378 - val_accuracy: 0.6621\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6736 - val_loss: 0.6361 - val_accuracy: 0.6658\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6736 - val_loss: 0.6355 - val_accuracy: 0.6658\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6701 - val_loss: 0.6366 - val_accuracy: 0.6621\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6762 - val_loss: 0.6361 - val_accuracy: 0.6621\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6765 - val_loss: 0.6361 - val_accuracy: 0.6621\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6758 - val_loss: 0.6356 - val_accuracy: 0.6621\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6765 - val_loss: 0.6356 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6754 - val_loss: 0.6342 - val_accuracy: 0.6658\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6765 - val_loss: 0.6327 - val_accuracy: 0.6671\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6769 - val_loss: 0.6340 - val_accuracy: 0.6621\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6778 - val_loss: 0.6342 - val_accuracy: 0.6621\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6756 - val_loss: 0.6334 - val_accuracy: 0.6658\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6780 - val_loss: 0.6350 - val_accuracy: 0.6621\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6756 - val_loss: 0.6324 - val_accuracy: 0.6671\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6780 - val_loss: 0.6321 - val_accuracy: 0.6671\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6767 - val_loss: 0.6335 - val_accuracy: 0.6621\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6754 - val_loss: 0.6339 - val_accuracy: 0.6621\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6758 - val_loss: 0.6318 - val_accuracy: 0.6671\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6747 - val_loss: 0.6319 - val_accuracy: 0.6671\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6760 - val_loss: 0.6318 - val_accuracy: 0.6671\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6749 - val_loss: 0.6338 - val_accuracy: 0.6609\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6756 - val_loss: 0.6320 - val_accuracy: 0.6658\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6767 - val_loss: 0.6305 - val_accuracy: 0.6671\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6758 - val_loss: 0.6317 - val_accuracy: 0.6658\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6754 - val_loss: 0.6364 - val_accuracy: 0.6609\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6762 - val_loss: 0.6346 - val_accuracy: 0.6596\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6765 - val_loss: 0.6308 - val_accuracy: 0.6621\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6756 - val_loss: 0.6312 - val_accuracy: 0.6621\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6762 - val_loss: 0.6309 - val_accuracy: 0.6646\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6776 - val_loss: 0.6302 - val_accuracy: 0.6646\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6771 - val_loss: 0.6312 - val_accuracy: 0.6646\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6776 - val_loss: 0.6298 - val_accuracy: 0.6634\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6802 - val_loss: 0.6298 - val_accuracy: 0.6646\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6782 - val_loss: 0.6329 - val_accuracy: 0.6634\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6789 - val_loss: 0.6312 - val_accuracy: 0.6609\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6802 - val_loss: 0.6299 - val_accuracy: 0.6609\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6811 - val_loss: 0.6304 - val_accuracy: 0.6609\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6811 - val_loss: 0.6301 - val_accuracy: 0.6584\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6813 - val_loss: 0.6299 - val_accuracy: 0.6609\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6819 - val_loss: 0.6299 - val_accuracy: 0.6609\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6798 - val_loss: 0.6301 - val_accuracy: 0.6584\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6804 - val_loss: 0.6300 - val_accuracy: 0.6609\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6817 - val_loss: 0.6302 - val_accuracy: 0.6609\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6830 - val_loss: 0.6310 - val_accuracy: 0.6683\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6852 - val_loss: 0.6300 - val_accuracy: 0.6634\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6815 - val_loss: 0.6300 - val_accuracy: 0.6609\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6822 - val_loss: 0.6301 - val_accuracy: 0.6683\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6855 - val_loss: 0.6297 - val_accuracy: 0.6621\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6841 - val_loss: 0.6299 - val_accuracy: 0.6621\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6870 - val_loss: 0.6302 - val_accuracy: 0.6621\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6839 - val_loss: 0.6302 - val_accuracy: 0.6609\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6841 - val_loss: 0.6305 - val_accuracy: 0.6696\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6859 - val_loss: 0.6306 - val_accuracy: 0.6696\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6868 - val_loss: 0.6302 - val_accuracy: 0.6621\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6877 - val_loss: 0.6299 - val_accuracy: 0.6621\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6872 - val_loss: 0.6307 - val_accuracy: 0.6720\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6887 - val_loss: 0.6302 - val_accuracy: 0.6658\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6885 - val_loss: 0.6306 - val_accuracy: 0.6658\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6879 - val_loss: 0.6302 - val_accuracy: 0.6671\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6866 - val_loss: 0.6304 - val_accuracy: 0.6696\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6890 - val_loss: 0.6298 - val_accuracy: 0.6683\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6885 - val_loss: 0.6302 - val_accuracy: 0.6720\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6892 - val_loss: 0.6315 - val_accuracy: 0.6683\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6894 - val_loss: 0.6301 - val_accuracy: 0.6683\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6892 - val_loss: 0.6307 - val_accuracy: 0.6683\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6881 - val_loss: 0.6297 - val_accuracy: 0.6696\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6894 - val_loss: 0.6306 - val_accuracy: 0.6696\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6890 - val_loss: 0.6299 - val_accuracy: 0.6683\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6894 - val_loss: 0.6307 - val_accuracy: 0.6683\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6881 - val_loss: 0.6301 - val_accuracy: 0.6683\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6892 - val_loss: 0.6301 - val_accuracy: 0.6683\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6883 - val_loss: 0.6302 - val_accuracy: 0.6683\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6885 - val_loss: 0.6302 - val_accuracy: 0.6683\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6896 - val_loss: 0.6305 - val_accuracy: 0.6683\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6885 - val_loss: 0.6304 - val_accuracy: 0.6683\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6896 - val_loss: 0.6305 - val_accuracy: 0.6683\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6883 - val_loss: 0.6305 - val_accuracy: 0.6683\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6892 - val_loss: 0.6302 - val_accuracy: 0.6671\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6903 - val_loss: 0.6304 - val_accuracy: 0.6683\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6894 - val_loss: 0.6300 - val_accuracy: 0.6696\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6892 - val_loss: 0.6305 - val_accuracy: 0.6683\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6883 - val_loss: 0.6316 - val_accuracy: 0.6683\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6894 - val_loss: 0.6309 - val_accuracy: 0.6683\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6879 - val_loss: 0.6316 - val_accuracy: 0.6708\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6883 - val_loss: 0.6308 - val_accuracy: 0.6683\n",
      "42/42 [==============================] - 0s 981us/step\n",
      "    | Etapa 5 PETR3_B_0_30min - Time: 5956.508513689041\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getEnsambles)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"ensambles done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WINFUT_F_0_60min - Obtendo resultados!\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 23:02:58.895062: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 23:02:58.897974: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 23:02:58.951832: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 23:02:58.959874: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 23:02:58.969383: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 23:02:59.025672: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 PETR3_B_0_30min - Obtendo resultados!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 23:03:00.172628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 23:03:00.183709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 23:03:00.213693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Etapa 6 WINFUT_F_0_30min - Obtendo resultados!\n",
      "    | Etapa 6 PETR3_B_0_60min - Obtendo resultados!\n",
      "    | Etapa 6 WDOFUT_F_0_30min - Obtendo resultados!\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(getResults)(dataName, setDivision) for dataName in dataNames)\n",
    "commit_and_push(f\"results done {datetime.now()}\", \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa as estrategias definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerando estrategias...\n",
      "Files: ['PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/classification \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/regression \n",
      "\n",
      "Files: ['PETR3_B_0_60min_predictions_class.csv', 'PETR3_B_0_1min_ensamble.csv', 'PETR4_B_0_30min_Predictions.csv', 'PETR4_B_0_15min_ensamble.csv', 'PETR4_B_0_60min_ensamble.csv', 'PETR3_B_0_30min_ensamble.csv', 'PETR3_B_0_1min_predictions.csv', 'WINFUT_F_0_60min_ensamble.csv', 'PETR4_B_0_15min_predictions_class.csv', 'PETR3_B_0_5min_predictions.csv', 'WINFUT_F_0_30min_ensamble.csv', 'WINFUT_F_0_60min_predictions.csv', 'PETR3_B_0_5min_ensamble.csv', 'PETR3_B_0_5min_predictions_class.csv', 'PETR3_B_0_60min_ensamble.csv', 'PETR4_B_0_30min_predictions_class.csv', 'PETR3_B_0_15min_ensamble.csv', 'WDOFUT_F_0_30min_predictions.csv', 'WINFUT_F_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_predictions_class.csv', 'PETR4_B_0_30min_ensamble.csv', 'PETR4_B_0_15min_predictions.csv', 'PETR3_B_0_15min_predictions_class.csv', 'PETR3_B_0_30min_predictions_class.csv', 'WINFUT_F_0_30min_predictions.csv', 'PETR4_B_0_60min_predictions.csv', 'PETR4_B_0_60min_predictions_class.csv', 'WDOFUT_F_0_30min_ensamble.csv', 'PETR3_B_0_15min_predictions.csv', 'PETR3_B_0_1min_predictions_class.csv', 'WINFUT_F_0_30min_predictions_class.csv', 'PETR3_B_0_30min_predictions.csv', 'PETR3_B_0_60min_predictions.csv', 'PETR4_B_0_30min_predictions.csv'] \n",
      " Path: ../Results/test/statistic \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble1 \n",
      "\n",
      "Files: ['WINFUT_F_0_30min.csv', 'PETR4_B_0_30min.csv', 'PETR3_B_0_5min.csv', 'PETR3_B_0_15min.csv', 'WDOFUT_F_0_30min.csv', 'PETR3_B_0_1min.csv', 'PETR3_B_0_60min.csv', 'PETR4_B_0_15min.csv', 'WINFUT_F_0_60min.csv', 'PETR3_B_0_30min.csv', 'PETR4_B_0_60min.csv'] \n",
      " Path: ../Results/test/ensamble2 \n",
      "\n",
      "Commit e push bem-sucedidos.\n"
     ]
    }
   ],
   "source": [
    "from strategies import GetStrategies\n",
    "GetStrategies()\n",
    "commit_and_push(f\"strategies done {datetime.now()}\", \"main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
